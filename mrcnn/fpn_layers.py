"""
Mask R-CNN
The main Mask R-CNN model implemenetation.

Copyright (c) 2017 Matterport, Inc.
Licensed under the MIT License (see LICENSE for details)
Written by Waleed Abdulla
"""

import keras.backend as KB
import keras.layers  as KL
from   mrcnn.helper_layers import PyramidROIAlign, BatchNorm
from   mrcnn.utils         import logt

############################################################
#  FPN Layers Graph - 
############################################################
def fpn_graph(Resnet_Layers, verbose = 0):
    """
    #----------------------------------------------------------------------------
    # Build the Feature Pyramid Network (FPN) layers.
    # Top-down Layers
    # Returns a list of the last layers of each stage, 5 in total.
    # Don't create the thead (stage 5), so we pick the 4th item in the list.
    #----------------------------------------------------------------------------        
    # Top-down Layers
    # TODO: add assert to varify feature map sizes match what's in config
    """
    print('\n>>> Feature Pyramid Network (FPN) Graph ')
    
    _, C2, C3, C4, C5 = Resnet_Layers

    logt('Input FPN C5 ' , C5, verbose = verbose)    
    logt('Input FPN C4 ' , C4, verbose = verbose)    
    logt('Input FPN C3 ' , C3, verbose = verbose)    
    logt('Input FPN C2 ' , C2, verbose = verbose)    
    
    P5 = KL.Conv2D(256, (1, 1), name='fpn_c5p5')(C5)
    logt('FPN P5 ' , P5, verbose = verbose)    
    
    x = KL.UpSampling2D(size=(2, 2))(P5)
    y = KL.Conv2D(256, (1, 1))(C4)
    logt('   Upsampled P5 (x)' , x, verbose = verbose)    
    logt('   Conv2D    C4 (y)' , y, verbose = verbose)    
    
    P4 = KL.Add(name="fpn_p4add")([
         KL.UpSampling2D(size=(2, 2), name="fpn_p5upsampled")(P5),
         KL.Conv2D(256, (1, 1), name='fpn_c4p4')(C4)])
    logt('FPN P4 (x+y)' , P4, verbose = verbose)    

    x = KL.UpSampling2D(size=(2, 2))(P4)
    y = KL.Conv2D(256, (1, 1))(C3)
    logt('   Upsampled P4 (x)' , x, verbose = verbose)    
    logt('   Conv2D    C3 (y)' , y, verbose = verbose)    
    
    P3 = KL.Add(name="fpn_p3add")([
         KL.UpSampling2D(size=(2, 2), name="fpn_p4upsampled")(P4),
         KL.Conv2D(256, (1, 1), name='fpn_c3p3')(C3)])
    logt('FPN P3 (x+y)' , P3, verbose = verbose)    
    
    
    x = KL.UpSampling2D(size=(2, 2))(P3)
    y = KL.Conv2D(256, (1, 1))(C2)
    logt('   Upsampled P3 (x)' , x, verbose = verbose)    
    logt('   Conv2D    C2 (y)' , y, verbose = verbose)    
    
    P2 = KL.Add(name="fpn_p2add")([
         KL.UpSampling2D(size=(2, 2), name="fpn_p3upsampled")(P3),
         KL.Conv2D(256, (1, 1), name='fpn_c2p2')(C2)])
    logt('FPN P2 (x+y)' , P2, verbose = verbose)    
    
    # Attach 3x3 conv to all P layers to get the final feature maps.
    P2 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p2")(P2)
    P3 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p3")(P3)
    P4 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p4")(P4)
    P5 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p5")(P5)
    
    # P6 is used for the 5th anchor scale in RPN. Generated by
    # subsampling from P5 with stride of 2.
    P6 = KL.MaxPooling2D(pool_size=(1, 1), strides=2, name="fpn_p6")(P5)
    if verbose:
        print()
        print('    FPN Final output') 
        logt('     FPN P6 (Maxpool2D of P5 w/ stride 2)', P6)
        logt('     FPN P5 (Conv2D (3,3) of P5)', P5)
        logt('     FPN P4 (Conv2D (3,3) of P4)', P4)
        logt('     FPN P3 (Conv2D (3,3) of P3)', P3)
        logt('     FPN P2 (Conv2D (3,3) of P2)', P2)

    return [P2, P3, P4, P5, P6]
    

###############################################################
#  Feature Pyramid Network Head - Classifier
###############################################################
def fpn_classifier_graph(rois, feature_maps, image_shape, pool_size, num_classes, verbose = 0):
    '''
    Builds the computation graph of the feature pyramid network classifier
    and regressor heads.
    
    Inputs:
    -------
    rois:               [batch, num_rois, 4 ] 
                        Proposal boxes in normalized coordinates (y1, x1, y2, x2)
                        
    feature_maps:       List of feature maps from diffent layers of the pyramid,
                        [P2, P3, P4, P5]. Each has a different resolution.
    image_shape:        [height, width, depth]
    
    pool_size:          The width of the square feature map generated from ROI Pooling.
    
    num_classes:        number of classes, which determines the depth of the results

    Returns:
    --------
    logits:             [N, NUM_CLASSES] classifier logits (before softmax)
    probs:              [N, NUM_CLASSES] classifier probabilities
    bbox_deltas:        [N, (dy, dx, log(dh), log(dw))] 
                        Deltas to apply to proposal boxes
                        
    '''
    print('\n>>> FPN Classifier Graph verbose:', verbose)
    if verbose:
    
        logt('    INPUT: rois shape ', rois)
        logt('    INPUT: mrcnn feature_maps ', len(feature_maps))
        logt('    -      feature_map P2 ', feature_maps[0])
        logt('    -      feature_map P3 ', feature_maps[1])
        logt('    -      feature_map P4 ', feature_maps[2])
        logt('    -      feature_map P5 ', feature_maps[3])
        logt('    INPUT: image_shape', image_shape)
        logt('    INPUT: pool_size  ', pool_size)
        logt('    INPUT: num_classes', num_classes)
    
    # ROI Pooling
    # Shape: [batch, num_boxes, pool_height, pool_width, channels]
    
    x = PyramidROIAlign([pool_size, pool_size], image_shape, name="roi_align_classifier")([rois] + feature_maps)
    logt('roi_align_classifier ' ,x, verbose = verbose)
    
    # Two 1024 FC layers (implemented with Conv2D for consistency)
    #-------------------------------------------------------------------------------------------
    # TimeDistributed : 
    # 
    #   Applies the Conv2D layer to each slice of the batch input. The input should be at least 3D,
    #   and the dimension of index one will be considered to be the temporal dimension.
    #
    # Example: 
    #   Consider a batch of 32 samples, where each sample is a sequence of 10 vectors of 16 dimensions. 
    #   The batch input shape of the layer is then (32, 10, 16). The input_shape, not including the 
    #   samples dimension, is (10, 16).
    #   You can then use TimeDistributed to apply a Dense layer to each of the 10 timesteps, independently:
    #   ## as the first layer in a model
    #   model = Sequential()
    #   model.add(TimeDistributed(Dense(8), input_shape=(10, 16)))
    #   ## now model.output_shape == (None, 10, 8)
    #
    #   In subsequent layers, there is no need for the input_shape:
    #   
    #   model.add(TimeDistributed(Dense(32)))
    #   # now model.output_shape == (None, 10, 32)
    #
    #   The output will then have shape (32, 10, 32).    
    #-------------------------------------------------------------------------------------------
    
    x = KL.TimeDistributed(KL.Conv2D(1024, (pool_size, pool_size), padding="valid"), name="mrcnn_class_conv1")(x)
    logt('mrcnn_class_conv1' ,x, verbose = verbose)
    
    x = KL.TimeDistributed(BatchNorm(axis=3), name='mrcnn_class_bn1')(x)
    logt('mrcnn_class_bn1  ' ,x, verbose = verbose)
    
    x = KL.Activation('relu')(x)
    logt('mrcnn_class_relu1' ,x, verbose = verbose)
    logt( verbose = verbose)
    # x = KL.Dropout(0.5)(x)
    x = KL.TimeDistributed(KL.Conv2D(1024, (1, 1)), name="mrcnn_class_conv2")(x)
    logt('mrcnn_class_conv2 ' ,x, verbose = verbose)
    
    x = KL.TimeDistributed(BatchNorm(axis=3), name='mrcnn_class_bn2')(x)
    logt('mrcnn_class_bn2   ' ,x, verbose = verbose)
    
    x = KL.Activation('relu')(x)
    logt('mrcnn_class_relu2 ' ,x, verbose = verbose)
    logt(verbose = verbose)
    
    shared = KL.Lambda(lambda x: KB.squeeze(KB.squeeze(x, 3), 2), name="pool_squeeze")(x)
    logt('pool_squeeze(Shared)', shared, verbose = verbose)

    ## Classifier head
    # x = KL.TimeDistributed(KL.Dense(num_classes, name = 'mrcnn_class_logits'))(shared)
    mrcnn_class_logits = KL.TimeDistributed(KL.Dense(num_classes), name = 'mrcnn_class_logits')(shared)
    logt('mrcnn_class_logits ' , mrcnn_class_logits, verbose = verbose)    
    
    mrcnn_class_logits = KL.Lambda(lambda x: KB.identity(x, name = 'mrcnn_class_logits'), name='mrcnn_logits_lambda')(mrcnn_class_logits)
    logt('mrcnn_class_logits (final)' , mrcnn_class_logits, verbose = verbose)    
    
    # x = KL.TimeDistributed(KL.Activation("softmax"))(mrcnn_class_logits)
    mrcnn_probs = KL.TimeDistributed(KL.Activation("softmax"), name = 'mrcnn_class_act')(mrcnn_class_logits)
    logt('mrcnn_probs  ' , mrcnn_probs, verbose = verbose)
    
    mrcnn_probs        = KL.Lambda(lambda x: KB.identity(x, name = 'mrcnn_class'), name='mrcnn_class_lambda')(mrcnn_probs)
    logt('mrcnn_probs (final) ' , mrcnn_probs, verbose = verbose)
    
    
    ## BBox head
    # [batch, boxes, num_classes * (dy, dx, log(dh), log(dw))]
    x = KL.TimeDistributed(KL.Dense(num_classes * 4, activation='linear'),name='mrcnn_bbox_fc')(shared)
    logt('mrcnn_bbox_fc ' , x, verbose = verbose)
    
    # Reshape to [batch, boxes, num_classes, (dy, dx, log(dh), log(dw))]
    s = KB.int_shape(x)
    mrcnn_bbox = KL.Reshape((s[1], num_classes, 4), name='mrcnn_bbox_rs')(x)
    logt('mrcnn_bbox_fc reshaped output' , mrcnn_bbox, verbose = verbose)    
    # mrcnn_bbox = KB.identity(mrcnn_bbox, name = "mrcnn_bbox")    
    mrcnn_bbox = KL.Lambda(lambda x: KB.identity(x, name = 'mrcnn_bbox'), name='mrcnn_bbox_lambda') (mrcnn_bbox)
    
    logt('mrcnn_bbox (final)' , mrcnn_bbox, verbose = verbose)    
    
    return mrcnn_class_logits, mrcnn_probs, mrcnn_bbox

    
###############################################################
#  Feature Pyramid Network Head - Mask
###############################################################
def fpn_mask_graph(rois, feature_maps, image_shape, pool_size, num_classes):
    """
    Builds the computation graph of the mask head of Feature Pyramid Network.

    num_rois is determined by config.TRAIN_ROIS_PER_IMAGE (default: 200)
    
    Inputs:
    -------
    rois:               [batch, num_rois, (y1, x1, y2, x2)] 
                        Proposal boxes in normalized coordinates.
    feature_maps:       List of feature maps from diffent layers of the pyramid,
                        [P2, P3, P4, P5]. Each has a different resolution.
    image_shape:        [height, width, depth]
    pool_size:          The width of the square feature map generated from ROI Pooling.
    num_classes:        number of classes, which determines the depth of the results

    Returns:
    --------
                    Masks [batch, num_rois, height, width, num_classes]
    """
    # ROI Pooling
    # Shape: [batch, boxes, pool_height, pool_width, channels]
    print('\n>>> FPN Mask Graph ')
    print('     rois shape          :', rois.get_shape())
    print('     Number of feature map layers passed from Resnet :', len(feature_maps))
    for item in feature_maps:
        print('         feature_maps shape  :', item.get_shape())
    print('     input_shape         :', image_shape)
    print('     pool_size           :', pool_size)
    

    x = PyramidROIAlign([pool_size, pool_size], image_shape, name="roi_align_mask")([rois] + feature_maps)

    # Conv layers
    x = KL.TimeDistributed(KL.Conv2D(256, (3, 3), padding="same"), name="mrcnn_mask_conv1")(x)
    x = KL.TimeDistributed(BatchNorm(axis=3), name='mrcnn_mask_bn1')(x)
    x = KL.Activation('relu')(x)

    x = KL.TimeDistributed(KL.Conv2D(256, (3, 3), padding="same"), name="mrcnn_mask_conv2")(x)
    x = KL.TimeDistributed(BatchNorm(axis=3), name='mrcnn_mask_bn2')(x)
    x = KL.Activation('relu')(x)

    x = KL.TimeDistributed(KL.Conv2D(256, (3, 3), padding="same"), name="mrcnn_mask_conv3")(x)
    x = KL.TimeDistributed(BatchNorm(axis=3), name='mrcnn_mask_bn3')(x)
    x = KL.Activation('relu')(x)

    x = KL.TimeDistributed(KL.Conv2D(256, (3, 3), padding="same"), name="mrcnn_mask_conv4")(x)
    x = KL.TimeDistributed(BatchNorm(axis=3), name='mrcnn_mask_bn4')(x)
    x = KL.Activation('relu')(x)

    x = KL.TimeDistributed(KL.Conv2DTranspose(256, (2, 2), strides=2, activation="relu"), name="mrcnn_mask_deconv")(x)
    x = KL.TimeDistributed(KL.Conv2D(num_classes, (1, 1), strides=1, activation="sigmoid"), name="mrcnn_mask")(x)
    
    print('     FPN Mask Graph output shape :', x.get_shape())
    
    return x

