{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Mask R-CNN - Train on NewShapes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Notes from implementation\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T20:39:44.329413Z",
     "start_time": "2018-12-22T20:39:43.917173Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "--> Execution started at: 12-22-2018 @ 21:39:44\n",
      "    Tensorflow Version: 1.8.0   Keras Version : 2.2.0 \n",
      "\n",
      "   Arguments passed :\n",
      "   --------------------\n",
      "   batch_size                     1\n",
      "   coco_classes                   None\n",
      "   epochs                         2\n",
      "   fcn_arch                       FCN32\n",
      "   fcn_layers                     ['fcn32+']\n",
      "   fcn_logs_dir                   train_fcn\n",
      "   fcn_losses                     fcn_BCE_loss\n",
      "   fcn_model                      last\n",
      "   last_epoch                     222\n",
      "   lr                             0.0001\n",
      "   mrcnn_exclude_layers           None\n",
      "   mrcnn_layers                   ['res3+']\n",
      "   mrcnn_logs_dir                 train_mrcnn_newshapes\n",
      "   mrcnn_model                    shapes\n",
      "   new_log_folder                 True\n",
      "   opt                            ADAM\n",
      "   scale_factor                   4\n",
      "   steps_in_epoch                 100\n",
      "   sysout                         SCREEN\n",
      "   val_steps                      8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.utils        as utils\n",
    "import mrcnn.visualize    as visualize\n",
    "from datetime            import datetime   \n",
    "from mrcnn.utils         import command_line_parser, Paths\n",
    "from mrcnn.datagen       import data_generator, load_image_gt, data_gen_simulate\n",
    "from mrcnn.prep_notebook import mrcnn_newshape_train, build_mrcnn_training_pipeline_newshapes\n",
    "from mrcnn.newshapes     import prep_newshape_dataset\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "start_time = datetime.now().strftime(\"%m-%d-%Y @ %H:%M:%S\")\n",
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "parser = command_line_parser()\n",
    "input_parms = \" --epochs 2 \"\n",
    "input_parms +=\" --steps_in_epoch 100 \"\n",
    "input_parms +=\" --last_epoch     222\" \n",
    "input_parms +=\" --batch_size       1 \" \n",
    "input_parms +=\" --lr          0.0001 \"\n",
    "input_parms +=\" --val_steps        8 \" \n",
    "input_parms +=\" --mrcnn_logs_dir  train_mrcnn_newshapes \"\n",
    "input_parms +=\" --mrcnn_model     shapes \"\n",
    "input_parms +=\" --mrcnn_layers    res3+\"\n",
    "input_parms +=\" --opt             adam \"\n",
    "input_parms +=\" --sysout        screen \"\n",
    "input_parms +=\" --new_log_folder    \"\n",
    "# input_parms +=\" --fcn_logs_dir   train_fcn8_newshapes \"\n",
    "# input_parms +=\" --fcn_model      init \"\n",
    "# input_parms +=\" --fcn_arch       fcn8 \" \n",
    "# input_parms +=\" --fcn_layers     all \" \n",
    "# input_parms +=\"--fcn_model /home/kbardool/models/train_fcn_adagrad/shapes20180709T1732/fcn_shapes_1167.h5\"\n",
    " \n",
    "args = parser.parse_args(input_parms.split())\n",
    "utils.display_input_parms(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T20:35:40.738671Z",
     "start_time": "2018-12-22T20:35:34.461460Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Arguments passed :\n",
      "   --------------------\n",
      "   batch_size                     1\n",
      "   coco_classes                   None\n",
      "   epochs                         2\n",
      "   fcn_arch                       FCN32\n",
      "   fcn_layers                     fcn32+\n",
      "   fcn_logs_dir                   train_fcn\n",
      "   fcn_losses                     fcn_BCE_loss\n",
      "   fcn_model                      last\n",
      "   last_epoch                     222\n",
      "   lr                             0.0001\n",
      "   mrcnn_exclude_layers           None\n",
      "   mrcnn_layers                   ['mrcnn', 'fpn', 'rpn']\n",
      "   mrcnn_logs_dir                 train_mrcnn_newshapes\n",
      "   mrcnn_model                    shapes\n",
      "   new_log_folder                 True\n",
      "   opt                            ADAM\n",
      "   scale_factor                   4\n",
      "   steps_in_epoch                 100\n",
      "   sysout                         SCREEN\n",
      "   val_steps                      8\n",
      "\n",
      "\n",
      ">>> Initialize Paths\n",
      " windows  Windows\n",
      "\n",
      "   Paths:\n",
      "   -------------------------\n",
      "COCO_DATASET_PATH              F:\\MLDatasets\\coco2014\n",
      "COCO_HEATMAP_PATH              F:\\MLDatasets\\coco2014_heatmaps\n",
      "COCO_MODEL_PATH                F:\\PretrainedModels\\mask_rcnn_coco.h5\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_ROOT                       F:\\\n",
      "DIR_TRAINING                   F:\\models\n",
      "FCN_TRAINING_PATH              F:\\models\\train_fcn_coco\n",
      "FCN_VGG16_MODEL_PATH           F:\\PretrainedModels\\fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "MRCNN_TRAINING_PATH            F:\\models\\train_mrcnn_newshapes\n",
      "PRED_CLASS_INFO_PATH           F:\\PretrainedModels\\predicted_classes_info.pkl\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "SHAPES_MODEL_PATH              F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      ">>> Initialize ModelBase model \n",
      "   Mode      :  training\n",
      "   Model dir :  F:\\models\\train_mrcnn_newshapes\n",
      ">>> set_log_dir(): model_path:  None\n",
      "    set_log_dir(): model_path has NOT been provided : None \n",
      "                   NewFolder: False  config.NEW_LOG_FOLDER: True \n",
      "    set_log_dir(): weight file template (self.checkpoint_path): F:\\models\\train_mrcnn_newshapes\\mrcnn20181222T2135\\mrcnn_{epoch:04d}.h5 \n",
      "    set_log_dir(): weight file dir      (self.log_dir)        : F:\\models\\train_mrcnn_newshapes\\mrcnn20181222T2135 \n",
      "    set_log_dir(): Last completed epoch (self.epoch)          : 0 \n",
      ">>> ModelBase initialiation complete\n",
      ">>> ---Initialize MRCNN model, mode:  training\n",
      "\n",
      "----------------------------\n",
      ">>> Resnet Graph \n",
      "----------------------------\n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "\n",
      ">>> RPN Layer \n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "--------------------------------\n",
      ">>>  CHM Layer  \n",
      "--------------------------------\n",
      "    > CHMLayer Call()              :  list length: 3\n",
      "--------------------------------\n",
      ">>>  CHM Layer COMPUTE OUTPUT SHAPE \n",
      "--------------------------------\n",
      "<class 'list'> 3\n",
      "\n",
      "-----------------------------------------\n",
      ">>>  CHM Layer (Ground Truth Generation) \n",
      "-----------------------------------------\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      "\n",
      ">>> rpn_class_loss_graph\n",
      "    rpn_match size : (?, ?, 1)\n",
      "    tf default session:  None\n",
      "    loss      : (?,) Tensor(\"rpn_class_loss/Shape:0\", shape=(1,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_class_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_class_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> rpn_class_loss_graph\n",
      "    rpn_match size : (?, ?, 1)\n",
      "    tf default session:  None\n",
      "    loss      : (?,) Tensor(\"rpn_class_loss/Shape_3:0\", shape=(1,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_class_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_class_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    loss      : <unknown> Tensor(\"rpn_bbox_loss/Shape:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_bbox_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_bbox_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    loss      : <unknown> Tensor(\"rpn_bbox_loss/Shape_3:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"rpn_bbox_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"rpn_bbox_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (1, ?)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "    loss      : (?, 32) Tensor(\"mrcnn_class_loss/Shape:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_class_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_class_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_class_logits size : (?, 32, 7)\n",
      "    active_class_ids  size : (?, ?)\n",
      "    loss      : (?, 32) Tensor(\"mrcnn_class_loss/Shape_3:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_class_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_class_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (1, ?)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (1, ?, ?)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "    loss      : <unknown> Tensor(\"mrcnn_bbox_loss/Shape:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_bbox_loss/Shape_1:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_bbox_loss/Shape_2:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_bbox size         : (?, 32, 7, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "    reshpaed pred_bbox size         : (?, 7, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "    loss      : <unknown> Tensor(\"mrcnn_bbox_loss/Shape_3:0\", shape=(?,), dtype=int32) KerasTensor:  False\n",
      "    mean loss : () Tensor(\"mrcnn_bbox_loss/Shape_4:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "    reshaped mean loss : (1, 1) Tensor(\"mrcnn_bbox_loss/Shape_5:0\", shape=(2,), dtype=int32) KerasTensor:  False\n",
      "\n",
      ">>> Build MaskRCNN build complete. mode:  training\n",
      ">>> MaskRCNN initialiation complete. Mode:  training\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COCO_CLASSES                   None\n",
      "COCO_DATASET_PATH              F:\\MLDatasets\\coco2014\n",
      "COCO_MODEL_PATH                F:\\PretrainedModels\\mask_rcnn_coco.h5\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DETECTION_PER_CLASS            32\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            100\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [32 32]\n",
      "GPU_COUNT                      1\n",
      "HEATMAP_SCALE_FACTOR           4\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_BUFFER                   20\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 222\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MAX_SHAPES_PER_IMAGE           15\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "MIN_SHAPES_PER_IMAGE           1\n",
      "NAME                           mrcnn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    7\n",
      "OPTIMIZER                      ADAM\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             30\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             50\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "ROI_GT_IOU_THRESHOLD           0.2\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "SHAPES_MODEL_PATH              F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      "STEPS_PER_EPOCH                100\n",
      "SYSOUT                         SCREEN\n",
      "TRAINING_PATH                  F:\\models\\train_mrcnn_newshapes\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               8\n",
      "VERBOSE                        0\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 128, 128, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: cntxt_layer/pred_heatmap:0                 Type: float32           Shape: (1, 32, 32, 7)\n",
      " layer:  1    output name: cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  2    output name: cntxt_layer_gt/gt_heatmap:0                Type: float32           Shape: (1, 32, 32, 7)\n",
      " layer:  3    output name: cntxt_layer_gt/gt_heatmap_scores:0         Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  4    output name: mrcnn_class_lambda/mrcnn_class:0           Type: float32           Shape: (?, 32, 7)\n",
      " layer:  5    output name: mrcnn_bbox_lambda/mrcnn_bbox:0             Type: float32           Shape: (?, 32, 7, 4)\n",
      " layer:  6    output name: proposal_targets/output_rois:0             Type: float32           Shape: (1, ?, ?)\n",
      " layer:  7    output name: proposal_targets/target_class_ids:0        Type: int32             Shape: (1, ?)\n",
      " layer:  8    output name: proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (1, ?, ?)\n",
      " layer:  9    output name: mrcnn_logits_lambda/mrcnn_class_logits:0   Type: float32           Shape: (?, 32, 7)\n",
      " layer: 10    output name: active_class_ids/strided_slice_3:0         Type: float32           Shape: (?, ?)\n",
      " layer: 11    output name: ROI/rpn_roi_proposals:0                    Type: float32           Shape: (1, ?, ?)\n",
      " layer: 12    output name: rpn_class_loss/rpn_class_loss:0            Type: float32           Shape: (1, 1)\n",
      " layer: 13    output name: rpn_bbox_loss/rpn_bbox_loss:0              Type: float32           Shape: (1, 1)\n",
      " layer: 14    output name: mrcnn_class_loss/mrcnn_class_loss:0        Type: float32           Shape: (1, 1)\n",
      " layer: 15    output name: mrcnn_bbox_loss/mrcnn_bbox_loss:0          Type: float32           Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "mrcnn_model= build_mrcnn_training_pipeline_newshapes(args = args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T12:22:31.858313Z",
     "start_time": "2018-12-17T12:22:31.533287Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 128, 128, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: cntxt_layer/pred_heatmap:0                 Type: float32           Shape: (1, 32, 32, 7)\n",
      " layer:  1    output name: cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  2    output name: cntxt_layer_gt/gt_heatmap:0                Type: float32           Shape: (1, 32, 32, 7)\n",
      " layer:  3    output name: cntxt_layer_gt/gt_heatmap_scores:0         Type: float32           Shape: (1, 7, 32, 23)\n",
      " layer:  4    output name: mrcnn_class_lambda/mrcnn_class:0           Type: float32           Shape: (?, 32, 7)\n",
      " layer:  5    output name: mrcnn_bbox_lambda/mrcnn_bbox:0             Type: float32           Shape: (?, 32, 7, 4)\n",
      " layer:  6    output name: proposal_targets/output_rois:0             Type: float32           Shape: (1, ?, ?)\n",
      " layer:  7    output name: proposal_targets/target_class_ids:0        Type: int32             Shape: (1, ?)\n",
      " layer:  8    output name: proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (1, ?, ?)\n",
      " layer:  9    output name: mrcnn_logits_lambda/mrcnn_class_logits:0   Type: float32           Shape: (?, 32, 7)\n",
      " layer: 10    output name: active_class_ids/strided_slice_3:0         Type: float32           Shape: (?, ?)\n",
      " layer: 11    output name: ROI/rpn_roi_proposals:0                    Type: float32           Shape: (1, ?, ?)\n",
      " layer: 12    output name: rpn_class_loss/rpn_class_loss:0            Type: float32           Shape: (1, 1)\n",
      " layer: 13    output name: rpn_bbox_loss/rpn_bbox_loss:0              Type: float32           Shape: (1, 1)\n",
      " layer: 14    output name: mrcnn_class_loss/mrcnn_class_loss:0        Type: float32           Shape: (1, 1)\n",
      " layer: 15    output name: mrcnn_bbox_loss/mrcnn_bbox_loss:0          Type: float32           Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "mrcnn_model.display_layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T20:36:01.698580Z",
     "start_time": "2018-12-22T20:36:01.387340Z"
    }
   },
   "outputs": [],
   "source": [
    "# t1 = mrcnn_model.get_trainable_layers()\n",
    "# for i, tt in enumerate(t1):\n",
    "#     print(i, tt.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T20:36:18.624526Z",
     "start_time": "2018-12-22T20:36:14.605419Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      " Load Model with init parm: [ shapes ]\n",
      " Exclude layers: \n",
      "    -  mrcnn_class_logits\n",
      "    -  mrcnn_bbox_fc\n",
      "-----------------------------------------------\n",
      " ---> coco : F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      ">>> load_weights() from : F:\\PretrainedModels\\mask_rcnn_shapes.h5\n",
      "    Weights file loaded: F:\\PretrainedModels\\mask_rcnn_shapes.h5 \n",
      "==========================================\n",
      "MRCNN  MODEL Load weight file COMPLETE \n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Load Mask RCNN Model Weight file\n",
    "##------------------------------------------------------------------------------------\n",
    "## WHEN RUNNING TRAINING AND INITIALIZING WEIGHTS FROM From mask_rcnn_shapes.h5\n",
    "## MUST EXCLUDE \"mrcnn_class_logits\" and \"mrcnn_bbox_fc\" layers\n",
    "exclude_list = [\"mrcnn_class_logits\", \"mrcnn_bbox_fc\"] \n",
    "mrcnn_model.load_model_weights(init_with = 'shapes', exclude = exclude_list, verbose = 1)   \n",
    "\n",
    "## Not required after INIT epoch, as now weights have been initialized properly. \n",
    "\n",
    "# mrcnn_model.load_model_weights(init_with = 'last',verbose = 1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build newshape datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T20:48:08.657879Z",
     "start_time": "2018-12-22T20:47:47.821669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepares complete\n",
      "Prepares complete\n"
     ]
    }
   ],
   "source": [
    "# del dataset_train, dataset_val, train_generator, val_generator\n",
    "# from mrcnn.prep_notebook import prep_newshape_dataset\n",
    "dataset_train, train_generator = prep_newshape_dataset( mrcnn_model.config, 10000, generator=True)\n",
    "dataset_val  , val_generator   = prep_newshape_dataset( mrcnn_model.config,  2500, generator=True)\n",
    "class_names = dataset_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T11:15:47.506768Z",
     "start_time": "2018-12-17T11:15:47.094473Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(dataset_train), type(train_generator))\n",
    "print(type(dataset_val), type(val_generator))\n",
    "print(len(dataset_train.image_info))\n",
    "print(len(dataset_val.image_info))\n",
    "print(len(dataset_train.image_ids), len(dataset_val.image_info))\n",
    "# dataset_train.display_active_class_info()\n",
    "print(dataset_train.class_from_source_map)\n",
    "print(dataset_train.class_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  display Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display next image from generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:51:04.592179Z",
     "start_time": "2018-12-20T17:51:04.302543Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:51:05.294289Z",
     "start_time": "2018-12-20T17:51:04.594148Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image id :  8507\n",
      " Image_id    :  8507  Reference:  [('car', (172, 2, 103), (100, 65, 15, 7))] Coco Id: 8507\n",
      " Image meta  :  [8507  128  128    3    0    0  128  128]\n",
      " Class ids   :  (1,)    [2]\n",
      " Class Names :  ['car']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5EAAAOICAYAAABPC3XsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize.display_training_batch(dataset_train, train_batch_x)\n",
    "\n",
    "# imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "# img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "# for img_idx in range(mrcnn_config.BATCH_SIZE):\n",
    "#     image_id = img_meta[img_idx,0]\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     bbox = utils.extract_bboxes(mask)\n",
    "#     print('Image id: ',image_id)\n",
    "#     print('Image meta', img_meta[img_idx])\n",
    "# #     print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "#     visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names, figsize =(8,8))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Load a specific image using image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T17:40:53.807454Z",
     "start_time": "2018-12-16T17:40:53.368124Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "IMAGE_LIST = [2000,4000,5000,6000]\n",
    "train_batch_x, train_batch_y = test_batch_x, test_batch_y = data_gen_simulate(dataset_train, mrcnn_model.config, IMAGE_LIST)\n",
    "visualize.display_training_batch(dataset_train, train_batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T17:47:37.428614Z",
     "start_time": "2018-12-16T17:47:35.464220Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training mrcnn, fpn, rpn layers\n",
    "\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "- Or now we can pass a list of layers we want to train in layers !\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:51:05.630509Z",
     "start_time": "2018-12-20T17:51:05.296272Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last epoch ran :  0\n",
      "    epochs to run  :  2\n",
      "    steps per epoch:  100\n",
      "    learning rate  :  0.0001\n",
      "    momentum       :  0.9\n",
      "    weight decay   :  0.0002\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "# Wed 09-05-2018\n",
    "# config.STEPS_PER_EPOCH        = 8\n",
    "# config.EARLY_STOP_PATIENCE    = 70\n",
    "train_layers = [ 'mrcnn', 'fpn','rpn']   ## equivalent to \"heads\"\n",
    "# train_layers = ['all']\n",
    "loss_names   = [ \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "# train_layers = [ 'mrcnn']\n",
    "# loss_names   = [ \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "\n",
    "mrcnn_model.config.LAST_EPOCH_RAN  =  0 #222\n",
    "mrcnn_model.config.EPOCHS_TO_RUN   =  2 # 100\n",
    "mrcnn_model.config.LEARNING_RATE   = 0.0001\n",
    "# mrcnn_model.config.STEPS_PER_EPOCH = 2\n",
    "# mrcnn_model.config.SYSOUT = 'screen'\n",
    " \n",
    "print('    last epoch ran : ',mrcnn_model.config.LAST_EPOCH_RAN)\n",
    "print('    epochs to run  : ',mrcnn_model.config.EPOCHS_TO_RUN)\n",
    "print('    steps per epoch: ',mrcnn_model.config.STEPS_PER_EPOCH)\n",
    "print('    learning rate  : ', mrcnn_model.config.LEARNING_RATE)\n",
    "print('    momentum       : ', mrcnn_model.config.LEARNING_MOMENTUM)\n",
    "print('    weight decay   : ',mrcnn_model.config.WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:51:38.904477Z",
     "start_time": "2018-12-20T17:51:08.627099Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mrcnn', 'fpn', 'rpn']\n",
      "['(mrcnn\\\\_.*)', '(fpn\\\\_.*)', '(rpn\\\\_.*)']\n",
      "layers regex : (mrcnn\\_.*)|(fpn\\_.*)|(rpn\\_.*)\n",
      "type train_dataset: <class 'mrcnn.newshapes.NewShapesDataset'>\n",
      "type val_dataset: <class 'mrcnn.newshapes.NewShapesDataset'>\n",
      "    learning rate :  0.0001\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "   0  input_image            (InputLayer          )   ............................no weights to train ]\n",
      "   1  zero_padding2d_1       (ZeroPadding2D       )   ............................no weights to train ]\n",
      "   2  conv1                  (Conv2D              )   ............................not a layer we want to train ]\n",
      "   3  bn_conv1               (BatchNorm           )   ............................not a layer we want to train ]\n",
      "   4  activation_1           (Activation          )   ............................no weights to train ]\n",
      "   5  max_pooling2d_1        (MaxPooling2D        )   ............................no weights to train ]\n",
      "   6  res2a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "   7  bn2a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "   8  activation_2           (Activation          )   ............................no weights to train ]\n",
      "   9  res2a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  10  bn2a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  11  activation_3           (Activation          )   ............................no weights to train ]\n",
      "  12  res2a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  13  res2a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  14  bn2a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  15  bn2a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  16  add_1                  (Add                 )   ............................no weights to train ]\n",
      "  17  res2a_out              (Activation          )   ............................no weights to train ]\n",
      "  18  res2b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  19  bn2b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  20  activation_4           (Activation          )   ............................no weights to train ]\n",
      "  21  res2b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  22  bn2b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  23  activation_5           (Activation          )   ............................no weights to train ]\n",
      "  24  res2b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  25  bn2b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  26  add_2                  (Add                 )   ............................no weights to train ]\n",
      "  27  res2b_out              (Activation          )   ............................no weights to train ]\n",
      "  28  res2c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  29  bn2c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  30  activation_6           (Activation          )   ............................no weights to train ]\n",
      "  31  res2c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  32  bn2c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  33  activation_7           (Activation          )   ............................no weights to train ]\n",
      "  34  res2c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  35  bn2c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  36  add_3                  (Add                 )   ............................no weights to train ]\n",
      "  37  res2c_out              (Activation          )   ............................no weights to train ]\n",
      "  38  res3a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  39  bn3a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  40  activation_8           (Activation          )   ............................no weights to train ]\n",
      "  41  res3a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  42  bn3a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  43  activation_9           (Activation          )   ............................no weights to train ]\n",
      "  44  res3a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  45  res3a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  46  bn3a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  47  bn3a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  48  add_4                  (Add                 )   ............................no weights to train ]\n",
      "  49  res3a_out              (Activation          )   ............................no weights to train ]\n",
      "  50  res3b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  51  bn3b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  52  activation_10          (Activation          )   ............................no weights to train ]\n",
      "  53  res3b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  54  bn3b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  55  activation_11          (Activation          )   ............................no weights to train ]\n",
      "  56  res3b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  57  bn3b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  58  add_5                  (Add                 )   ............................no weights to train ]\n",
      "  59  res3b_out              (Activation          )   ............................no weights to train ]\n",
      "  60  res3c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  61  bn3c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  62  activation_12          (Activation          )   ............................no weights to train ]\n",
      "  63  res3c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  64  bn3c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  65  activation_13          (Activation          )   ............................no weights to train ]\n",
      "  66  res3c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  67  bn3c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  68  add_6                  (Add                 )   ............................no weights to train ]\n",
      "  69  res3c_out              (Activation          )   ............................no weights to train ]\n",
      "  70  res3d_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  71  bn3d_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  72  activation_14          (Activation          )   ............................no weights to train ]\n",
      "  73  res3d_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  74  bn3d_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  75  activation_15          (Activation          )   ............................no weights to train ]\n",
      "  76  res3d_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  77  bn3d_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  78  add_7                  (Add                 )   ............................no weights to train ]\n",
      "  79  res3d_out              (Activation          )   ............................no weights to train ]\n",
      "  80  res4a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  81  bn4a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  82  activation_16          (Activation          )   ............................no weights to train ]\n",
      "  83  res4a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  84  bn4a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  85  activation_17          (Activation          )   ............................no weights to train ]\n",
      "  86  res4a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  87  res4a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  88  bn4a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  89  bn4a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  90  add_8                  (Add                 )   ............................no weights to train ]\n",
      "  91  res4a_out              (Activation          )   ............................no weights to train ]\n",
      "  92  res4b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  93  bn4b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  94  activation_18          (Activation          )   ............................no weights to train ]\n",
      "  95  res4b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  96  bn4b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  97  activation_19          (Activation          )   ............................no weights to train ]\n",
      "  98  res4b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  99  bn4b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 100  add_9                  (Add                 )   ............................no weights to train ]\n",
      " 101  res4b_out              (Activation          )   ............................no weights to train ]\n",
      " 102  res4c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 103  bn4c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 104  activation_20          (Activation          )   ............................no weights to train ]\n",
      " 105  res4c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 106  bn4c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 107  activation_21          (Activation          )   ............................no weights to train ]\n",
      " 108  res4c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 109  bn4c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 110  add_10                 (Add                 )   ............................no weights to train ]\n",
      " 111  res4c_out              (Activation          )   ............................no weights to train ]\n",
      " 112  res4d_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 113  bn4d_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 114  activation_22          (Activation          )   ............................no weights to train ]\n",
      " 115  res4d_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 116  bn4d_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 117  activation_23          (Activation          )   ............................no weights to train ]\n",
      " 118  res4d_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 119  bn4d_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 120  add_11                 (Add                 )   ............................no weights to train ]\n",
      " 121  res4d_out              (Activation          )   ............................no weights to train ]\n",
      " 122  res4e_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 123  bn4e_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 124  activation_24          (Activation          )   ............................no weights to train ]\n",
      " 125  res4e_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 126  bn4e_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 127  activation_25          (Activation          )   ............................no weights to train ]\n",
      " 128  res4e_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 129  bn4e_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 130  add_12                 (Add                 )   ............................no weights to train ]\n",
      " 131  res4e_out              (Activation          )   ............................no weights to train ]\n",
      " 132  res4f_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 133  bn4f_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 134  activation_26          (Activation          )   ............................no weights to train ]\n",
      " 135  res4f_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 136  bn4f_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 137  activation_27          (Activation          )   ............................no weights to train ]\n",
      " 138  res4f_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 139  bn4f_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 140  add_13                 (Add                 )   ............................no weights to train ]\n",
      " 141  res4f_out              (Activation          )   ............................no weights to train ]\n",
      " 142  res4g_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 143  bn4g_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 144  activation_28          (Activation          )   ............................no weights to train ]\n",
      " 145  res4g_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 146  bn4g_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 147  activation_29          (Activation          )   ............................no weights to train ]\n",
      " 148  res4g_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 149  bn4g_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 150  add_14                 (Add                 )   ............................no weights to train ]\n",
      " 151  res4g_out              (Activation          )   ............................no weights to train ]\n",
      " 152  res4h_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 153  bn4h_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 154  activation_30          (Activation          )   ............................no weights to train ]\n",
      " 155  res4h_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 156  bn4h_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 157  activation_31          (Activation          )   ............................no weights to train ]\n",
      " 158  res4h_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 159  bn4h_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 160  add_15                 (Add                 )   ............................no weights to train ]\n",
      " 161  res4h_out              (Activation          )   ............................no weights to train ]\n",
      " 162  res4i_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 163  bn4i_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 164  activation_32          (Activation          )   ............................no weights to train ]\n",
      " 165  res4i_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 166  bn4i_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 167  activation_33          (Activation          )   ............................no weights to train ]\n",
      " 168  res4i_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 169  bn4i_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 170  add_16                 (Add                 )   ............................no weights to train ]\n",
      " 171  res4i_out              (Activation          )   ............................no weights to train ]\n",
      " 172  res4j_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 173  bn4j_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 174  activation_34          (Activation          )   ............................no weights to train ]\n",
      " 175  res4j_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 176  bn4j_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 177  activation_35          (Activation          )   ............................no weights to train ]\n",
      " 178  res4j_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 179  bn4j_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 180  add_17                 (Add                 )   ............................no weights to train ]\n",
      " 181  res4j_out              (Activation          )   ............................no weights to train ]\n",
      " 182  res4k_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 183  bn4k_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 184  activation_36          (Activation          )   ............................no weights to train ]\n",
      " 185  res4k_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 186  bn4k_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 187  activation_37          (Activation          )   ............................no weights to train ]\n",
      " 188  res4k_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 189  bn4k_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 190  add_18                 (Add                 )   ............................no weights to train ]\n",
      " 191  res4k_out              (Activation          )   ............................no weights to train ]\n",
      " 192  res4l_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 193  bn4l_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 194  activation_38          (Activation          )   ............................no weights to train ]\n",
      " 195  res4l_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 196  bn4l_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 197  activation_39          (Activation          )   ............................no weights to train ]\n",
      " 198  res4l_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 199  bn4l_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 200  add_19                 (Add                 )   ............................no weights to train ]\n",
      " 201  res4l_out              (Activation          )   ............................no weights to train ]\n",
      " 202  res4m_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 203  bn4m_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 204  activation_40          (Activation          )   ............................no weights to train ]\n",
      " 205  res4m_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 206  bn4m_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 207  activation_41          (Activation          )   ............................no weights to train ]\n",
      " 208  res4m_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 209  bn4m_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 210  add_20                 (Add                 )   ............................no weights to train ]\n",
      " 211  res4m_out              (Activation          )   ............................no weights to train ]\n",
      " 212  res4n_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 213  bn4n_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 214  activation_42          (Activation          )   ............................no weights to train ]\n",
      " 215  res4n_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 216  bn4n_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 217  activation_43          (Activation          )   ............................no weights to train ]\n",
      " 218  res4n_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 219  bn4n_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 220  add_21                 (Add                 )   ............................no weights to train ]\n",
      " 221  res4n_out              (Activation          )   ............................no weights to train ]\n",
      " 222  res4o_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 223  bn4o_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 224  activation_44          (Activation          )   ............................no weights to train ]\n",
      " 225  res4o_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 226  bn4o_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 227  activation_45          (Activation          )   ............................no weights to train ]\n",
      " 228  res4o_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 229  bn4o_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 230  add_22                 (Add                 )   ............................no weights to train ]\n",
      " 231  res4o_out              (Activation          )   ............................no weights to train ]\n",
      " 232  res4p_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 233  bn4p_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 234  activation_46          (Activation          )   ............................no weights to train ]\n",
      " 235  res4p_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 236  bn4p_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 237  activation_47          (Activation          )   ............................no weights to train ]\n",
      " 238  res4p_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 239  bn4p_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 240  add_23                 (Add                 )   ............................no weights to train ]\n",
      " 241  res4p_out              (Activation          )   ............................no weights to train ]\n",
      " 242  res4q_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 243  bn4q_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 244  activation_48          (Activation          )   ............................no weights to train ]\n",
      " 245  res4q_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 246  bn4q_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 247  activation_49          (Activation          )   ............................no weights to train ]\n",
      " 248  res4q_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 249  bn4q_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 250  add_24                 (Add                 )   ............................no weights to train ]\n",
      " 251  res4q_out              (Activation          )   ............................no weights to train ]\n",
      " 252  res4r_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 253  bn4r_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 254  activation_50          (Activation          )   ............................no weights to train ]\n",
      " 255  res4r_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 256  bn4r_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 257  activation_51          (Activation          )   ............................no weights to train ]\n",
      " 258  res4r_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 259  bn4r_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 260  add_25                 (Add                 )   ............................no weights to train ]\n",
      " 261  res4r_out              (Activation          )   ............................no weights to train ]\n",
      " 262  res4s_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 263  bn4s_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 264  activation_52          (Activation          )   ............................no weights to train ]\n",
      " 265  res4s_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 266  bn4s_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 267  activation_53          (Activation          )   ............................no weights to train ]\n",
      " 268  res4s_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 269  bn4s_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 270  add_26                 (Add                 )   ............................no weights to train ]\n",
      " 271  res4s_out              (Activation          )   ............................no weights to train ]\n",
      " 272  res4t_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 273  bn4t_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 274  activation_54          (Activation          )   ............................no weights to train ]\n",
      " 275  res4t_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 276  bn4t_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 277  activation_55          (Activation          )   ............................no weights to train ]\n",
      " 278  res4t_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 279  bn4t_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 280  add_27                 (Add                 )   ............................no weights to train ]\n",
      " 281  res4t_out              (Activation          )   ............................no weights to train ]\n",
      " 282  res4u_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 283  bn4u_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 284  activation_56          (Activation          )   ............................no weights to train ]\n",
      " 285  res4u_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 286  bn4u_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 287  activation_57          (Activation          )   ............................no weights to train ]\n",
      " 288  res4u_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 289  bn4u_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 290  add_28                 (Add                 )   ............................no weights to train ]\n",
      " 291  res4u_out              (Activation          )   ............................no weights to train ]\n",
      " 292  res4v_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 293  bn4v_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 294  activation_58          (Activation          )   ............................no weights to train ]\n",
      " 295  res4v_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 296  bn4v_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 297  activation_59          (Activation          )   ............................no weights to train ]\n",
      " 298  res4v_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 299  bn4v_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 300  add_29                 (Add                 )   ............................no weights to train ]\n",
      " 301  res4v_out              (Activation          )   ............................no weights to train ]\n",
      " 302  res4w_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 303  bn4w_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 304  activation_60          (Activation          )   ............................no weights to train ]\n",
      " 305  res4w_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 306  bn4w_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 307  activation_61          (Activation          )   ............................no weights to train ]\n",
      " 308  res4w_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 309  bn4w_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 310  add_30                 (Add                 )   ............................no weights to train ]\n",
      " 311  res4w_out              (Activation          )   ............................no weights to train ]\n",
      " 312  res5a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 313  bn5a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 314  activation_62          (Activation          )   ............................no weights to train ]\n",
      " 315  res5a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 316  bn5a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 317  activation_63          (Activation          )   ............................no weights to train ]\n",
      " 318  res5a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 319  res5a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      " 320  bn5a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 321  bn5a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 322  add_31                 (Add                 )   ............................no weights to train ]\n",
      " 323  res5a_out              (Activation          )   ............................no weights to train ]\n",
      " 324  res5b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 325  bn5b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 326  activation_64          (Activation          )   ............................no weights to train ]\n",
      " 327  res5b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 328  bn5b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 329  activation_65          (Activation          )   ............................no weights to train ]\n",
      " 330  res5b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 331  bn5b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 332  add_32                 (Add                 )   ............................no weights to train ]\n",
      " 333  res5b_out              (Activation          )   ............................no weights to train ]\n",
      " 334  res5c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 335  bn5c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 336  activation_66          (Activation          )   ............................no weights to train ]\n",
      " 337  res5c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 338  bn5c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 339  activation_67          (Activation          )   ............................no weights to train ]\n",
      " 340  res5c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 341  bn5c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 342  add_33                 (Add                 )   ............................no weights to train ]\n",
      " 343  res5c_out              (Activation          )   ............................no weights to train ]\n",
      " 344  fpn_c5p5               (Conv2D              )   TRAIN \n",
      " 345  fpn_p5upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 346  fpn_c4p4               (Conv2D              )   TRAIN \n",
      " 347  fpn_p4add              (Add                 )   ............................no weights to train ]\n",
      " 348  fpn_p4upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 349  fpn_c3p3               (Conv2D              )   TRAIN \n",
      " 350  fpn_p3add              (Add                 )   ............................no weights to train ]\n",
      " 351  fpn_p3upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 352  fpn_c2p2               (Conv2D              )   TRAIN \n",
      " 353  fpn_p2add              (Add                 )   ............................no weights to train ]\n",
      " 354  fpn_p5                 (Conv2D              )   TRAIN \n",
      " 355  fpn_p2                 (Conv2D              )   TRAIN \n",
      " 356  fpn_p3                 (Conv2D              )   TRAIN \n",
      " 357  fpn_p4                 (Conv2D              )   TRAIN \n",
      " 358  fpn_p6                 (MaxPooling2D        )   ............................no weights to train ]\n",
      "Entering model layer:  rpn_model ------------------------------\n",
      "       0  input_rpn_feature_map   (InputLayer          )   ............................no weights to train ]\n",
      "       1  rpn_conv_shared        (Conv2D              )   TRAIN \n",
      "       2  rpn_class_raw          (Conv2D              )   TRAIN \n",
      "       3  lambda_1               (Lambda              )   ............................no weights to train ]\n",
      "       4  rpn_bbox_pred          (Conv2D              )   TRAIN \n",
      "       5  rpn_class_xxx          (Activation          )   ............................no weights to train ]\n",
      "       6  lambda_2               (Lambda              )   ............................no weights to train ]\n",
      "Exiting model layer  rpn_model --------------------------------\n",
      " 360  rpn_class              (Lambda              )   ............................no weights to train ]\n",
      " 361  rpn_bbox               (Lambda              )   ............................no weights to train ]\n",
      " 362  input_gt_boxes         (InputLayer          )   ............................no weights to train ]\n",
      " 363  ROI                    (ProposalLayer       )   ............................no weights to train ]\n",
      " 364  input_gt_class_ids     (InputLayer          )   ............................no weights to train ]\n",
      " 365  input_normalized_gt_boxes   (Lambda              )   ............................no weights to train ]\n",
      " 366  proposal_targets       (DetectionTargetLayer)   ............................no weights to train ]\n",
      " 367  roi_align_classifier   (PyramidROIAlign     )   ............................no weights to train ]\n",
      " 368  mrcnn_class_conv1      (TimeDistributed     )   TRAIN \n",
      " 369  mrcnn_class_bn1        (TimeDistributed     )   TRAIN \n",
      " 370  activation_68          (Activation          )   ............................no weights to train ]\n",
      " 371  mrcnn_class_conv2      (TimeDistributed     )   TRAIN \n",
      " 372  mrcnn_class_bn2        (TimeDistributed     )   TRAIN \n",
      " 373  activation_69          (Activation          )   ............................no weights to train ]\n",
      " 374  pool_squeeze           (Lambda              )   ............................no weights to train ]\n",
      " 375  mrcnn_class_logits     (TimeDistributed     )   TRAIN \n",
      " 376  mrcnn_logits_lambda    (Lambda              )   ............................no weights to train ]\n",
      " 377  mrcnn_bbox_fc          (TimeDistributed     )   TRAIN \n",
      " 378  mrcnn_class_act        (TimeDistributed     )   ............................no weights to train ]\n",
      " 379  mrcnn_bbox_rs          (Reshape             )   ............................no weights to train ]\n",
      " 380  input_image_meta       (InputLayer          )   ............................no weights to train ]\n",
      " 381  mrcnn_class_lambda     (Lambda              )   ............................no weights to train ]\n",
      " 382  mrcnn_bbox_lambda      (Lambda              )   ............................no weights to train ]\n",
      " 383  active_class_ids       (Lambda              )   ............................no weights to train ]\n",
      " 384  input_rpn_match        (InputLayer          )   ............................no weights to train ]\n",
      " 385  rpn_class_logits       (Lambda              )   ............................no weights to train ]\n",
      " 386  input_rpn_bbox         (InputLayer          )   ............................no weights to train ]\n",
      " 387  cntxt_layer            (CHMLayer            )   ............................no weights to train ]\n",
      " 388  cntxt_layer_gt         (CHMLayerTarget      )   ............................no weights to train ]\n",
      " 389  rpn_class_loss         (Lambda              )   ............................no weights to train ]\n",
      " 390  rpn_bbox_loss          (Lambda              )   ............................no weights to train ]\n",
      " 391  mrcnn_class_loss       (Lambda              )   ............................no weights to train ]\n",
      " 392  mrcnn_bbox_loss        (Lambda              )   ............................no weights to train ]\n",
      "    learning rate :  0.0001\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "\n",
      " Compile Model :\n",
      "----------------\n",
      "    losses        :  ['rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "    optimizer     :  <keras.optimizers.Adam object at 0x000000E687C72DD8>\n",
      "    learning rate :  0.0001\n",
      "    momentum      :  0.9\n",
      "\n",
      " Add losses:\n",
      "----------------\n",
      "    losses:  ['rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "    keras_model.losses           : []\n",
      "\n",
      "    Loss: rpn_class_loss  Related Layer is : rpn_class_loss\n",
      "      >> Add add loss for  Tensor(\"rpn_class_loss/rpn_class_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: rpn_bbox_loss  Related Layer is : rpn_bbox_loss\n",
      "      >> Add add loss for  Tensor(\"rpn_bbox_loss/rpn_bbox_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: mrcnn_class_loss  Related Layer is : mrcnn_class_loss\n",
      "      >> Add add loss for  Tensor(\"mrcnn_class_loss/mrcnn_class_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "    Loss: mrcnn_bbox_loss  Related Layer is : mrcnn_bbox_loss\n",
      "      >> Add add loss for  Tensor(\"mrcnn_bbox_loss/mrcnn_bbox_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "\n",
      "Keras model.losses : \n",
      "---------------------\n",
      "   Tensor(\"Mean:0\", shape=(1, 1), dtype=float32)    name: Mean:0\n",
      "   Tensor(\"Mean_2:0\", shape=(1, 1), dtype=float32)    name: Mean_2:0\n",
      "   Tensor(\"Mean_3:0\", shape=(1, 1), dtype=float32)    name: Mean_3:0\n",
      "   Tensor(\"Mean_1:0\", shape=(1, 1), dtype=float32)    name: Mean_1:0\n",
      "\n",
      "Keras_model._losses:\n",
      "---------------------\n",
      "   Tensor(\"Mean:0\", shape=(1, 1), dtype=float32)    name: Mean:0\n",
      "   Tensor(\"Mean_1:0\", shape=(1, 1), dtype=float32)    name: Mean_1:0\n",
      "   Tensor(\"Mean_2:0\", shape=(1, 1), dtype=float32)    name: Mean_2:0\n",
      "   Tensor(\"Mean_3:0\", shape=(1, 1), dtype=float32)    name: Mean_3:0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras_model._per_input_losses:\n",
      "------------------------------\n",
      "   None    name: <class 'NoneType'>\n",
      "{   None: [   <tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_1:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_2:0' shape=(1, 1) dtype=float32>,\n",
      "              <tf.Tensor 'Mean_3:0' shape=(1, 1) dtype=float32>]}\n",
      "\n",
      "L2 Regularization losses:\n",
      "-------------------------\n",
      "   Tensor(\"truediv:0\", shape=(), dtype=float32)    name: truediv:0\n",
      "   Tensor(\"truediv_1:0\", shape=(), dtype=float32)    name: truediv_1:0\n",
      "   Tensor(\"truediv_2:0\", shape=(), dtype=float32)    name: truediv_2:0\n",
      "   Tensor(\"truediv_3:0\", shape=(), dtype=float32)    name: truediv_3:0\n",
      "   Tensor(\"truediv_4:0\", shape=(), dtype=float32)    name: truediv_4:0\n",
      "   Tensor(\"truediv_5:0\", shape=(), dtype=float32)    name: truediv_5:0\n",
      "   Tensor(\"truediv_6:0\", shape=(), dtype=float32)    name: truediv_6:0\n",
      "   Tensor(\"truediv_7:0\", shape=(), dtype=float32)    name: truediv_7:0\n",
      "   Tensor(\"truediv_8:0\", shape=(), dtype=float32)    name: truediv_8:0\n",
      "   Tensor(\"truediv_9:0\", shape=(), dtype=float32)    name: truediv_9:0\n",
      "   Tensor(\"truediv_10:0\", shape=(), dtype=float32)    name: truediv_10:0\n",
      "   Tensor(\"truediv_11:0\", shape=(), dtype=float32)    name: truediv_11:0\n",
      "   Tensor(\"truediv_12:0\", shape=(), dtype=float32)    name: truediv_12:0\n",
      "   Tensor(\"truediv_13:0\", shape=(), dtype=float32)    name: truediv_13:0\n",
      "   Tensor(\"truediv_14:0\", shape=(), dtype=float32)    name: truediv_14:0\n",
      "   Tensor(\"truediv_15:0\", shape=(), dtype=float32)    name: truediv_15:0\n",
      "   Tensor(\"truediv_16:0\", shape=(), dtype=float32)    name: truediv_16:0\n",
      "   Tensor(\"truediv_17:0\", shape=(), dtype=float32)    name: truediv_17:0\n",
      "   Tensor(\"truediv_18:0\", shape=(), dtype=float32)    name: truediv_18:0\n",
      "   Tensor(\"truediv_19:0\", shape=(), dtype=float32)    name: truediv_19:0\n",
      "   Tensor(\"truediv_20:0\", shape=(), dtype=float32)    name: truediv_20:0\n",
      "   Tensor(\"truediv_21:0\", shape=(), dtype=float32)    name: truediv_21:0\n",
      "   Tensor(\"truediv_22:0\", shape=(), dtype=float32)    name: truediv_22:0\n",
      "   Tensor(\"truediv_23:0\", shape=(), dtype=float32)    name: truediv_23:0\n",
      "   Tensor(\"truediv_24:0\", shape=(), dtype=float32)    name: truediv_24:0\n",
      "   Tensor(\"truediv_25:0\", shape=(), dtype=float32)    name: truediv_25:0\n",
      "   Tensor(\"truediv_26:0\", shape=(), dtype=float32)    name: truediv_26:0\n",
      "   Tensor(\"truediv_27:0\", shape=(), dtype=float32)    name: truediv_27:0\n",
      "   Tensor(\"truediv_28:0\", shape=(), dtype=float32)    name: truediv_28:0\n",
      "   Tensor(\"truediv_29:0\", shape=(), dtype=float32)    name: truediv_29:0\n",
      "\n",
      "    Final list of keras_model.losses \n",
      "    -------------------------------- \n",
      "[   <tf.Tensor 'Mean:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_2:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'AddN:0' shape=() dtype=float32>,\n",
      "    <tf.Tensor 'Mean_3:0' shape=(1, 1) dtype=float32>,\n",
      "    <tf.Tensor 'Mean_1:0' shape=(1, 1) dtype=float32>]\n",
      "\n",
      " Length of Keras_Model.outputs: 16\n",
      "\n",
      " Add Metrics :\n",
      "--------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : rpn_class_loss  Related Layer is : rpn_class_loss\n",
      "      >> Add metric  rpn_class_loss  with metric tensor:  rpn_class_loss/rpn_class_loss:0  to list of metrics ...\n",
      "    Loss name : rpn_bbox_loss  Related Layer is : rpn_bbox_loss\n",
      "      >> Add metric  rpn_bbox_loss  with metric tensor:  rpn_bbox_loss/rpn_bbox_loss:0  to list of metrics ...\n",
      "    Loss name : mrcnn_class_loss  Related Layer is : mrcnn_class_loss\n",
      "      >> Add metric  mrcnn_class_loss  with metric tensor:  mrcnn_class_loss/mrcnn_class_loss:0  to list of metrics ...\n",
      "    Loss name : mrcnn_bbox_loss  Related Layer is : mrcnn_bbox_loss\n",
      "      >> Add metric  mrcnn_bbox_loss  with metric tensor:  mrcnn_bbox_loss/mrcnn_bbox_loss:0  to list of metrics ...\n",
      "\n",
      " Final Keras metric_names:\n",
      " -------------------------\n",
      "['loss', 'rpn_class_loss', 'rpn_bbox_loss', 'mrcnn_class_loss', 'mrcnn_bbox_loss']\n",
      "\n",
      "Starting at epoch   0 of 2 epochs. LR=0.0001\n",
      "\n",
      "Steps per epoch     100 \n",
      "Batch size          1 \n",
      "Checkpoint Path:    F:\\models\\train_mrcnn_newshapes\\mrcnn20181220T1849\\mrcnn_{epoch:04d}.h5 \n",
      "Learning Rate       0.0001 \n",
      "Momentum            0.9 \n",
      "Weight Decay:       0.0002 \n",
      "VALIDATION_STEPS    8 \n",
      "REDUCE_LR_FACTOR    0.5 \n",
      "REDUCE_LR_COOLDOWN  30 \n",
      "REDUCE_LR_PATIENCE  40 \n",
      "MIN_LR              1e-10 \n",
      "EARLY_STOP_PATIENCE 80 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " outputs:  5\n",
      "(1, 1) [[3.3907]]\n",
      "(1, 1) [[0.0849]]\n",
      "(1, 1) [[2.03]]\n",
      "(1, 1) [[0.3457]]\n",
      "(1, 1) [[0.9301]]\n",
      "  1/100 [..............................] - ETA: 14:22 - loss: 3.3907 - rpn_class_loss: 0.0849 - rpn_bbox_loss: 2.0300 - mrcnn_class_loss: 0.3457 - mrcnn_bbox_loss: 0.9301 outputs:  5\n",
      "(1, 1) [[4.9317]]\n",
      "(1, 1) [[0.2029]]\n",
      "(1, 1) [[1.9663]]\n",
      "(1, 1) [[0.7313]]\n",
      "(1, 1) [[2.0312]]\n",
      "  2/100 [..............................] - ETA: 10:44 - loss: 4.1612 - rpn_class_loss: 0.1439 - rpn_bbox_loss: 1.9982 - mrcnn_class_loss: 0.5385 - mrcnn_bbox_loss: 1.4806 outputs:  5\n",
      "(1, 1) [[2.5484]]\n",
      "(1, 1) [[0.1253]]\n",
      "(1, 1) [[1.1134]]\n",
      "(1, 1) [[0.333]]\n",
      "(1, 1) [[0.9767]]\n",
      "  3/100 [..............................] - ETA: 9:23 - loss: 3.6236 - rpn_class_loss: 0.1377 - rpn_bbox_loss: 1.7033 - mrcnn_class_loss: 0.4700 - mrcnn_bbox_loss: 1.3127 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-61ecc14294e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mepochs_to_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmrcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCHS_TO_RUN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             losses = loss_names)                  \n\u001b[0m",
      "\u001b[1;32mE:\\git_projs\\MRCNN3\\mrcnn\\model_mrcnn.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, layers, losses, epochs, epochs_to_run, batch_size, steps_per_epoch, min_lr, debug)\u001b[0m\n\u001b[0;32m    970\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m                                  \u001b[1;31m# max(self.config.BATCH_SIZE // 2, 2),\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m         )\n\u001b[0;32m    974\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1429\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1430\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1431\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' outputs: '\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mrcnn_model.epoch = mrcnn_model.config.LAST_EPOCH_RAN\n",
    "mrcnn_model.train(dataset_train, \n",
    "            dataset_val, \n",
    "            learning_rate = mrcnn_model.config.LEARNING_RATE, \n",
    "            epochs_to_run = mrcnn_model.config.EPOCHS_TO_RUN,\n",
    "            layers = train_layers,\n",
    "            losses = loss_names)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:52:16.029452Z",
     "start_time": "2018-12-20T17:52:15.689559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ <tf.Tensor 'input_image:0' shape=(?, 128, 128, 3) dtype=float32>,\n",
      "  <tf.Tensor 'input_image_meta:0' shape=(?, ?) dtype=float32>,\n",
      "  <tf.Tensor 'input_rpn_match:0' shape=(?, ?, 1) dtype=int32>,\n",
      "  <tf.Tensor 'input_rpn_bbox:0' shape=(?, ?, 4) dtype=float32>,\n",
      "  <tf.Tensor 'input_gt_class_ids:0' shape=(?, ?) dtype=int32>,\n",
      "  <tf.Tensor 'input_gt_boxes:0' shape=(?, ?, 4) dtype=float32>]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(mrcnn_model.keras_model._feed_inputs)\n",
    "pp.pprint(mrcnn_model.keras_model._feed_targets)\n",
    "pp.pprint(mrcnn_model.keras_model._feed_loss_fns)\n",
    "pp.pprint(mrcnn_model.keras_model._feed_outputs)\n",
    "pp.pprint(mrcnn_model.keras_model._feed_sample_weights)\n",
    "pp.pprint(mrcnn_model.keras_model.updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers\n",
    "\n",
    "    - #### Or now we can pass a list of layers we want to train in layers !\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "# model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE / 10, epochs=211, layers=\"all\")\n",
    "\n",
    "train_layers = [ 'all']   ## equivalent to \"heads\"\n",
    "loss_names   = [ \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "\n",
    "mrcnn_model.config.LAST_EPOCH_RAN = 122\n",
    "mrcnn_model.config.EPOCHS_TO_RUN  = 100\n",
    "mrcnn_model.config.LEARNING_RATE   = 0.001\n",
    "# mrcnn_model.config.STEPS_PER_EPOCH = config.STEPS_PER_EPOCH\n",
    "\n",
    "mrcnn_model.epoch = mrcnn_model.config.LAST_EPOCH_RAN\n",
    "mrcnn_model.train(dataset_train, \n",
    "            dataset_val, \n",
    "            learning_rate = mrcnn_model.config.LEARNING_RATE / 10, \n",
    "            epochs_to_run = mrcnn_model.config.EPOCHS_TO_RUN,\n",
    "            layers = train_layers,\n",
    "            losses = loss_names)                  \n",
    "#             epochs = 25,            # total number of epochs to run (accross multiple trainings)\n",
    "#             batch_size = 0\n",
    "#             steps_per_epoch = 0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T20:49:44.382272Z",
     "start_time": "2018-05-09T20:49:42.272401Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_2500.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot Heatmaps `pr_heatmap` and `gt_heatmap`\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:37:20.334041Z",
     "start_time": "2018-04-24T12:37:19.929956Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox[0:3,:])\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox[0:3])\n",
    "\n",
    "# image_id = img_meta[img,0]\n",
    "# print('Image id: ',image_id)\n",
    "# p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "#             load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# # print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "# print(p_gt_bbox)\n",
    "# print(p_gt_class_id)\n",
    "# visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_tensor` and `gt_tensor2`\n",
    "\n",
    "layers_out[22]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "layers_out[28]  `gt_tensor2` is based on input_gt_class_ids and input_normlzd_gt_boxes, generated using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:34:26.381655Z",
     "start_time": "2018-04-24T12:34:25.980564Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[22][img])\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[0:2,2:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Display RoI proposals `pred_bboxes` generated for one class\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:49:29.945015Z",
     "start_time": "2018-04-24T13:49:29.457701Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 1 # <==== Class to display\n",
    "pred_tensor = layers_out[19]   # numpy pred_tesnor\n",
    "# pred_tensor = layers_out[25]   # tensorflow pred_tensor \n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "print(p_image_meta)dd\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "print(pred_tensor[img,cls])\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "print(caps)\n",
    "\n",
    "visualize.draw_boxes(p_image, pred_tensor[img,cls,:,2:6], captions = caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:39:14.676360Z",
     "start_time": "2018-04-24T12:39:14.435714Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers_out[0][0] * [128, 128,128,128]   #output_rois*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Calculate  mrcnn_bbox_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:30:12.704056Z",
     "start_time": "2018-04-24T13:30:09.806418Z"
    },
    "hidden": true,
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "target_bbox      = layers_out[2][0:1]\n",
    "mrcnn_bbox       = layers_out[10][0:1]\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print('target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class with max probability', mrcnn_class_ids.shape)\n",
    "print(mrcnn_class_ids)\n",
    "print('target_bboxes', target_bbox.shape)\n",
    "# print(target_bbox)  # tgt_bounding boxes\n",
    "print('mrcnn_bboxes',mrcnn_bbox.shape)\n",
    "# print(mrcnn_bbox)  #mrcnn_bboxes\n",
    "pred_bbox = mrcnn_bbox\n",
    "\n",
    "# calc mrcnn_bbox_loss\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print(target_class_ids.shape)\n",
    "target_bbox      = K.reshape(target_bbox, (-1, 4))\n",
    "print('target_bboxx: ', target_bbox.shape)\n",
    "pred_bbox        = K.reshape(pred_bbox, (-1, pred_bbox.shape[2], 4))\n",
    "print('pred_bbox : ', pred_bbox.shape)\n",
    "\n",
    "positive_roi_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "print(positive_roi_ix.eval())\n",
    "positive_roi_class_ids = tf.cast( tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "print(positive_roi_class_ids.eval())\n",
    "indices                = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "print(target_bbox.eval())\n",
    "pred_bbox   = tf.gather_nd(pred_bbox, indices)\n",
    "print(pred_bbox.eval())\n",
    "\n",
    "print('tf.size ',tf.size(target_bbox).eval())\n",
    "\n",
    "diff = K.abs(target_bbox - pred_bbox)\n",
    "print(diff.eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(less_than_one.eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "\n",
    "\n",
    "# loss        = K.switch(tf.size(target_bbox) > 0,\n",
    "#                 smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "#                 tf.constant(0.0))\n",
    "print(loss.eval())\n",
    "sumloss = K.sum(loss)\n",
    "print(sumloss.eval())\n",
    "print((sumloss/40).eval())\n",
    "meanloss        = K.mean(loss)\n",
    "print(meanloss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Calculate mrcnn_class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:00:16.666089Z",
     "start_time": "2018-04-24T14:00:14.585712Z"
    },
    "hidden": true,
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "pred_class_logits = layers_out[8][0:1]\n",
    "active_class_ids    = np.array([1,1,1,1])\n",
    "\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print(' target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class logits', pred_class_logits.shape)\n",
    "print(pred_class_logits)\n",
    "print(' active, class_ids ', active_class_ids.shape)\n",
    "print(active_class_ids)  # tgt_bounding boxes\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "print(pred_class_ids.eval())  #mrcnn_bboxes\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print(mrcnn_class_ids)\n",
    "# pred_bbox = mrcnn_bbox\n",
    "pred_active = tf.to_float(tf.gather(active_class_ids, pred_class_ids))\n",
    "print(pred_active.eval())\n",
    "# calc mrcnn_bbox_loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "       labels=target_class_ids, logits=pred_class_logits)\n",
    "print(loss.eval())\n",
    "\n",
    "loss = loss * tf.to_float(pred_active)\n",
    "print(loss.eval())\n",
    "\n",
    "print(tf.reduce_sum(loss).eval())\n",
    "print(tf.reduce_sum(pred_active).eval())\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Calculate mrcnn_mask_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:30:39.761487Z",
     "start_time": "2018-04-24T14:30:35.393858Z"
    },
    "hidden": true,
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids    = layers_out[1][0:3]\n",
    "target_masks        = layers_out[3][0:3]\n",
    "pred_masks          = layers_out[11][0:3]\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print('    target_class_ids shape :', target_class_ids.shape)\n",
    "print('    target_masks     shape :', target_masks.shape)\n",
    "print('    pred_masks       shape :', pred_masks.shape)    \n",
    "\n",
    "\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print('    target_class_ids shape :', target_class_ids.shape, '\\n', target_class_ids.eval())\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', mask_shape.shape, mask_shape.eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', pred_shape.shape, pred_shape.eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3], pred_shape[4]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "\n",
    "pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "# Only positive ROIs contribute to the loss. And only\n",
    "# the class specific mask of each ROI.\n",
    "positive_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "positive_class_ids = tf.cast(tf.gather(target_class_ids, positive_ix), tf.int64)\n",
    "indices            = tf.stack([positive_ix, positive_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.gather(target_masks, positive_ix)\n",
    "print('     y_true shape:', tf.shape(y_true).eval())\n",
    "y_pred = tf.gather_nd(pred_masks, indices)\n",
    "print('     y_pred shape:', tf.shape(y_pred).eval())\n",
    "\n",
    "loss = K.switch(tf.size(y_true) > 0,\n",
    "                K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "                tf.constant(0.0))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "loss = K.mean(loss)\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Calculate a pixel loss on fcn_gaussian and gt_gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:03:44.110249Z",
     "start_time": "2018-04-24T15:03:38.231280Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "pred_masks          = layers_out[12][0:3]\n",
    "target_masks        = layers_out[27][0:3]\n",
    "\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())    \n",
    "\n",
    "diff = K.abs(target_masks - pred_masks)\n",
    "print(tf.shape(diff).eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "print(tf.shape(less_than_one).eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "# loss = K.switch(tf.size(y_true) > 0,\n",
    "#                 K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "#                 tf.constant(0.0))\n",
    "meanloss = K.mean(loss)\n",
    "print(tf.shape(meanloss).eval())\n",
    "print(meanloss.eval())\n",
    "# loss = K.reshape(loss, [1, 1])\n",
    "# print('     final loss shape:', loss.get_shape())\n",
    "# return loss\n",
    "\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', tf.shape(mask_shape).eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[1], mask_shape[2]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', tf.shape(pred_shape).eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[1], pred_shape[2]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())\n",
    "# Permute predicted masks to [N, num_classes, height, width]\n",
    "# diff = K.abs(target_masks - pred_masks)\n",
    "# print(tf.shape(diff).eval())\n",
    "\n",
    "# less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(tf.shape(less_than_one).eval())\n",
    "\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print(tf.shape(loss).eval())\n",
    "\n",
    "# meanloss = K.mean(loss)\n",
    "# print(tf.shape(meanloss).eval())\n",
    "# print(meanloss.eval())\n",
    "\n",
    "loss = K.switch(tf.size(target_masks) > 0,\n",
    "                smooth_l1_loss(y_true=target_masks, y_pred=pred_masks),\n",
    "                tf.constant(0.0))\n",
    "loss = K.mean(loss)\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', loss.get_shape())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Mean values of GT, Pred, and FCN heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:52:02.002508Z",
     "start_time": "2018-04-24T14:51:42.964543Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "pred_masks = tf.identity(layers_out[24])\n",
    "gt_masks = tf.identity(layers_out[27])\n",
    "fcn_masks = tf.identity(layers_out[12])\n",
    "print(gt_masks.shape, fcn_masks.shape)\n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        gt_mean = K.mean(gt_masks[img,:,:,cls])\n",
    "        fcn_mean= K.mean(fcn_masks[img,:,:,cls])\n",
    "        pred_mean= K.mean(pred_masks[img,:,:,cls])\n",
    "        print('Img/Cls: ', img, '/', cls,'    gtmean: ', gt_mean.eval(), '\\t fcn : ' , fcn_mean.eval(), '\\t pred :', pred_mean.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:52:37.323856Z",
     "start_time": "2018-04-24T12:52:37.052134Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img  = 0\n",
    "class_probs = layers_out[9][img]   # mrcnn_class\n",
    "deltas      = layers_out[10][img]       # mrcnn_bbox\n",
    "\n",
    "print(class_probs.shape)\n",
    "print('class probabilities')\n",
    "print(class_probs)\n",
    "class_ids = np.argmax(layers_out[9][img],axis = 1)     # mrcnn_class_ids\n",
    "print(' class with max probability')\n",
    "print(class_ids)\n",
    "\n",
    "\n",
    "# layers_out[10][2,0,3]\n",
    "print('deltas.shape :', deltas.shape)\n",
    "print(deltas[0:4])\n",
    "\n",
    "deltas_specific = deltas[np.arange(32),class_ids]\n",
    "print('deltas of max prob class: ', deltas_specific.shape)\n",
    "print(deltas_specific[0:5])\n",
    "output_rois = layers_out[0][img]*[128,128,128,128]\n",
    "print('output_rois: ', output_rois.shape)\n",
    "print(output_rois[0:])\n",
    "\n",
    "refined_rois    = apply_box_deltas(output_rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "print('refined rois: ',refined_rois.shape)\n",
    "print(refined_rois)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF]",
   "language": "python",
   "name": "conda-env-TF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
