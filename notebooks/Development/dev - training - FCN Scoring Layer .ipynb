{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Development of a score based on the gaussian heatmaps \n",
    "This can be used to generate the 'ground truth' score of the heatmaps produced from the Contextual layer , which will be compared with the score produced from the FCN heatmaps layer. \n",
    "\n",
    "- First we generate the heatmaps, and also visually cehck them. \n",
    "- the we pass the heatmaps to the routine that prodcues the scores \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build MRCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T10:38:48.199205Z",
     "start_time": "2019-02-11T10:38:40.469778Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import mrcnn.utils     as utils\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.visualize_2 as vis2 \n",
    "import mrcnn.prep_notebook as prep\n",
    "\n",
    "from mrcnn.visualize     import display_training_batch\n",
    "from mrcnn.newshapes     import prep_newshape_dataset\n",
    "from mrcnn.utils         import trim_zeros, compute_overlaps\n",
    "\n",
    "from datetime            import datetime   \n",
    "from mrcnn.utils         import command_line_parser, Paths\n",
    "from mrcnn.coco          import prep_coco_dataset\n",
    "from mrcnn.prep_notebook import build_fcn_training_pipeline,run_fcn_training_pipeline\n",
    "from mrcnn.datagen  import data_gen_simulate\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "float_formatter = lambda x: \"%10.4f\" % x\n",
    "np_format = {}\n",
    "np_format['float']=float_formatter\n",
    "# np.set_printoptions(linewidth=150, precision=3, floatmode='fixed', threshold =10000, formatter = np_format)  \n",
    "np.set_printoptions(linewidth=190, precision=4, threshold=10000, suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:16:00.064221Z",
     "start_time": "2018-12-12T10:14:38.223381Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "parser = command_line_parser()\n",
    "input_parms  =\" --batch_size 1 \"\n",
    "input_parms +=\" --epochs 2 \"\n",
    "input_parms +=\" --steps_in_epoch 32 \"\n",
    "input_parms +=\" --last_epoch 0 \"\n",
    "input_parms +=\" --lr 0.00001  \"\n",
    "input_parms +=\" --val_steps 8 \" \n",
    "input_parms +=\" --mrcnn_logs_dir train_mrcnn_coco \"\n",
    "input_parms +=\" --fcn_logs_dir   train_fcn8_coco_adam \"\n",
    "input_parms +=\" --mrcnn_model    last \"\n",
    "input_parms +=\" --fcn_model      F:/models/train_fcn8_coco_adam/fcn20181109T0000/fcn_1569.h5\"\n",
    "input_parms +=\" --opt            adagrad \"\n",
    "input_parms +=\" --fcn_arch       fcn8 \" \n",
    "input_parms +=\" --fcn_layers     all \" \n",
    "input_parms +=\" --sysout        screen \"\n",
    "# input_parms +=\" --coco_classes   62 63 67 78 79 80 81 82 72 73 74 75 76 77 \"\n",
    "input_parms +=\" --coco_classes   78 79 80 81 82 44 46 47 48 49 50 51 34 35 36 37 38 39 40 41 42 43 10 11 13 14 15 \"\n",
    "input_parms +=\" --new_log_folder    \"\n",
    "print(input_parms)\n",
    "\n",
    "args = parser.parse_args(input_parms.split())\n",
    "utils.display_input_parms(args)\n",
    "\n",
    "mrcnn_model, fcn_model = build_fcn_training_pipeline(args = args, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Training & Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:17:28.794989Z",
     "start_time": "2018-12-12T10:16:42.939467Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_class_ids = args.coco_classes\n",
    "print('load coco classes: ', load_class_ids)\n",
    "\n",
    "dataset_train, train_generator= prep_coco_dataset(['train', 'val35k'], fcn_model.config, generator = True,shuffle = False, load_coco_classes=load_class_ids)\n",
    "# dataset_val, val_generator    = prep_coco_dataset(['minival'], fcn_config, generator = True, shuffle = False)\n",
    "# dataset_test.display_class_info()\n",
    "dataset_train.display_active_class_info()\n",
    "print(\"Testing Dataset Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Testing Dataset Class Count: {}\".format(dataset_train.num_classes))\n",
    "class_names = dataset_train.class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Display image with Ground Truth bounding boxes and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:17:37.430070Z",
     "start_time": "2018-12-12T10:17:35.220662Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "visualize.display_training_batch(dataset_train, train_batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:17:43.555177Z",
     "start_time": "2018-12-12T10:17:43.171108Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMAGE_LIST = train_batch_x[1][:,0]\n",
    "print('IMAGE_LIST : ', IMAGE_LIST)\n",
    "for image_id in IMAGE_LIST:\n",
    "    print()\n",
    "    print('IMAGE_ID : ', image_id)#### Load a specific image using image_id\n",
    "    annotations = dataset_train.image_info[image_id][\"annotations\"]\n",
    "#     print(annotations)\n",
    "    for annotation in annotations:\n",
    "        class_id = dataset_train.map_source_class_id( \"coco.{}\".format(annotation['category_id']))\n",
    "        print(\"coco.id: {} --> class_id : {}  - {} \".format(annotation['category_id'],class_id, dataset_train.class_names[class_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a specific image using image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:17:49.249140Z",
     "start_time": "2018-12-12T10:17:47.234625Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, _ =  data_gen_simulate(dataset_train, mrcnn_model.config, [7143]) ## [1234])\n",
    "visualize.display_training_batch(dataset_train, train_batch_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass data through MRCNN-FCN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `run_mrcnn_training_pipeline()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:18:54.183417Z",
     "start_time": "2018-12-12T10:17:53.086186Z"
    }
   },
   "outputs": [],
   "source": [
    "from mrcnn.prep_notebook import run_full_training_pipeline, run_mrcnn_training_pipeline, run_fcn_training_pipeline   ###run_pipeline_on_input\n",
    "outputs = run_full_training_pipeline(mrcnn_model, fcn_model, dataset_train, train_batch_x, verbose= 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:19:17.940033Z",
     "start_time": "2018-12-12T10:19:17.522616Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(outputs), outputs.keys())\n",
    "model_pr_heatmap                = outputs['mrcnn_output'][0]          # layer:  0   shape: (1, 256, 256, 81)\n",
    "model_pr_heatmap_scores         = outputs['mrcnn_output'][1]          # layer:  1   shape: (1, 81, 200, 11)\n",
    "model_gt_heatmap                = outputs['mrcnn_output'][2]          # layer:  2   shape: (1, 256, 256, 81)\n",
    "model_gt_heatmap_scores         = outputs['mrcnn_output'][3]          # layer:  3   shape: (1, 81, 200, 11)\n",
    "model_mrcnn_class               = outputs['mrcnn_output'][4]\n",
    "model_mrcnn_bbox                = outputs['mrcnn_output'][5]\n",
    "model_output_rois               = outputs['mrcnn_output'][6]\n",
    "model_target_class_ids          = outputs['mrcnn_output'][7]\n",
    "model_roi_gt_boxes              = outputs['mrcnn_output'][8]\n",
    "\n",
    "model_fcn_heatmap               = outputs['fcn_output'][0]          # layer:  0   shape: (1, 256, 256, 81)\n",
    "model_fcn_softmax               = outputs['fcn_output'][1]          # layer:  1   shape: ()\n",
    "model_MSE_loss                  = outputs['fcn_output'][2]          # layer:  1   shape: ()\n",
    "model_BCE_loss                  = outputs['fcn_output'][3]          # layer:  1   shape: ()\n",
    "model_fcn_scores                = outputs['fcn_output'][4]\n",
    "\n",
    "print('model_pr_heatmap       : ', model_gt_heatmap.shape)\n",
    "print('model_pr_heatmap_scores: ', model_gt_heatmap_scores.shape)\n",
    "print('model_gt_heatmap       : ', model_gt_heatmap.shape)\n",
    "print('model_gt_heatmap_scores: ', model_gt_heatmap_scores.shape)\n",
    "print('model_fcn_heatmap      : ', model_fcn_heatmap.shape)\n",
    "print('model_fcn_softmax      : ', model_fcn_softmax.shape)\n",
    "print('model_fcn_scores       : ', model_fcn_scores.shape)\n",
    "print('model_CE_loss          : ', model_BCE_loss)\n",
    "print('model_MSE_loss         : ', model_MSE_loss)\n",
    "\n",
    "img_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Display output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:19:22.254461Z",
     "start_time": "2018-12-12T10:19:21.881529Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(outputs['image_batch'].shape)\n",
    "for i in outputs:\n",
    "    print('Group:', i)\n",
    "    for item in outputs[i]:\n",
    "        print(' Type ', type(item), item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:19:27.796115Z",
     "start_time": "2018-12-12T10:19:27.394965Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_image      =  train_batch_x[0]\n",
    "# input_image_meta =  train_batch_x[1]\n",
    "# # input_rpn_match  =  train_batch_x[2]\n",
    "# # input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = outputs['mrcnn_input'][4]\n",
    "# # input_gt_bboxes    = train_batch_x[5]\n",
    "# # input_gt_masks     = train_batch_x[6]\n",
    "# print(' Input image shape is :', input_image.shape)\n",
    "# h, w = input_image.shape[1], input_image.shape[2]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "# input_normlzd_gt_bboxes = tf.identity(input_gt_bboxes / [h,w,h,w])\n",
    "\n",
    "# # gt_masks   =  train_batch_x[6]\n",
    "# print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "# print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(input_gt_class_ids)\n",
    "# print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n",
    "# print(' input_normlzd_gt_bboxes    ', input_normlzd_gt_bboxes.shape)\n",
    "# print(input_image_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display values from FCN Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:19:35.054331Z",
     "start_time": "2018-12-12T10:19:34.669438Z"
    }
   },
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%10.3f\" % x\n",
    "np_format = {}\n",
    "np_format['float']=float_formatter\n",
    "np.set_printoptions(linewidth=150, precision=3, floatmode='fixed', threshold =10000, formatter = np_format)\n",
    "\n",
    "gt_class_ids = np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('Image : {}  ClassIds: {}'.format(img_id, gt_class_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:50:56.702117Z",
     "start_time": "2018-11-25T20:50:56.327168Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.bincount(model_gt_heatmap_scores[img_id,:,:,4])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Display heatmap stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:19:38.366387Z",
     "start_time": "2018-12-12T10:19:37.268436Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "gt_class_ids = np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "pr_class_ids = np.unique(model_pr_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "fcn_class_ids = np.unique(model_fcn_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('Image : {}  GT ClassIds: {}'.format(img_id, gt_class_ids))\n",
    "print('Image : {}  PR ClassIds: {}'.format(img_id, pr_class_ids))\n",
    "print('Image : {}  FCN ClassIds: {}'.format(img_id, fcn_class_ids))\n",
    "# for i in range(pr_class_ids[-1]+1):\n",
    "for i in range(81):\n",
    "    print('class:', i, '-', dataset_train.class_names[i],'predicted in MRCNN' if i in pr_class_ids else ' ' , ' (Ground Truth) ' if  i in gt_class_ids else ' ')\n",
    "    print('FCN class: {:3d}   min: {:12.8f}    max: {:12.8f}    avg: {:12.8f}    sum: {:12.8f} '.format(i, np.min(model_fcn_heatmap[img_id,:,:,i]), \n",
    "                                                                    np.max(model_fcn_heatmap[img_id,:,:,i]), np.mean(model_fcn_heatmap[img_id,:,:,i]), \n",
    "                                                                    np.sum(model_fcn_heatmap[img_id,:,:,i])))\n",
    "    print('PR  class: {:3d}   min: {:12.8f}    max: {:12.8f}    avg: {:12.8f}    sum: {:12.8f} '.format(i, np.min(model_pr_heatmap[img_id,:,:,i]), \n",
    "                                                                    np.max(model_pr_heatmap[img_id,:,:,i]),  np.mean(model_pr_heatmap[img_id,:,:,i]),\n",
    "                                                                    np.sum(model_pr_heatmap[img_id,:,:,i])))\n",
    "    print('GT  class: {:3d}   min: {:12.8f}    max: {:12.8f}    avg: {:12.8f}    sum: {:12.8f} '.format(i, np.min(model_gt_heatmap[img_id,:,:,i]), \n",
    "                                                                    np.max(model_gt_heatmap[img_id,:,:,i]),  np.mean(model_gt_heatmap[img_id,:,:,i]),\n",
    "                                                                    np.sum(model_gt_heatmap[img_id,:,:,i])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  display fcn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:07:11.749229Z",
     "start_time": "2018-12-11T19:07:11.382951Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=190, precision=4, threshold=10000, suppress = True)\n",
    "print('Image : {}  PR ClassIds: {}'.format(img_id, pr_class_ids))\n",
    "print('Image : {}  fcn ClassIds: {}'.format(img_id, fcn_class_ids))\n",
    "print(model_fcn_scores.shape)\n",
    "for i in  fcn_class_ids:\n",
    "    print('\\nclass:', i, '-', dataset_train.class_names[i],' - predicted in MRCNN' if i in pr_class_ids else ' ' , ' - (Ground Truth) ' if  i in gt_class_ids else ' ')\n",
    "    print(model_fcn_scores[img_id,i, :25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T11:49:02.443285Z",
     "start_time": "2018-11-16T11:49:02.123879Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(model_pr_heatmap_scores.shape)\n",
    "print(model_fcn_scores[0,0:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T16:50:14.662228Z",
     "start_time": "2018-11-29T16:50:14.337975Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print(model_fcn_heatmap[0,i,:,4])\n",
    "#     print(np.min(model_fcn_heatmap[0,i,:,1]), np.max(model_fcn_heatmap[0,i,:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  `Pred_Tensor`, `Pred_heatmap`, `mrcnn_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T09:45:42.436974Z",
     "start_time": "2018-05-22T09:45:42.182291Z"
    },
    "hidden": true,
    "hideCode": true,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=210, suppress=True)\n",
    "img = 0\n",
    "\n",
    "# print(KB.int_shape(output_rois))\n",
    "# print(output_rois[img,:15]*[128, 128,128,128])\n",
    "# print(input_gt_class_ids[0])\n",
    "\n",
    "# print(' Pred_tensor')\n",
    "# print(pred_tensor.shape)\n",
    "# print(pred_tensor[img,:,:10])\n",
    "\n",
    "# print(' gt_tensor')\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[img,:,:10])\n",
    "\n",
    "# print(' output_rois')\n",
    "# print(output_rois.shape)\n",
    "# print(output_rois[img,:15] * [128, 128,128,128])\n",
    "\n",
    "\n",
    "# print(' roi_gt_boxes')\n",
    "# print(roi_gt_boxes.shape)\n",
    "# print(roi_gt_boxes[img,:15] * [128, 128,128,128])\n",
    "\n",
    "print(' Pred Heatmap Scores')\n",
    "print(pred_heatmap_scores.dtype)\n",
    "\n",
    "\n",
    "print(' FCN Scores')\n",
    "print(fcn_scores.dtype)\n",
    "for cls in range(4):\n",
    "    print(pred_heatmap_scores[img,cls,:10])\n",
    "    print(fcn_scores[img,cls,:10,2:])\n",
    "\n",
    "# img = 2\n",
    "# max_score = np.max(mrcnn_class, axis = -1)\n",
    "# max_class = np.argmax(mrcnn_class, axis = -1)\n",
    "# # print(' output_rois[',img,'] \\n', output_rois[1]*[128,128,128,128])\n",
    "# print('max class shape:',max_class.shape, 'max score shape: ',max_score.shape)\n",
    "# print('max class[',img,']\\n',max_class[img])\n",
    "# print('max score[',img,']\\n',max_score[img])\n",
    "# print('mrcnn class.shape ',mrcnn_class.shape)\n",
    "# print('mrcnn_class[',img,',:]\\n',mrcnn_class[img,:])\n",
    "# print(output_rois[1])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display `output_rois` for visual check - passed on to  `build_pred_tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T20:45:16.040038Z",
     "start_time": "2018-05-21T20:45:15.807401Z"
    },
    "hidden": true,
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('output_rois shape is ', output_rois.shape)\n",
    "img = 0\n",
    "for img in range(5):\n",
    "    print('Image ', img , ' ------------')\n",
    "    print(output_rois[img]*[128,128,128,128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "####  Display for visual check - `pred_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T20:46:05.173284Z",
     "start_time": "2018-05-21T20:46:04.920073Z"
    },
    "hidden": true,
    "hideCode": true,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_tensor shape is ', pred_tensor.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(pred_tensor[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "####  Display for visual check - `gt_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T20:31:43.625908Z",
     "start_time": "2018-05-17T20:31:43.364212Z"
    },
    "hidden": true,
    "hideCode": true,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "print('gt_tensor shape is ', gt_tensor.shape)\n",
    "img = 1\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(gt_tensor[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `pred_heatmap_scores` is the final result which is passed from  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T21:14:28.370605Z",
     "start_time": "2018-05-21T21:14:28.095876Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6, suppress=True)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_heatmap_scores shape is ', pred_heatmap_scores.shape)\n",
    "for img in [0,1,2]:\n",
    "    for k in range(4):\n",
    "        print('Image ', img , '/ Class ',k,' ------------')\n",
    "        print(np.min(pred_heatmap_scores[img,k,:,8]))\n",
    "        print(pred_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "####  `GT_HEATMAP_SCORES` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T16:21:22.761774Z",
     "start_time": "2018-11-13T16:21:22.398394Z"
    },
    "hidden": true,
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print('gt_heatmap_scores shape is ', model_gt_heatmap_scores.shape)\n",
    "img_id = 0\n",
    "gt_class_ids = np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('Image : {}  GT ClassIds: {}'.format(img_id, gt_class_ids))\n",
    "\n",
    "for cls in gt_class_ids:\n",
    "    print('\\nImage ', img_id , '/ Class ',cls,' ------------')\n",
    "    for box in range(model_gt_heatmap_scores.shape[2]):\n",
    "        print(model_gt_heatmap_scores[img_id,cls, box])\n",
    "        if (np.all(model_gt_heatmap_scores[img_id,cls, box, :4] == 0)):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "#### `PRED_HEATMAP_SCORES` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:16:57.847511Z",
     "start_time": "2018-12-11T19:16:57.371156Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np_format = {}\n",
    "float_formatter = lambda x: \"%10.4f\" % x\n",
    "int_formatter   = lambda x: \"%10d\" % x\n",
    "np_format['float'] = float_formatter\n",
    "np_format['int']   = int_formatter\n",
    "np.set_printoptions(linewidth=195, precision=4, floatmode='fixed', threshold =10000, formatter = np_format)\n",
    "print('pred_heatmap_scores shape is ', model_pr_heatmap_scores.shape)\n",
    "img_id = 0\n",
    "pr_class_ids = np.unique(model_pr_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('Image : {}  GT ClassIds: {}'.format(img_id, pr_class_ids))\n",
    "\n",
    "for cls in pr_class_ids:\n",
    "    print('\\nImage ', img_id , '/ Class ',cls,' ------------')\n",
    "    for box in range(model_pr_heatmap_scores.shape[2]):       \n",
    "        print(model_pr_heatmap_scores[img_id,cls, box, :8])\n",
    "        print('{:>86s} {}'.format(' fcn old style scores:  ', model_pr_heatmap_scores[img_id,cls, box,[8,9,10]]))\n",
    "        print('{:>86s} {}'.format(' fcn alt scores1:  ',model_pr_heatmap_scores[img_id,cls, box,[11,12,13,14,15,16]]))\n",
    "        print('{:>86s} {}'.format(' fcn_scores2:  '    ,model_pr_heatmap_scores[img_id,cls, box,[17,18,19,20,21,22]]))\n",
    "        print()        \n",
    "        if (np.all(model_pr_heatmap_scores[img_id,cls, box, :4] == 0)):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "####  `gt_heatmap_scores`  and `fcn_heatmap_scores` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T10:25:25.611236Z",
     "start_time": "2018-12-12T10:25:25.068100Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np_format = {}\n",
    "float_formatter = lambda x: \"%10.4f\" % x\n",
    "int_formatter   = lambda x: \"%10d\" % x\n",
    "np_format['float'] = float_formatter\n",
    "np_format['int']   = int_formatter\n",
    "np.set_printoptions(linewidth=195, precision=4, floatmode='fixed', threshold =10000, formatter = np_format)\n",
    "print('fcn_heatmap_scores shape is ', model_fcn_scores.shape)\n",
    "img_id = 0\n",
    "pr_class_ids = np.unique(model_fcn_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('Image : {}  GT ClassIds: {}'.format(img_id, pr_class_ids))\n",
    "\n",
    "for cls in pr_class_ids:\n",
    "    print('\\nImage ', img_id , '/ Class ',cls,' ------------')\n",
    "    for box in range(model_fcn_scores.shape[2]):       \n",
    "        print(model_fcn_scores[img_id,cls, box, :8])\n",
    "        print('{:>86s} {}'.format(' fcn old style scores:  ', model_fcn_scores[img_id,cls, box,[8,9,10]]))\n",
    "        print('{:>86s} {}'.format(' fcn alt scores1:  ',model_fcn_scores[img_id,cls, box,[11,12,13,14,15,16]]))\n",
    "        print('{:>86s} {}'.format(' fcn_scores2:  '    ,model_fcn_scores[img_id,cls, box,[17,18,19,20,21,22]]))\n",
    "        print()        \n",
    "        if (np.all(model_fcn_scores[img_id,cls, box, :4] == 0)):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### `pred_heatmap_norm` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T20:55:58.752564Z",
     "start_time": "2018-05-21T20:55:58.464796Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(pred_heatmap_norm.shape)\n",
    "temp = pred_heatmap_norm\n",
    "np.set_printoptions(linewidth=150, threshold=10000, suppress=False)\n",
    "print('  Temp shape :',  temp.shape)\n",
    "temp_sum = np.sum(temp,axis=(1,2))\n",
    "print('temp_sum is ', temp_sum.shape)\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        print('img ',i,' class ', j, ' sum:',temp_sum[i,j],  ' max: ',np.max(temp[i,:,:,j]),' mean: ', np.mean(temp[i,:,:,j]),' min: ', np.min(temp[i,:,:,j]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "####  `fcn_heatmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T20:56:07.906104Z",
     "start_time": "2018-05-21T20:56:07.641900Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000, suppress=False)\n",
    "temp = fcn_heatmap_norm\n",
    "print('  Temp shape :',  temp.shape)\n",
    "temp_sum = np.sum(temp,axis=(1,2))\n",
    "print('temp_sum is ', temp_sum.shape)\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        print('img ',i,' class ', j, ' sum:',temp_sum[i,j],  ' max: ',np.max(temp[i,:,:,j]),' mean: ', np.mean(temp[i,:,:,j]),' min: ', np.min(temp[i,:,:,j]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T21:09:58.924538Z",
     "start_time": "2018-05-21T21:09:58.670388Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000, suppress=False)\n",
    "temp = fcn_heatmap\n",
    "print('  Temp shape :',  temp.shape)\n",
    "temp_sum = np.sum(temp,axis=(1,2))\n",
    "print('temp_sum is ', temp_sum.shape)\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        print('img ',i,' class ', j, ' sum:',temp_sum[i,j],  ' max: ',np.max(temp[i,:,:,j]),' mean: ', np.mean(temp[i,:,:,j]),' min: ', np.min(temp[i,:,:,j]))    \n",
    "\n",
    "\n",
    "# sess = KB.get_session()\n",
    "# with sess.as_default():\n",
    "#     temp = tf.identity(fcn_heatmap\n",
    "#     np.set_printoptions(linewidth=150, threshold=10000)\n",
    "#     print('  output shapes :',  temp.get_shape())\n",
    "#     temp_sum = tf.reduce_sum(temp, [2,3])\n",
    "#     temp_min = tf.reduce_min(temp, [2,3])\n",
    "#     temp_max = tf.reduce_max(temp, [2,3])\n",
    "#     temp_avg = tf.reduce_mean(temp, [2,3])\n",
    "#     print('temp_sum is ', temp_sum.shape)\n",
    "#     for i in range(5):\n",
    "#         for j in range(4):\n",
    "#                 print('img/cls ',i,'/', j,'  sum:',temp_sum[i,j], 'min',temp_min[i,j] ,'max',temp_max[i,j] ,'avg',temp_avg[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T21:12:55.147060Z",
     "start_time": "2018-05-21T21:12:53.450743Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000, precision = 6,suppress=False)\n",
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "    tmp = tf.identity(fcn_heatmap)\n",
    "    print(tf.shape(tmp).eval())\n",
    "    reduce_max = tf.reduce_max(tmp,axis = [1,2], keepdims=True)\n",
    "    print(tf.shape(reduce_max).eval())\n",
    "    reduce_min = tf.reduce_min(tmp, axis = [1,2], keepdims=True)\n",
    "    print(tf.shape(reduce_min).eval())\n",
    "    print(reduce_min.eval())\n",
    "    print(reduce_max.eval())\n",
    "    y  =  (tmp - reduce_min) / (reduce_max - reduce_min)        \n",
    "    print(tf.shape(y).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Display Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:20:36.613386Z",
     "start_time": "2018-12-11T19:20:36.240122Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import (plot_one_bbox_heatmap, \n",
    "                             plot_3d_heatmap, plot_2d_heatmap, \n",
    "                              plot_2d_heatmap_compare, plot_3d_heatmap_compare)\n",
    "# import matplotlib as plt\n",
    "# %matplotlib inline\n",
    "img_id = 0\n",
    "image_id=outputs['mrcnn_input'][1][img_id,0]\n",
    "print('Image id: ',image_id, ' Coco ID: ', dataset_train.image_info[image_id]['id'])\n",
    "\n",
    "coco_class_names = dataset_train.class_names\n",
    "gt_class_ids = np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "pr_class_ids = np.unique(model_pr_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "fcn_class_ids = np.unique(model_fcn_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('GT   class ids: ', gt_class_ids)\n",
    "print('Pred class ids: ', pr_class_ids)\n",
    "print('FCN  class ids: ', fcn_class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2D Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2D plot of `model_gt_heatmap` returned from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:21:04.125885Z",
     "start_time": "2018-12-11T19:21:02.666834Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Image : {}  ClassIds: {}'.format(img_id, gt_class_ids))\n",
    "plot_2d_heatmap(model_gt_heatmap, model_gt_heatmap_scores, img_id, gt_class_ids, \n",
    "                 class_names = coco_class_names, columns = 3, scale = 4, scaling = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2D plot of `model_fcn_heatmap` returned from model (with Ground Truth Bounding Boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:21:32.773170Z",
     "start_time": "2018-12-11T19:21:31.181044Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Image : {}  ClassIds: {}'.format(img_id, gt_class_ids))\n",
    "visualize.plot_2d_heatmap(model_fcn_heatmap, model_gt_heatmap_scores,img_id, gt_class_ids, columns = 3,\n",
    "                             class_names = coco_class_names, scale = 4, scaling = 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2D plot of `model_fcn_heatmap` returned from model (with MRCNN PREDICTED Bounding Boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T16:39:52.489025Z",
     "start_time": "2018-11-25T16:39:51.271812Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(model_fcn_heatmap.shape)\n",
    "print('Image : {}  ClassIds: {}'.format(img_id, pr_class_ids))\n",
    "fig  = visualize.plot_2d_heatmap(model_fcn_heatmap, model_pr_heatmap_scores,img_id, pr_class_ids, columns = 3,\n",
    "                             class_names = coco_class_names, scale = 4, scaling = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  2D plot of `model_fcn_heatmap` returned from model - ALL CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T16:40:56.209036Z",
     "start_time": "2018-11-25T16:40:36.263470Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    class_ids = np.unique(model_pr_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  Pred ClassIds: {}'.format(img_id, class_ids))\n",
    "    print('            Gt   ClassIds: {}'.format(np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()))\n",
    "#     plot_2d_heatmap_with_bboxes(model_fcn_heatmap[...,:class_ids[-1]+1], model_gt_heatmap_scores, img_id, \n",
    "#                                 class_ids, class_names = class_names, columns = 2, scale = 4)\n",
    "    fig = plot_2d_heatmap(model_fcn_heatmap, model_pr_heatmap_scores, img_id,\n",
    "                                class_names = coco_class_names, columns = 4, scale = 4, scaling = 'all')\n",
    "#     fig.savefig('fcn_heatmaps_2d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2D plot of `pred_heatmap_norm` returned from MRCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T13:21:36.529484Z",
     "start_time": "2018-11-16T13:21:22.955664Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Image : {}  ClassIds: {}'.format(img_id, pr_class_ids))\n",
    "plot_2d_heatmap(model_pr_heatmap, model_pr_heatmap_scores, img_id, pr_class_ids, \n",
    "                            class_names = coco_class_names, size = (7,7), scale = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2D comparative display `pred_heatmap` / `fcn_heatmap`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T16:55:17.612800Z",
     "start_time": "2018-11-25T16:55:15.578354Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    class_ids = np.unique(model_pr_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "#     class_ids = list(range(30))\n",
    "    plot_2d_heatmap_compare(model_pr_heatmap, model_fcn_heatmap, model_pr_heatmap_scores, \n",
    "                            img_id, class_ids = class_ids, class_names = coco_class_names, scale = 4, scaling = 'class' )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Overlay predictions on image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Overlay image with gt_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T20:02:49.922290Z",
     "start_time": "2018-11-12T20:02:46.533514Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import display_heatmaps, display_heatmaps_fcn, display_heatmaps_mrcnn\n",
    "# visualize.display_image_bw(image)\n",
    "print(model_gt_heatmap_scores.shape)\n",
    "class_ids = np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('class ids: ', class_ids)\n",
    "display_heatmaps_mrcnn(train_batch_x, model_output, 0, hm = 'gt',\n",
    "                     config = mrcnn_config, class_ids = class_ids, class_names = coco_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Overlay image with pred_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T20:02:38.615907Z",
     "start_time": "2018-11-12T20:02:35.034819Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import display_heatmaps, display_heatmaps_fcn, display_heatmaps_mrcnn\n",
    "# visualize.display_image_bw(image)\n",
    "print(model_gt_heatmap_scores.shape)\n",
    "class_ids = np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('class ids: ', class_ids)\n",
    "display_heatmaps_mrcnn(train_batch_x, model_output, 0, hm = 'pr',  \n",
    "                     config = mrcnn_config, class_ids = class_ids, class_names = coco_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Overlay image with fcn_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:07:33.047984Z",
     "start_time": "2018-11-25T17:07:32.719748Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize.display_heatmaps_mrcnn_fcn(outputs['mrcnn_input'], outputs['mrcnn_output'], 0, heatmap = model_fcn_heatmap, hm = 'pr', columns = 3,\n",
    "#                      class_ids = gt_class_ids, \n",
    "#                                      config = mrcnn_model.config, class_names = coco_class_names, scaling = 'clip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Overlay image with gt_heatmaps and fcn_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:03:54.363950Z",
     "start_time": "2018-11-25T17:03:50.712720Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize.display_heatmaps_compare(outputs['mrcnn_input'], outputs['mrcnn_output'], heatmap = model_fcn_heatmap, image_id = 0, \n",
    "                                   hm = 'pr', config = mrcnn_model.config, class_ids = gt_class_ids, class_names = coco_class_names, scaling = 'each')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Overlay image with pr_heatmaps and fcn_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:04:15.236239Z",
     "start_time": "2018-11-25T17:04:10.539076Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize.display_heatmaps_compare(outputs['mrcnn_input'], outputs['mrcnn_output'], heatmap = model_fcn_heatmap, image_id = 0, hm = 'pr', \n",
    "                     config = mrcnn_model.config, class_ids = pr_class_ids, class_names = coco_class_names, scaling = 'each')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  3D Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D plot of  `gt_heatmap_norm` returned form code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T20:04:07.641872Z",
     "start_time": "2018-11-12T20:04:07.308343Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ## range(mrcnn_config.BATCH_SIZE):\n",
    "    print(model_gt_heatmap.shape)\n",
    "    class_ids = np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(model_gt_heatmap, img_id, class_ids, class_names = coco_class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D plot of `pred_heatmap_norm` returned form model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T20:04:31.458052Z",
     "start_time": "2018-11-12T20:04:26.328523Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(model_pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(model_pred_heatmap_norm, img_id, class_ids, class_names = coco_class_names, zlim = 'all' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  3D plot of `fcn_heatmap` returned form model - classes predicted by MRCNN only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T18:57:20.474820Z",
     "start_time": "2018-11-29T18:57:20.103230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(np.max(model_fcn_heatmap), np.min(model_fcn_heatmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T20:37:09.075461Z",
     "start_time": "2018-11-12T20:37:03.706045Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(model_fcn_heatmap.shape)\n",
    "    class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(model_fcn_heatmap, img_id, class_ids,class_names = coco_class_names, zlim = 'one',scaling = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  3D plot of `fcn_softmax` returned form model - only classes in pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T12:20:25.796835Z",
     "start_time": "2018-11-11T12:20:18.840473Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(model_fcn_heatmap.shape)\n",
    "    class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(model_fcn_softmax, img_id, class_ids,class_names = coco_class_names, scaling = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D plot of `fcn_heatmap` returned form model - all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T12:27:01.327992Z",
     "start_time": "2018-11-05T12:25:46.068250Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "#     plot_3d_heatmap(model_fcn_heatmap, img_id, class_ids,class_names = class_names, size = (8,8), zlim=0)\n",
    "#     plot_3d_heatmap_all_classes(model_fcn_heatmap[...,:class_ids[-1]+1], img_id, class_names = class_names, size = (8,8), zlim=0.0)\n",
    "    plot_3d_heatmap(model_fcn_heatmap, img_id, class_names = class_names, columns = 2,scaling = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D comparative display `pred_heatmap` / `fcn_heatmap` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:30:30.174183Z",
     "start_time": "2018-11-05T13:29:36.585211Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(model_pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    class_ids.append(1)\n",
    "    class_ids = list(range(30))\n",
    "#     print(class_ids)\n",
    "    plot_3d_heatmap_compare(model_pred_heatmap_norm,model_fcn_heatmap, img_id, class_ids = class_ids, \n",
    "                            class_names = class_names, size=(8,8), zlim = 'all' , scaling = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D comparative display `gt_heatmap` / `fcn_heatmap` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:04:56.630705Z",
     "start_time": "2018-11-01T11:04:40.766628Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    class_ids = np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    class_ids.extend([1,2])\n",
    "    print(class_ids)\n",
    "    print(type(class_ids))\n",
    "    class_ids.sort()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap_compare(model_gt_heatmap,model_fcn_heatmap, img_id, class_ids, class_names = class_names, size=(8,8), zlim = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  FCN Scoring - `FCNScoringLayer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Display shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T13:14:48.128024Z",
     "start_time": "2018-11-30T13:14:47.769566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(model_gt_heatmap.shape)\n",
    "print(model_gt_heatmap_scores.shape)\n",
    "print(model_pr_heatmap.shape)\n",
    "print(model_pr_heatmap_scores.shape)\n",
    "print(model_fcn_heatmap.shape)\n",
    "print(model_fcn_softmax.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `normalize()`  - `build_fcn_score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop `score_fcn_heatmaps()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T16:08:15.809423Z",
     "start_time": "2018-11-30T16:08:12.948401Z"
    },
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##--------------------------------------------------------------------------\n",
    "## setup input values\n",
    "# in_tensor = tf.placeholder(tf.float32, shape=[3,4,32,6], name = 'in_tensor')\n",
    "# gt_scores  = tf.identity(model_gt_heatmap_scores)\n",
    "fcn_hm        = tf.identity(model_fcn_heatmap)\n",
    "pr_hm_scores  = tf.identity(model_pr_heatmap_scores)\n",
    "in_heatmap    = tf.identity(model_fcn_heatmap)\n",
    "# config = fcn_model.config\n",
    "# self   = fcn_model\n",
    "# names = ['Dev']\n",
    "\n",
    "fcn_heatmap_scores   = fcn_scoring_graph([fcn_hm , pr_hm_scores], fcn_model.config) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `fcn_scoring_graph()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.chm_layer import build_hm_score_v2, build_hm_score_v3, normalize_scores\n",
    "from mrcnn.utils import logt\n",
    "#     def fcn_scoring_graph(input, config, mode):\n",
    "\n",
    "# in_heatmap, pr_scores = input\n",
    "rois_per_image        = KB.int_shape(pr_scores)[2] \n",
    "img_h, img_w          = config.IMAGE_SHAPE[:2]\n",
    "batch_size            = config.BATCH_SIZE\n",
    "num_classes           = config.NUM_CLASSES  \n",
    "heatmap_scale         = config.HEATMAP_SCALE_FACTOR\n",
    "verbose               = config.VERBOSE\n",
    "CLASS_COLUMN          = 4\n",
    "SCORE_COLUMN          = 5\n",
    "DT_TYPE_COLUMN        = 6\n",
    "SEQUENCE_COLUMN       = 7\n",
    "NORM_SCORE_COLUMN     = 8\n",
    "# if mode == 'training':\n",
    "    # SEQUENCE_COLUMN       = 6\n",
    "    # NORM_SCORE_COLUMN     = 7\n",
    "# else:\n",
    "    # DT_TYPE_COLUMN        = 6\n",
    "    # SEQUENCE_COLUMN       = 7\n",
    "    # NORM_SCORE_COLUMN     = 8\n",
    "\n",
    "print('\\n ')\n",
    "print('---------------------------------------------')\n",
    "print('>>> FCN Scoring Graph  - mode:', mode)\n",
    "print('---------------------------------------------')\n",
    "logt('in_heatmap.shape  ', in_heatmap, verbose = verbose)\n",
    "logt('pr_hm_scores.shape', pr_scores, verbose = verbose )\n",
    "# rois per image is determined by size of input tensor \n",
    "#   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "#   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "logt('pr_scores shape ', pr_scores, verbose = verbose)\n",
    "logt('rois_per_image  ', rois_per_image , verbose = verbose)\n",
    "logt('config.DETECTION_MAX_INSTANCES ', config.DETECTION_MAX_INSTANCES, verbose = verbose)\n",
    "logt('config.DETECTIONS_PER_CLASS    ', config.DETECTION_PER_CLASS, verbose = verbose)\n",
    "logt('SEQUENCE_COLUMN                ', SEQUENCE_COLUMN, verbose = verbose)\n",
    "logt('NORM_SCORE_COLUMN              ', NORM_SCORE_COLUMN, verbose = verbose)\n",
    "\n",
    "##---------------------------------------------------------------------------------------------\n",
    "## Stack non_zero bboxes from PR_SCORES into pt2_dense \n",
    "##---------------------------------------------------------------------------------------------\n",
    "# pt2_ind shape  : [?, 3] : [ {image_index, class_index , roi row_index }]\n",
    "# pt2_dense shape: [?, 11] : \n",
    "#    pt2_dense[0:3]  roi coordinates \n",
    "#    pt2_dense[4]    is class id \n",
    "#    pt2_dense[5]    is score from mrcnn    \n",
    "#    pt2_dense[6]    is bbox sequence id    \n",
    "#    pt2_dense[7]    is normalized score (per class)    \n",
    "#-----------------------------------------------------------------------------\n",
    "pt2_sum = tf.reduce_sum(tf.abs(pr_scores[:,:,:,:CLASS_COLUMN]), axis=-1)\n",
    "pt2_ind = tf.where(pt2_sum > 0)\n",
    "pt2_dense = tf.gather_nd(pr_scores, pt2_ind)\n",
    "logt('in_heatmap       ', in_heatmap, verbose = verbose)\n",
    "logt('pr_scores.shape  ', pr_scores , verbose = verbose)\n",
    "logt('pt2_sum shape    ', pt2_sum   , verbose = verbose)\n",
    "logt('pt2_ind shape    ', pt2_ind   , verbose = verbose)\n",
    "logt('pt2_dense shape  ', pt2_dense , verbose = verbose)\n",
    "\n",
    "\n",
    "##---------------------------------------------------------------------------------------------\n",
    "##  Build mean and convariance tensors for bounding boxes\n",
    "##---------------------------------------------------------------------------------------------\n",
    "# bboxes_scaled = tf.to_int32(tf.round(pt2_dense[...,0:4])) / heatmap_scale\n",
    "bboxes_scaled = pt2_dense[...,0:CLASS_COLUMN] / heatmap_scale\n",
    "width  = bboxes_scaled[:,3] - bboxes_scaled[:,1]      # x2 - x1\n",
    "height = bboxes_scaled[:,2] - bboxes_scaled[:,0]\n",
    "cx     = bboxes_scaled[:,1] + ( width  / 2.0)\n",
    "cy     = bboxes_scaled[:,0] + ( height / 2.0)\n",
    "# means  = tf.stack((cx,cy),axis = -1)\n",
    "covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "covar  = tf.sqrt(covar)            \n",
    "\n",
    "\n",
    "##---------------------------------------------------------------------------------------------\n",
    "##  build indices and extract heatmaps corresponding to each bounding boxes' class id\n",
    "##---------------------------------------------------------------------------------------------\n",
    "hm_indices = tf.cast(pt2_ind[:, :2],dtype=tf.int32)\n",
    "logt('hm_indices  ',  hm_indices, verbose = verbose)\n",
    "\n",
    "pt2_heatmaps = tf.transpose(in_heatmap, [0,3,1,2])\n",
    "logt('pt2_heatmaps',  pt2_heatmaps, verbose = verbose)\n",
    "\n",
    "pt2_heatmaps = tf.gather_nd(pt2_heatmaps, hm_indices )\n",
    "logt('pt2_heatmaps',  pt2_heatmaps, verbose = verbose)\n",
    "\n",
    "##--------------------------------------------------------------------------------------------\n",
    "## (0) Generate scores using prob_grid and pt2_dense\n",
    "##--------------------------------------------------------------------------------------------\n",
    "old_style_scores = tf.map_fn(build_hm_score_v2, [pt2_heatmaps, bboxes_scaled, pt2_dense[:, NORM_SCORE_COLUMN]], \n",
    "                             dtype = tf.float32, swap_memory = True)\n",
    "logt('old_style_scores',  old_style_scores, verbose = verbose)                      \n",
    "\n",
    "# old_style_scores = tf.scatter_nd(pt2_ind, old_style_scores, \n",
    "                                 # [batch_size, num_classes, rois_per_image, KB.int_shape(old_style_scores)[-1]],\n",
    "                                 # name = 'scores_scattered')\n",
    "# print('    old_style_scores        :',  old_style_scores.get_shape(), KB.int_shape(old_style_scores))                                 \n",
    "\n",
    "##---------------------------------------------------------------------------------------------\n",
    "## generate score based on gaussian using bounding box masks \n",
    "##---------------------------------------------------------------------------------------------\n",
    "alt_scores_1 = tf.map_fn(build_hm_score_v3, [pt2_heatmaps, cy, cx,covar], dtype=tf.float32)    \n",
    "logt('alt_scores_1 ', alt_scores_1 , verbose = verbose)\n",
    "\n",
    "##---------------------------------------------------------------------------------------------\n",
    "##  Scatter back to per-class tensor /  normalize by class\n",
    "##---------------------------------------------------------------------------------------------\n",
    "alt_scores_1_norm = tf.scatter_nd(pt2_ind, alt_scores_1, \n",
    "                                [batch_size, num_classes, rois_per_image, KB.int_shape(alt_scores_1)[-1]],\n",
    "                                name='alt_scores_1_norm')\n",
    "logt('alt_scores_1_scattered', alt_scores_1_norm, verbose = verbose)\n",
    "\n",
    "alt_scores_1_norm = normalize_scores(alt_scores_1_norm)\n",
    "logt('alt_scores_1_norm(by_class)', alt_scores_1_norm, verbose = verbose)\n",
    "\n",
    "alt_scores_1_norm = tf.gather_nd(alt_scores_1_norm, pt2_ind)\n",
    "logt('alt_scores_1_norm(by_image)', alt_scores_1_norm, verbose = verbose)\n",
    "\n",
    "##---------------------------------------------------------------------------------------------\n",
    "## Normalize input heatmap normalization (per class) to calculate alt_score_2\n",
    "##--------------------------------------------------------------------------------------------\n",
    "logt('Normalize heatmap within each class !-------------------------------------', verbose = verbose)         \n",
    "in_heatmap_norm = tf.transpose(in_heatmap, [0,3,1,2])\n",
    "\n",
    "logt('in_heatmap_norm  ', in_heatmap_norm, verbose = verbose)\n",
    "## normalize in class\n",
    "normalizer = tf.reduce_max(in_heatmap_norm, axis=[-2,-1], keepdims = True)\n",
    "normalizer = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "in_heatmap_norm = in_heatmap_norm / normalizer\n",
    "\n",
    "# gauss_heatmap_sum_normalized = gauss_heatmap_sum / normalizer\n",
    "logt('normalizer shape ', normalizer, verbose = verbose)   \n",
    "logt('normalized heatmap  ', in_heatmap_norm, verbose = verbose)\n",
    "\n",
    "##---------------------------------------------------------------------------------------------\n",
    "##  build indices and extract heatmaps corresponding to each bounding boxes' class id\n",
    "##  build alternative scores#  based on normalized/sclaked clipped heatmap\n",
    "##---------------------------------------------------------------------------------------------\n",
    "hm_indices = tf.cast(pt2_ind[:, :2],dtype=tf.int32)\n",
    "logt('hm_indices shape',  hm_indices, verbose = verbose)\n",
    "\n",
    "pt2_heatmaps = tf.gather_nd(in_heatmap_norm, hm_indices )\n",
    "logt('pt2_heatmaps',  pt2_heatmaps, verbose = verbose)\n",
    "\n",
    "alt_scores_2 = tf.map_fn(build_hm_score_v3, [pt2_heatmaps, cy, cx,covar], dtype=tf.float32)    \n",
    "logt('alt_scores_2',alt_scores_2, verbose = verbose)\n",
    "\n",
    "alt_scores_2_norm = tf.scatter_nd(pt2_ind, alt_scores_2, \n",
    "                                 [batch_size, num_classes, rois_per_image, KB.int_shape(alt_scores_2)[-1]], name = 'alt_scores_2')  \n",
    "logt('alt_scores_2(scattered)', alt_scores_2_norm , verbose = verbose)\n",
    "\n",
    "alt_scores_2_norm = normalize_scores(alt_scores_2_norm)\n",
    "logt('alt_scores_2_norm(by_class)', alt_scores_2_norm, verbose = verbose)\n",
    "\n",
    "alt_scores_2_norm = tf.gather_nd(alt_scores_2_norm, pt2_ind)\n",
    "logt('alt_scores_2_norm(by_image)', alt_scores_2_norm, verbose = verbose)\n",
    "\n",
    "\n",
    "##--------------------------------------------------------------------------------------------\n",
    "##  Append alt_scores_1, alt_scores_1_norm to yield fcn_scores_dense \n",
    "##--------------------------------------------------------------------------------------------\n",
    "fcn_scores_dense = tf.concat([pt2_dense[:, : NORM_SCORE_COLUMN+1], old_style_scores, alt_scores_1, alt_scores_1_norm, alt_scores_2, alt_scores_2_norm], \n",
    "                              axis = -1, name = 'fcn_scores_dense')\n",
    "logt('fcn_scores_dense    ', fcn_scores_dense , verbose = verbose)\n",
    "\n",
    "##---------------------------------------------------------------------------------------------\n",
    "##  Scatter back to per-image tensor \n",
    "##---------------------------------------------------------------------------------------------\n",
    "seq_ids = tf.to_int32( rois_per_image - pt2_dense[:, SEQUENCE_COLUMN] )\n",
    "scatter_ind= tf.stack([hm_indices[:,0], seq_ids], axis = -1, name = 'scatter_ind')\n",
    "fcn_scores_by_class = tf.scatter_nd(pt2_ind, fcn_scores_dense, \n",
    "                                    [batch_size, num_classes, rois_per_image, fcn_scores_dense.shape[-1]], name='fcn_hm_scores')\n",
    "# fcn_scores_by_image = tf.scatter_nd(scatter_ind, fcn_scores_dense, \n",
    "                                    # [batch_size, rois_per_image, fcn_scores_dense.shape[-1]], name='fcn_hm_scores_by_image')\n",
    "logt('seq_ids             ', seq_ids, verbose = verbose)\n",
    "logt('sscatter_ids        ', scatter_ind, verbose = verbose)\n",
    "logt('fcn_scores_by_class ', fcn_scores_by_class, verbose = verbose)\n",
    "# logt('fcn_scores_by_image ', fcn_scores_by_image) \n",
    "logt('complete', verbose = verbose)\n",
    "\n",
    "    return fcn_scores_by_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### evaluate various nodes from computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T16:15:32.197258Z",
     "start_time": "2018-11-30T16:15:27.612600Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "with sess.as_default():   \n",
    "#     r_cy = cy.eval()\n",
    "#     r_cx = cx.eval()\n",
    "#     r_covar = covar.eval()\n",
    "#     r_pt2_sum = pt2_sum.eval()\n",
    "#     r_pt2_ind = pt2_ind.eval()\n",
    "#     r_pt2_dense = pt2_dense.eval()\n",
    "#     r_scores = scores.eval()\n",
    "#     r_both_scores = both_scores.eval()\n",
    "#     r_normalizer = normalizer.eval()\n",
    "#     r_scores_norm = scores_norm.eval()print(r_normalizer)\n",
    "#     r_fcn_scores = fcn_scores.eval()\n",
    "#     r_Padding = Padding.eval()\n",
    "#     r_scatter_ind = scatter_ind.eval()\n",
    "#     r_map_output = map_output.eval()\n",
    "#     r_fcn_scores_dense = fcn_scores_dense.eval()    \n",
    "#     r_in_heatmap_norm = in_heatmap_norm.eval()\n",
    "#     r_fcn_scores = fcn_scores.eval()\n",
    "    r_fcn_heatmap_scores = fcn_heatmap_scores.eval()    \n",
    "\n",
    "#     r_in_heatmap  = model_fcn_heatmap\n",
    "#     r_pt2_hm_reshape = pt2_hm_reshape.eval()    \n",
    "#     r_hm_indices = hm_indices.eval()\n",
    "#     r_pt2_heatmaps = pt2_heatmaps.eval()\n",
    "#     r_pt2_hm_reshape = pt2_hm_reshape.eval()\n",
    "#     r_hm_indices = hm_indices.eval()\n",
    "#     r_pt2_heatmaps = pt2_heatmaps.eval()\n",
    "# print(r_pt2_sum.shape)\n",
    "# print(r_pt2_ind.shape)\n",
    "# print(r_pt2_dense.shape)\n",
    "# print(r_pt2_heatmaps.shape)\n",
    "\n",
    "# print(pr_hm_scores.shape)\n",
    "# print(r_fcn_scores.shape)\n",
    "# print(r_in_heatmap_norm.shape)\n",
    "print(r_fcn_heatmap_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display evaluated items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T16:15:37.922534Z",
     "start_time": "2018-11-30T16:15:37.610312Z"
    }
   },
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%9.4f\" % x\n",
    "np_format = {}\n",
    "np_format['float']=float_formatter\n",
    "np.set_printoptions(linewidth=200, precision=3, floatmode='fixed', threshold =10000, formatter = np_format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T16:15:38.818873Z",
     "start_time": "2018-11-30T16:15:38.513069Z"
    }
   },
   "outputs": [],
   "source": [
    "  \n",
    "# print(model_pr_heatmap_scores[0,0,:50])\n",
    "print('Image ids: ', outputs['mrcnn_input'][1][:,0])\n",
    "# print(' pt2_dense  :', r_pt2_dense.shape)\n",
    "# print(r_pt2_dense)\n",
    "img_id = 0\n",
    "gt_class_ids = np.unique(model_gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "pr_class_ids = np.unique(model_pr_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "fcn_class_ids = np.unique(r_fcn_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('Image : {}  GT ClassIds: {}'.format(img_id, gt_class_ids))\n",
    "print('Image : {}  PR ClassIds: {}'.format(img_id, pr_class_ids))\n",
    "print('Image : {}  FCN ClassIds: {}'.format(img_id, fcn_class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T13:21:51.725960Z",
     "start_time": "2018-11-30T13:21:51.414843Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # print(model_pr_heatmap_scores[0,1,:10])\n",
    "# for i in range(r_pt2_dense.shape[0]):\n",
    "#     print(i,r_pt2_dense[i,[4,5,6]], np.sum(r_pt2_heatmaps[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### display cx,cy,covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T19:20:24.898485Z",
     "start_time": "2018-11-26T19:20:22.993131Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(' cx / cy/ covar:', r_cy.shape, r_cy.shape, r_covar.shape)\n",
    "# r_xy = np.stack([r_cx,r_cy, ], axis = 1 )\n",
    "# r_xy_covar = np.concatenate([r_xy, r_covar, r_map_output], axis = 1)\n",
    "# print(r_cx[12], r_cy[12], r_covar[12,:])\n",
    "\n",
    "# print('\\n map_output')\n",
    "# print(r_map_output[:20])\n",
    "\n",
    "# print('\\n r_xy_covar')\n",
    "# print(r_xy_covar[:60])\n",
    "\n",
    "# print('fcn_scores_dense')\n",
    "# print(r_fcn_scores_dense)\n",
    "# print(r_xy_covar)\n",
    "#     print('    hm_indices :',  r_hm_indices.shape, r_hm_indices.ndim)\n",
    "#     print(r_hm_indices)\n",
    "#     print('    pt2_heatmaps.shape: ',r_pt2_heatmaps.shape)\n",
    "# print(' pt2_ind  : ', r_pt2_ind.shape)    \n",
    "# print(r_pt2_ind)    \n",
    "# print(r_scores_norm.shape)\n",
    "# print(r_scores_norm)    \n",
    " \n",
    "# print(' fcn_scores_dense : ', r_fcn_scores_dense.shape)\n",
    "# print(r_fcn_scores_dense)\n",
    "# print(' fcn_scores_by_image :', r_fcn_scores_by_image.shape)\n",
    "# print(r_fcn_scores_by_image[0,:,4:-4])\n",
    "print()\n",
    "# print(r_fcn_scores_by_class[img_id,pr_class_ids,:20,:-8])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T16:15:52.852063Z",
     "start_time": "2018-11-30T16:15:52.493765Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%9.4f\" % x\n",
    "np_format = {}\n",
    "np_format['float']=float_formatter\n",
    "np.set_printoptions(linewidth=190, precision=3, floatmode='fixed', threshold =10000, formatter = np_format)\n",
    "img_id = 0\n",
    "print('Image : {}  PR ClassIds: {}'.format(img_id, pr_class_ids))\n",
    "print('Image : {}  fcn ClassIds: {}'.format(img_id, fcn_class_ids))\n",
    "print(model_fcn_scores.shape)\n",
    "print(model_pr_heatmap_scores.shape)\n",
    "for i in  fcn_class_ids:\n",
    "    if i == 0 :\n",
    "        continue\n",
    "    print()\n",
    "    print('class:', i, '-', dataset_train.class_names[i],'predicted in MRCNN' if i in pr_class_ids else ' ' , ' (Ground Truth) ' if  i in gt_class_ids else ' ')\n",
    "    for j in range(200):\n",
    "        print(model_pr_heatmap_scores[img_id, i, j, [4,5,6,7, 11,12,13, 14,15,16, 17,18,19, 20,21,22]])\n",
    "        print(  r_fcn_heatmap_scores[img_id, i, j,  [4,5,6,7, 11,12,13, 14,15,16, 17,18,19, 20,21,22]])\n",
    "\n",
    "        print()\n",
    "        if (np.all( r_fcn_heatmap_scores[img_id,i,j,:4] == 0)):\n",
    "            break        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:07:41.821198Z",
     "start_time": "2018-11-30T15:07:41.374183Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_id = 0 \n",
    "for i in  pr_class_ids:\n",
    "    if i == 0 :\n",
    "        continue\n",
    "    print()\n",
    "    print('class:', i, '-', dataset_train.class_names[i],'predicted in MRCNN' if i in pr_class_ids else ' ' , ' (Ground Truth) ' if  i in gt_class_ids else ' ')\n",
    "    for j in range(200):\n",
    "#         print('{:>86s} {}  '.format('PR bbox :  ',  r_pr_heatmap_scores[img_id, i,j,:4]))        \n",
    "        print('{:>86s} {}          {}'.format('class, score, seqIid, norm_score:  ',  model_pr_heatmap_scores[img_id, i,j,[4,6]],model_pr_heatmap_scores[img_id, i,j,[5,7]]))\n",
    "#         print('{:>86s} {}'.format(' model_pr old style_scores:  ',model_pr_heatmap_scores[img_id, i,j,[8,9,10]]))\n",
    "#         print('{:>86s} {}'.format(' fcn old style_scores:  ',  r_fcn_heatmap_scores[img_id, i,j,[8,9,10]]))\n",
    "        print('{:>86s} {}'.format(' model_pr alt_scores_1:  ', model_pr_heatmap_scores[img_id, i,j,11:14]))\n",
    "        print('{:>86s} {}'.format(' model_pr alt_scores_1 normalized:  ', model_pr_heatmap_scores[img_id, i,j, 14:17]))\n",
    "        print('{:>86s} {}'.format(' model_pr alt_scores_2:  ',model_pr_heatmap_scores[img_id, i,j, 17:20]))\n",
    "        print('{:>86s} {}'.format(' model_pr alt_scores_2 normalized:  ',model_pr_heatmap_scores[img_id, i,j,20:23]))\n",
    "        print()\n",
    "        print('{:>86s} {}'.format(' fcn alt_scores_1:  '     , r_fcn_heatmap_scores[img_id, i,j,11:14]))\n",
    "        print('{:>86s} {}'.format(' fcn alt_scores_1 normalized:  '     , r_fcn_heatmap_scores[img_id, i,j,14:17]))    \n",
    "        print('{:>86s} {}'.format(' fcn alt_scores_2:  ',r_fcn_heatmap_scores[img_id, i,j,17:20]))\n",
    "        print('{:>86s} {}'.format(' fcn alt_scores_2 normalized:  ',r_fcn_heatmap_scores[img_id, i,j,20:23]))        \n",
    "        print()\n",
    "        \n",
    "        \n",
    "#         print('{:>86s} {}  '.format('gt bbox :  ',  r_gt_heatmap_scores[img_id, i,j,:4]))\n",
    "#         print('{:>86s} {}  '.format('gt class, score, seqIid, norm_score:  ',  r_gt_heatmap_scores[img_id, i,j,[4,5,6,7]]))\n",
    "#         print('{:>86s} {}'.format(' gt old style_scores:  ',model_gt_heatmap_scores[img_id, i,j,[8,9,10]]))\n",
    "#         print('{:>86s} {}'.format(' gt old style_scores:  ', r_gt_heatmap_scores[img_id, i,j,[8,9,10]]))\n",
    "#         print('{:>86s} {}'.format(' model gt alt_scores_1:  ',model_gt_heatmap_scores[img_id, i,j,[11,12,13,14,15]]))\n",
    "#         print('{:>86s} {}'.format(' gt alt_scores_1:  ',r_gt_heatmap_scores[img_id, i,j,[11,12,13,14,15]]))\n",
    "#         print('{:>86s} {}'.format(' model gt alt_scores_1 normalized:  ',model_gt_heatmap_scores[img_id, i,j,[16,17,18,19,20]]))\n",
    "#         print('{:>86s} {}'.format(' gt alt_scores_1 normalized:  ',r_gt_heatmap_scores[img_id, i,j,[16,17,18,19,20]]))\n",
    "#         print('{:>86s} {}'.format(' model gt alt_scores_2::  ',model_gt_heatmap_scores[img_id, i,j, 21:26]))\n",
    "#         print('{:>86s} {}'.format(' gt alt_scores_2:  ',r_gt_heatmap_scores[img_id, i,j,21:26]))\n",
    "#         print('{:>86s} {}'.format(' model gt alt_scores_2 normalized:  ',model_gt_heatmap_scores[img_id, i,j,26:31]))\n",
    "#         print('{:>86s} {}'.format(' gt alt_scores_2 normalized:  ',r_gt_heatmap_scores[img_id, i,j,26:31]))        \n",
    "        print()\n",
    "        if (np.all( r_fcn_heatmap_scores[img_id,i,j,:4] == 0)):\n",
    "            print('break')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T14:16:51.158949Z",
     "start_time": "2018-11-30T14:16:50.679557Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%9.4f\" % x\n",
    "np_format = {}\n",
    "np_format['float']=float_formatter\n",
    "np.set_printoptions(linewidth=190, precision=3, floatmode='fixed', threshold =10000, formatter = np_format)\n",
    "img_id = 0\n",
    "print('Image : {}  PR ClassIds: {}'.format(img_id, pr_class_ids))\n",
    "print('Image : {}  fcn ClassIds: {}'.format(img_id, fcn_class_ids))\n",
    "print(model_fcn_scores.shape)\n",
    "print(model_pr_heatmap_scores.shape)\n",
    "for i in  fcn_class_ids:\n",
    "    if i == 0 :\n",
    "        continue\n",
    "    print()\n",
    "    print('class:', i, '-', dataset_train.class_names[i],'predicted in MRCNN' if i in pr_class_ids else ' ' , ' (Ground Truth) ' if  i in gt_class_ids else ' ')\n",
    "    for j in range(200):\n",
    "#         print(r_fcn_heatmap_scores[img_id, i, j,[4,5,6,15,16,17,18,19,20,21,22]])\n",
    "#         print(model_fcn_scores[img_id,i, j, 4:16])\n",
    "#         print(r_fcn_heatmap_scores[img_id, i, j, 4:16])\n",
    "#         print()\n",
    "\n",
    "#         print('\\t\\t',model_fcn_scores[img_id,i, j, 16:])\n",
    "#         print('\\t\\t',r_fcn_heatmap_scores[img_id, i, j, 16:])\n",
    "#         print()\n",
    "#         print(model_pr_heatmap_scores[img_id, i, j , [5,6,7, 11,12,13,14,15]])\n",
    "#         print(r_fcn_heatmap_scores[img_id, i, j,    [5,6,7, 11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]])\n",
    "        print(model_pr_heatmap_scores[img_id, i, j, [4,5,6,7]])\n",
    "        print(  r_fcn_heatmap_scores[img_id, i, j, [4,5,6,7]])\n",
    "        print('\\t\\t   model alt_scores_1 ',model_pr_heatmap_scores[img_id, i, j, 11:14], '\\t\\t  norm: ', model_pr_heatmap_scores[img_id, i, j, 14:17])\n",
    "        print('\\t\\t     fcn alt_scores_1 ',r_fcn_heatmap_scores[img_id, i, j, 11:14], '\\t\\t  norm: ',r_fcn_heatmap_scores[img_id, i, j, 14:17])\n",
    "        print()\n",
    "        print('\\t\\t   model alt_scores_2 ',model_pr_heatmap_scores[img_id, i, j, 17:20], '\\t\\t  norm: ', model_pr_heatmap_scores[img_id, i, j, 20:])\n",
    "        print('\\t\\t     fcn alt_scores_2 ',r_fcn_heatmap_scores[img_id, i, j, 17:20], '\\t\\t  norm: ',r_fcn_heatmap_scores[img_id, i, j, 20:])\n",
    "        print()\n",
    "        if (np.all(r_fcn_heatmap_scores[img_id,i,j,:4] == 0)):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T15:01:56.667771Z",
     "start_time": "2018-11-25T15:01:56.330768Z"
    },
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "# print(r_in_heatmap.shape)\n",
    "print( r_pt2_heatmaps.shape) ##,  r_pt2_hm_reshape.shape)\n",
    "print('pt2_ind')\n",
    "print(r_pt2_ind.shape)\n",
    "print(r_pt2_ind)\n",
    "print('hm_indices')\n",
    "print(r_hm_indices.shape)\n",
    "print(r_hm_indices)\n",
    "print('hm_indices2')\n",
    "print(r_hm_indices2.shape)\n",
    "print(r_hm_indices2)\n",
    "#     for idx in range(178):\n",
    "#         cls = hm_indices[idx]\n",
    "#         a = tf.reduce_all(tf.equal(pt2_heatmaps[:,:,idx], in_heatmap[:,:,cls]))\n",
    "#         print(idx, cls.eval(), a.eval() ) # '  ', a.eval())\n",
    "## same thing in numpy-------------------\n",
    "p1_sum = np.sum(r_pt2_heatmaps,axis=(1,2))\n",
    "p2_sum = np.sum(r_in_heatmap,axis=(1,2))\n",
    "print(p1_sum.shape, p2_sum.shape)\n",
    "# print(p2_sum)\n",
    "print('len(r_hm_indices): ',len(r_hm_indices))\n",
    "for idx in range(len(r_hm_indices)):\n",
    "    img = r_hm_indices2[idx,0]\n",
    "    cls = r_hm_indices2[idx,1]\n",
    "    print(idx, 'img: ', img, ' cls: ', cls, '   ') ##,r_pt2_ind[idx], r_hm_indices2[idx], r_hm_indices[idx])\n",
    "    a = np.all(r_pt2_heatmaps[idx,:,:] == r_in_heatmap[img,:,:,cls])\n",
    "    #     a = np.all(r_pt2_heatmaps[:,:,idx] == r_in_heatmap[:,:,cls])\n",
    "    print(idx, 'img: ', img, ' cls: ', cls, '   ', a ,'       ',p1_sum[idx], p2_sum[img,cls]) # '  ', a.eval())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:34:48.343664Z",
     "start_time": "2018-11-16T12:34:47.972843Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# img = 1\n",
    "# for row in range(200):\n",
    "#     a = np.all(r_fcn_scores_by_image[img,row] == model_fcn_scores[img,row])\n",
    "#     print(idx, 'img: ', img, ' row:', row, '  a:', a) ##,r_pt2_ind[idx], r_hm_indices2[idx], r_hm_indices[idx])\n",
    "    \n",
    "for idx in range(len(r_pt2_ind)):    \n",
    "    img = r_pt2_ind[idx,0]\n",
    "    cls = r_pt2_ind[idx,1]\n",
    "    row = r_pt2_ind[idx,2]\n",
    "    a = np.all(r_fcn_scores_by_[img,cls,row,:-2] == model_pr_heatmap_scores[img,cls,row])\n",
    "    print(idx, 'img: ', img, ' cls: ', cls, ' row:', row, '  a:', a) ##,r_pt2_ind[idx], r_hm_indices2[idx], r_hm_indices[idx])\n",
    "#     print(r_fcn_padded_scores[img,cls,row,:11] )\n",
    "#     print(model_pr_heatmap_scores[img,cls,row])\n",
    "\n",
    "    #     a = np.all(r_pt2_heatmaps[:,:,idx] == r_in_heatmap[:,:,cls])\n",
    "#     print(idx, 'img: ', img, ' cls: ', cls, '   ', a ,'       ',p1_sum[idx], p2_sum[img,cls]) # '  ', a.eval())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:09:01.700608Z",
     "start_time": "2018-11-15T14:09:01.194310Z"
    }
   },
   "outputs": [],
   "source": [
    "print(self.config.DETECTION_MAX_INSTANCES)\n",
    "print(mrcnn_model.config.DETECTION_MAX_INSTANCES)\n",
    "print(fcn_model.config.DETECTION_MAX_INSTANCES)\n",
    "\n",
    "print(self.config.DETECTION_PER_CLASS)\n",
    "print(mrcnn_model.config.DETECTION_PER_CLASS)\n",
    "print(fcn_model.config.DETECTION_PER_CLASS)\n",
    "\n",
    "print(mrcnn_model.config.TRAIN_ROIS_PER_IMAGE)\n",
    "print(fcn_model.config.TRAIN_ROIS_PER_IMAGE)\n",
    "print(self.config.TRAIN_ROIS_PER_IMAGE)\n",
    "\n",
    "float_formatter = lambda x: \"%10.5f\" % x\n",
    "np_format = {}\n",
    "np_format['float']=float_formatter\n",
    "np.set_printoptions(linewidth=150, precision=3, floatmode='fixed', threshold =10000, formatter = np_format)\n",
    "\n",
    "print(' fcn_scores: ', r_fcn_scores.shape)\n",
    "print(' padded_fcn_scores: ', r_fcn_padded_scores.shape)\n",
    "print(' P :', r_P)\n",
    "print(r_fcn_padded_scores)\n",
    "\n",
    "print(gt_class_ids)\n",
    "print(pr_class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "\n",
    "####  Display for visual check - `gauss_scores`  the final result from    `build_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T17:08:12.099515Z",
     "start_time": "2018-05-20T17:08:09.585183Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "#     scr_norm     = bbox_scores[...,-1]/ tf.reduce_max(bbox_scores[...,-1], axis = -1, keepdims=True)\n",
    "#     scr_norm     = tf.where(tf.is_nan(scr_norm),  tf.zeros_like(scr_norm), scr_norm)     \n",
    "    \n",
    "    \n",
    "#     reduce_max = tf.reduce_max(bbox_scores[...,-1], axis = -1, keepdims=True)\n",
    "#     reduce_min = tf.reduce_min(bbox_scores[...,-1], axis = -1, keepdims=True)  ## epsilon    = tf.ones_like(reduce_max) * 1e-7\n",
    "#     reduce_max = tf.where(tf.equal(reduce_max, 0.0), epsilon, reduce_max)\n",
    "#     scr_norm1  = (2* (bbox_scores[...,-1] - reduce_min) / (reduce_max - reduce_min)) - 1\n",
    "#     scr_norm   = tf.expand_dims(scr_norm, axis = -1)   \n",
    "    \n",
    "    res = fcn_scores.eval()\n",
    "#     bbx =  bbox_scores[...,-1].eval()\n",
    "#     scr =  scr_norm.eval()\n",
    "#     scr1 = scr_norm1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T17:12:10.341920Z",
     "start_time": "2018-05-20T17:12:10.034637Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=180, precision=5, suppress=False, threshold = 10000)\n",
    "# print(scr_norm.shape, scr_norm1.shape)\n",
    "# for i in range(5):\n",
    "#     for j in range(4):\n",
    "#         print('bbox')\n",
    "#         print(bbx[i,j])\n",
    "#         print('scr_norm')\n",
    "#         print(scr[i,j])\n",
    "#         print('scr_norm1')\n",
    "#         print(scr1[i,j])\n",
    "print(res.shape)\n",
    "print(res[...,8:])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T16:25:44.914311Z",
     "start_time": "2018-05-20T16:25:44.675762Z"
    }
   },
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "print(pred_heatmap_scores.shape)\n",
    "# pred_heatmap_scores[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T16:26:52.257369Z",
     "start_time": "2018-05-20T16:26:52.011134Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=8)\n",
    "with sess.as_default():\n",
    "    img = 0\n",
    "    for k in range(4):\n",
    "        print('FCN Scroes Image ', img , '/ Class ',k,' ------------')\n",
    "        print(test[img,k,:,6:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T15:54:28.997200Z",
     "start_time": "2018-05-20T15:54:23.845505Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=7)\n",
    "with sess.as_default():\n",
    "    test1 = tf.reduce_max(fcn_scores[...,-1], axis=-1)\n",
    "    print(test1.eval())\n",
    "    epsilon = tf.ones_like(test1) * 1e-7\n",
    "    print(epsilon.eval())\n",
    "    test2 = tf.where(tf.equal(test1, 0.0), epsilon, test1)\n",
    "    print(test2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `fcn_scoring_graph()` Previous versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `fcn_scoreing_graph()` previous version (saved Feb 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T19:27:52.543106Z",
     "start_time": "2018-11-26T19:27:41.799477Z"
    },
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fcn_scoring_graph(input, config, mode):\n",
    "    in_heatmap, pr_scores = input\n",
    "    rois_per_image        = KB.int_shape(pr_scores)[2] \n",
    "    img_h, img_w          = config.IMAGE_SHAPE[:2]\n",
    "    batch_size            = config.BATCH_SIZE\n",
    "    num_classes           = config.NUM_CLASSES  \n",
    "    heatmap_scale         = config.HEATMAP_SCALE_FACTOR\n",
    "    verbose               = config.VERBOSE\n",
    "    CLASS_COLUMN          = 4\n",
    "    SCORE_COLUMN          = 5\n",
    "    DT_TYPE_COLUMN        = 6\n",
    "    SEQUENCE_COLUMN       = 7\n",
    "    NORM_SCORE_COLUMN     = 8\n",
    "    # if mode == 'training':\n",
    "        # SEQUENCE_COLUMN       = 6\n",
    "        # NORM_SCORE_COLUMN     = 7\n",
    "    # else:\n",
    "        # DT_TYPE_COLUMN        = 6\n",
    "        # SEQUENCE_COLUMN       = 7\n",
    "        # NORM_SCORE_COLUMN     = 8\n",
    "        \n",
    "    print('\\n ')\n",
    "    print('---------------------------------------------')\n",
    "    print('>>> FCN Scoring Graph  - mode:', mode)\n",
    "    print('---------------------------------------------')\n",
    "    logt('in_heatmap.shape  ', in_heatmap, verbose = verbose)\n",
    "    logt('pr_hm_scores.shape', pr_scores, verbose = verbose )\n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "    logt('pr_scores shape ', pr_scores, verbose = verbose)\n",
    "    logt('rois_per_image  ', rois_per_image , verbose = verbose)\n",
    "    logt('config.DETECTION_MAX_INSTANCES ', config.DETECTION_MAX_INSTANCES, verbose = verbose)\n",
    "    logt('config.DETECTIONS_PER_CLASS    ', config.DETECTION_PER_CLASS, verbose = verbose)\n",
    "    logt('SEQUENCE_COLUMN                ', SEQUENCE_COLUMN, verbose = verbose)\n",
    "    logt('NORM_SCORE_COLUMN              ', NORM_SCORE_COLUMN, verbose = verbose)\n",
    "    \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## Stack non_zero bboxes from PR_SCORES into pt2_dense \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    # pt2_ind shape  : [?, 3] : [ {image_index, class_index , roi row_index }]\n",
    "    # pt2_dense shape: [?, 11] : \n",
    "    #    pt2_dense[0:3]  roi coordinates \n",
    "    #    pt2_dense[4]    is class id \n",
    "    #    pt2_dense[5]    is score from mrcnn    \n",
    "    #    pt2_dense[6]    is bbox sequence id    \n",
    "    #    pt2_dense[7]    is normalized score (per class)    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(pr_scores[:,:,:,:CLASS_COLUMN]), axis=-1)\n",
    "    pt2_ind = tf.where(pt2_sum > 0)\n",
    "    pt2_dense = tf.gather_nd(pr_scores, pt2_ind)\n",
    "    logt('in_heatmap       ', in_heatmap, verbose = verbose)\n",
    "    logt('pr_scores.shape  ', pr_scores , verbose = verbose)\n",
    "    logt('pt2_sum shape    ', pt2_sum   , verbose = verbose)\n",
    "    logt('pt2_ind shape    ', pt2_ind   , verbose = verbose)\n",
    "    logt('pt2_dense shape  ', pt2_dense , verbose = verbose)\n",
    "\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for bounding boxes\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    # bboxes_scaled = tf.to_int32(tf.round(pt2_dense[...,0:4])) / heatmap_scale\n",
    "    bboxes_scaled = pt2_dense[...,0:CLASS_COLUMN] / heatmap_scale\n",
    "    width  = bboxes_scaled[:,3] - bboxes_scaled[:,1]      # x2 - x1\n",
    "    height = bboxes_scaled[:,2] - bboxes_scaled[:,0]\n",
    "    cx     = bboxes_scaled[:,1] + ( width  / 2.0)\n",
    "    cy     = bboxes_scaled[:,0] + ( height / 2.0)\n",
    "    # means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)            \n",
    "\n",
    "    \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  build indices and extract heatmaps corresponding to each bounding boxes' class id\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    hm_indices = tf.cast(pt2_ind[:, :2],dtype=tf.int32)\n",
    "    logt('hm_indices  ',  hm_indices, verbose = verbose)\n",
    "    \n",
    "    pt2_heatmaps = tf.transpose(in_heatmap, [0,3,1,2])\n",
    "    logt('pt2_heatmaps',  pt2_heatmaps, verbose = verbose)\n",
    "    \n",
    "    pt2_heatmaps = tf.gather_nd(pt2_heatmaps, hm_indices )\n",
    "    logt('pt2_heatmaps',  pt2_heatmaps, verbose = verbose)\n",
    "\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## (0) Generate scores using prob_grid and pt2_dense\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    old_style_scores = tf.map_fn(build_hm_score_v2, [pt2_heatmaps, bboxes_scaled, pt2_dense[:, NORM_SCORE_COLUMN]], \n",
    "                                 dtype = tf.float32, swap_memory = True)\n",
    "    logt('old_style_scores',  old_style_scores, verbose = verbose)                      \n",
    "                                                                      \n",
    "    # old_style_scores = tf.scatter_nd(pt2_ind, old_style_scores, \n",
    "                                     # [batch_size, num_classes, rois_per_image, KB.int_shape(old_style_scores)[-1]],\n",
    "                                     # name = 'scores_scattered')\n",
    "    # print('    old_style_scores        :',  old_style_scores.get_shape(), KB.int_shape(old_style_scores))                                 \n",
    "                                     \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## generate score based on gaussian using bounding box masks \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    alt_scores_1 = tf.map_fn(build_hm_score_v3, [pt2_heatmaps, cy, cx,covar], dtype=tf.float32)    \n",
    "    logt('alt_scores_1 ', alt_scores_1 , verbose = verbose)\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  Scatter back to per-class tensor /  normalize by class\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    alt_scores_1_norm = tf.scatter_nd(pt2_ind, alt_scores_1, \n",
    "                                    [batch_size, num_classes, rois_per_image, KB.int_shape(alt_scores_1)[-1]],\n",
    "                                    name='alt_scores_1_norm')\n",
    "    logt('alt_scores_1_scattered', alt_scores_1_norm, verbose = verbose)\n",
    "    \n",
    "    alt_scores_1_norm = normalize_scores(alt_scores_1_norm)\n",
    "    logt('alt_scores_1_norm(by_class)', alt_scores_1_norm, verbose = verbose)\n",
    "    \n",
    "    alt_scores_1_norm = tf.gather_nd(alt_scores_1_norm, pt2_ind)\n",
    "    logt('alt_scores_1_norm(by_image)', alt_scores_1_norm, verbose = verbose)\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## Normalize input heatmap normalization (per class) to calculate alt_score_2\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    logt('Normalize heatmap within each class !-------------------------------------', verbose = verbose)         \n",
    "    in_heatmap_norm = tf.transpose(in_heatmap, [0,3,1,2])\n",
    "\n",
    "    logt('in_heatmap_norm  ', in_heatmap_norm, verbose = verbose)\n",
    "    ## normalize in class\n",
    "    normalizer = tf.reduce_max(in_heatmap_norm, axis=[-2,-1], keepdims = True)\n",
    "    normalizer = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    in_heatmap_norm = in_heatmap_norm / normalizer\n",
    "    \n",
    "    # gauss_heatmap_sum_normalized = gauss_heatmap_sum / normalizer\n",
    "    logt('normalizer shape ', normalizer, verbose = verbose)   \n",
    "    logt('normalized heatmap  ', in_heatmap_norm, verbose = verbose)\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  build indices and extract heatmaps corresponding to each bounding boxes' class id\n",
    "    ##  build alternative scores#  based on normalized/sclaked clipped heatmap\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    hm_indices = tf.cast(pt2_ind[:, :2],dtype=tf.int32)\n",
    "    logt('hm_indices shape',  hm_indices, verbose = verbose)\n",
    "    \n",
    "    pt2_heatmaps = tf.gather_nd(in_heatmap_norm, hm_indices )\n",
    "    logt('pt2_heatmaps',  pt2_heatmaps, verbose = verbose)\n",
    "\n",
    "    alt_scores_2 = tf.map_fn(build_hm_score_v3, [pt2_heatmaps, cy, cx,covar], dtype=tf.float32)    \n",
    "    logt('alt_scores_2',alt_scores_2, verbose = verbose)\n",
    "    \n",
    "    alt_scores_2_norm = tf.scatter_nd(pt2_ind, alt_scores_2, \n",
    "                                     [batch_size, num_classes, rois_per_image, KB.int_shape(alt_scores_2)[-1]], name = 'alt_scores_2')  \n",
    "    logt('alt_scores_2(scattered)', alt_scores_2_norm , verbose = verbose)\n",
    "    \n",
    "    alt_scores_2_norm = normalize_scores(alt_scores_2_norm)\n",
    "    logt('alt_scores_2_norm(by_class)', alt_scores_2_norm, verbose = verbose)\n",
    "    \n",
    "    alt_scores_2_norm = tf.gather_nd(alt_scores_2_norm, pt2_ind)\n",
    "    logt('alt_scores_2_norm(by_image)', alt_scores_2_norm, verbose = verbose)\n",
    "\n",
    "    \n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ##  Append alt_scores_1, alt_scores_1_norm to yield fcn_scores_dense \n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    fcn_scores_dense = tf.concat([pt2_dense[:, : NORM_SCORE_COLUMN+1], old_style_scores, alt_scores_1, alt_scores_1_norm, alt_scores_2, alt_scores_2_norm], \n",
    "                                  axis = -1, name = 'fcn_scores_dense')\n",
    "    logt('fcn_scores_dense    ', fcn_scores_dense , verbose = verbose)\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  Scatter back to per-image tensor \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    seq_ids = tf.to_int32( rois_per_image - pt2_dense[:, SEQUENCE_COLUMN] )\n",
    "    scatter_ind= tf.stack([hm_indices[:,0], seq_ids], axis = -1, name = 'scatter_ind')\n",
    "    fcn_scores_by_class = tf.scatter_nd(pt2_ind, fcn_scores_dense, \n",
    "                                        [batch_size, num_classes, rois_per_image, fcn_scores_dense.shape[-1]], name='fcn_hm_scores')\n",
    "    # fcn_scores_by_image = tf.scatter_nd(scatter_ind, fcn_scores_dense, \n",
    "                                        # [batch_size, rois_per_image, fcn_scores_dense.shape[-1]], name='fcn_hm_scores_by_image')\n",
    "    logt('seq_ids             ', seq_ids, verbose = verbose)\n",
    "    logt('sscatter_ids        ', scatter_ind, verbose = verbose)\n",
    "    logt('fcn_scores_by_class ', fcn_scores_by_class, verbose = verbose)\n",
    "    # logt('fcn_scores_by_image ', fcn_scores_by_image) \n",
    "    logt('complete', verbose = verbose)\n",
    "   \n",
    "    return fcn_scores_by_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `fcn_scoreing_graph()`  Nov 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T16:04:09.803119Z",
     "start_time": "2018-11-30T16:04:08.247528Z"
    }
   },
   "outputs": [],
   "source": [
    "from mrcnn.chm_layer import build_hm_score_v2, build_hm_score_v3, normalize_scores\n",
    "from mrcnn.utils import logt\n",
    "##-------------------------------------------------------------------------------------------------------\n",
    "##   score fcn heatmaps : gen scores from heatmap\n",
    "##-------------------------------------------------------------------------------------------------------\n",
    "##   We use the coordinates of the bounding boxes passed in pr_scores to calculate \n",
    "##   the score of bounding boxes overlaid on the heatmap produced by the fcn_layer\n",
    "##   - convert the pr_scores (or gt_hm_scores) from a per_class/per_bbox tensor to a per_class tensor\n",
    "##     [BATCH_SIZE, NUM_CLASSES, DETECTIONS_PER_CLASS, 11] --> [BATCH_SIZE, DETECTIONS_MAX_INSTANCES, 11]\n",
    "##   - Extract non-zero bounding boxes\n",
    "##   - calculate the Cy, Cx, and Covar of the bounding boxes \n",
    "##   - Clip the heatmap by using masks centered on Cy,Cx and +/- Covar_Y, Covar_X\n",
    "##-------------------------------------------------------------------------------------------------------\n",
    "def fcn_scoring_graph(input, config):\n",
    "    in_heatmap, pr_scores = input\n",
    "    detections_per_image  = pr_scores.shape[2] \n",
    "    rois_per_image  = KB.int_shape(pr_scores)[2] \n",
    "    img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "    heatmap_scale   = config.HEATMAP_SCALE_FACTOR\n",
    "    print('\\n ')\n",
    "    print('----------------------')\n",
    "    print('>>> FCN Scoring Layer ')\n",
    "    print('----------------------')\n",
    "    print('    in_heatmap.shape     :', in_heatmap.shape  , KB.int_shape(in_heatmap)  , 'Keras tensor ', KB.is_keras_tensor(in_heatmap))\n",
    "    print('    pr_hm_scores.shape   :', pr_scores.shape, KB.int_shape(pr_scores), 'Keras tensor ', KB.is_keras_tensor(pr_scores))\n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "    print('    detctions_per_image : ', detections_per_image, 'pr_scores shape', pr_scores.shape )\n",
    "    print('    rois_per_image      : ', rois_per_image )\n",
    "    print('    config.DETECTION_MAX_INSTANCES   : ', config.DETECTION_MAX_INSTANCES)\n",
    "    print('    config.DETECTIONS_PER_CLASS      : ', config.DETECTION_PER_CLASS)\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## Stack non_zero bboxes from PR_SCORES into pt2_dense \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    # pt2_ind shape  : [?, 3] : [ {image_index, class_index , roi row_index }]\n",
    "    # pt2_dense shape: [?, 11] : \n",
    "    #    pt2_dense[0:3]  roi coordinates \n",
    "    #    pt2_dense[4]    is class id \n",
    "    #    pt2_dense[5]    is score from mrcnn    \n",
    "    #    pt2_dense[6]    is bbox sequence id    \n",
    "    #    pt2_dense[7]    is normalized score (per class)    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(pr_scores[:,:,:,:4]), axis=-1)\n",
    "    pt2_ind = tf.where(pt2_sum > 0)\n",
    "    pt2_dense = tf.gather_nd(pr_scores, pt2_ind)\n",
    "    print('    in_heatmap          : ', in_heatmap.shape, KB.int_shape(in_heatmap))\n",
    "    print('    pr_scores.shape     : ', pr_scores.shape, KB.int_shape(pr_scores))\n",
    "    print('    pt2_sum shape       : ', pt2_sum.shape, KB.int_shape(pt2_sum))\n",
    "    print('    pt2_ind shape       : ', pt2_ind.shape, KB.int_shape(pt2_ind))     \n",
    "    print('    pt2_dense shape     : ', pt2_dense.get_shape(), KB.int_shape(pt2_dense))\n",
    "    # print('    bboxes  shape       : ', KB.int_shape(bboxes))\n",
    "\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for bounding boxes\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    # bboxes_scaled = tf.to_int32(tf.round(pt2_dense[...,0:4])) / heatmap_scale\n",
    "    bboxes_scaled = pt2_dense[...,0:4] / heatmap_scale\n",
    "    width  = bboxes_scaled[:,3] - bboxes_scaled[:,1]      # x2 - x1\n",
    "    height = bboxes_scaled[:,2] - bboxes_scaled[:,0]\n",
    "    cx     = bboxes_scaled[:,1] + ( width  / 2.0)\n",
    "    cy     = bboxes_scaled[:,0] + ( height / 2.0)\n",
    "    # means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)            \n",
    "\n",
    "    \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  build indices and extract heatmaps corresponding to each bounding boxes' class id\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    hm_indices = tf.cast(pt2_ind[:, :2],dtype=tf.int32)\n",
    "    print('    hm_indices shape         :',  hm_indices.get_shape(), KB.int_shape(hm_indices))\n",
    "    pt2_heatmaps = tf.transpose(in_heatmap, [0,3,1,2])\n",
    "    print('    pt2_heatmaps             :',  pt2_heatmaps.get_shape(), KB.int_shape(pt2_heatmaps))\n",
    "    pt2_heatmaps = tf.gather_nd(pt2_heatmaps, hm_indices )\n",
    "    print('    pt2_heatmaps after gather:',  pt2_heatmaps.get_shape(), KB.int_shape(pt2_heatmaps))\n",
    "\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## (0) Generate scores using prob_grid and pt2_dense - (NEW METHOD added 09-21-2018)\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    old_style_scores = tf.map_fn(build_hm_score_v2, [pt2_heatmaps, bboxes_scaled, pt2_dense[:,7]], \n",
    "                                 dtype = tf.float32, swap_memory = True)\n",
    "    print('    old_style_scores        :',  old_style_scores.get_shape(), KB.int_shape(old_style_scores))                                 \n",
    "                                                                      \n",
    "    # old_style_scores = tf.scatter_nd(pt2_ind, old_style_scores, \n",
    "                                     # [batch_size, num_classes, rois_per_image, KB.int_shape(old_style_scores)[-1]],\n",
    "                                     # name = 'scores_scattered')\n",
    "    # print('    old_style_scores        :',  old_style_scores.get_shape(), KB.int_shape(old_style_scores))                                 \n",
    "                                     \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## generate score based on gaussian using bounding box masks \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    alt_scores_1 = tf.map_fn(build_hm_score_v3, [pt2_heatmaps, cy, cx,covar], dtype=tf.float32)    \n",
    "    # alt_scores_1 = tf.expand_dims(alt_scores_1, axis = -1)\n",
    "    print('    alt_scores_1                  : ', alt_scores_1.shape ,' Keras tensor ', KB.is_keras_tensor(alt_scores_1) )  \n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  Scatter back to per-class tensor /  normalize by class\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    alt_scores_1_norm = tf.scatter_nd(pt2_ind, alt_scores_1, \n",
    "                                    [batch_size, num_classes, detections_per_image, KB.int_shape(alt_scores_1)[-1]],\n",
    "                                    name='alt_scores_1_norm')\n",
    "    print('    alt_scores_1_scattered            : ', alt_scores_1_norm.shape ,' Keras tensor ', KB.is_keras_tensor(alt_scores_1_norm) )  \n",
    "    alt_scores_1_norm = normalize_scores(alt_scores_1_norm)\n",
    "    print('    alt_scores_1_norm(by_class)  : ', alt_scores_1_norm.shape, KB.int_shape(alt_scores_1_norm))\n",
    "    alt_scores_1_norm = tf.gather_nd(alt_scores_1_norm, pt2_ind)\n",
    "    print('    alt_scores_1_norm(by_image)  : ', alt_scores_1_norm.shape, KB.int_shape(alt_scores_1_norm))\n",
    "\n",
    "###################################################################################################################\n",
    "    ## Note: Running this scoring method yields the exact same final result as alt_score_1, and is therefore redundant\n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    ## Normalize input heatmap normalization (per class) to calculate alt_score_2\n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    print('\\n    Normalize heatmap within each class !-------------------------------------')         \n",
    "    in_heatmap_norm = tf.transpose(in_heatmap, [0,3,1,2])\n",
    "\n",
    "    print('    in_heatmap_norm : ', in_heatmap_norm.get_shape(), 'Keras tensor ', KB.is_keras_tensor(in_heatmap_norm) )      \n",
    "    ## normalize in class\n",
    "    normalizer = tf.reduce_max(in_heatmap_norm, axis=[-2,-1], keepdims = True)\n",
    "    normalizer = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    in_heatmap_norm = in_heatmap_norm / normalizer\n",
    "    # gauss_heatmap_sum_normalized = gauss_heatmap_sum / normalizer\n",
    "    print('    normalizer shape   : ', normalizer.shape)   \n",
    "    print('    normalized heatmap : ', in_heatmap_norm.shape   ,' Keras tensor ', KB.is_keras_tensor(in_heatmap_norm) )\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  build indices and extract heatmaps corresponding to each bounding boxes' class id\n",
    "    ##  build alternative scores#  based on normalized/sclaked clipped heatmap\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    hm_indices = tf.cast(pt2_ind[:, :2],dtype=tf.int32)\n",
    "    logt('hm_indices shape',  hm_indices)\n",
    "    \n",
    "    pt2_heatmaps = tf.gather_nd(in_heatmap_norm, hm_indices )\n",
    "    logt('pt2_heatmaps',  pt2_heatmaps)\n",
    "\n",
    "    alt_scores_2 = tf.map_fn(build_hm_score_v3, [pt2_heatmaps, cy, cx,covar], dtype=tf.float32)    \n",
    "    logt('alt_scores_2',alt_scores_2)\n",
    "    \n",
    "    alt_scores_2_norm = tf.scatter_nd(pt2_ind, alt_scores_2, \n",
    "                                     [batch_size, num_classes, rois_per_image, KB.int_shape(alt_scores_2)[-1]], name = 'alt_scores_2')  \n",
    "    logt('alt_scores_2(scattered)', alt_scores_2_norm ) \n",
    "    \n",
    "    alt_scores_2_norm = normalize_scores(alt_scores_2_norm)\n",
    "    logt('alt_scores_2_norm(by_class)', alt_scores_2_norm)\n",
    "    \n",
    "    alt_scores_2_norm = tf.gather_nd(alt_scores_2_norm, pt2_ind)\n",
    "    logt('alt_scores_2_norm(by_image)', alt_scores_2_norm)\n",
    "####################################################################################################################\n",
    "    \n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ##  Append alt_scores_1, alt_scores_1_norm to yield fcn_scores_dense \n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    fcn_scores_dense = tf.concat([pt2_dense[:,:8], old_style_scores, alt_scores_1, alt_scores_1_norm, alt_scores_2, alt_scores_2_norm], \n",
    "                                  axis = -1, name = 'fcn_scores_dense')\n",
    "    logt('fcn_scores_dense    ', fcn_scores_dense )  \n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ##  Scatter back to per-image tensor \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    seq_ids = tf.to_int32( rois_per_image - pt2_dense[:,6] )\n",
    "    scatter_ind= tf.stack([hm_indices[:,0], seq_ids], axis = -1, name = 'scatter_ind')\n",
    "    fcn_scores_by_class = tf.scatter_nd(pt2_ind, fcn_scores_dense, \n",
    "                                        [batch_size, num_classes, detections_per_image, fcn_scores_dense.shape[-1]], name='fcn_scores')\n",
    "    fcn_scores_by_image = tf.scatter_nd(scatter_ind, fcn_scores_dense, \n",
    "                                        [batch_size, detections_per_image, fcn_scores_dense.shape[-1]], name='fcn_scores')\n",
    "    logt('seq_ids             ', seq_ids) \n",
    "    logt('sscatter_ids        ', scatter_ind)\n",
    "    logt('fcn_scores_by_class ', fcn_scores_by_class) \n",
    "    logt('fcn_scores_by_image ', fcn_scores_by_image) \n",
    "    logt('complete')    \n",
    "   \n",
    "    return fcn_scores_by_class\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python [conda env:TFG]",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
