{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Development notebook  FCN model \n",
    "\n",
    "Evaluate returned heatmap values from FCN, by passing data through MRCNN and then through FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T13:57:46.660334Z",
     "start_time": "2018-12-09T13:57:46.213108Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "--> Execution started at: 12-09-2018 @ 14:57:46\n",
      "    Tensorflow Version: 1.8.0   Keras Version : 2.2.0 \n",
      "--epochs 2 --steps_in_epoch 32  --last_epoch 0 --batch_size 1 --lr 0.00001 --val_steps 8 --mrcnn_logs_dir train_mrcnn_coco --fcn_logs_dir   train_fcn32_coco --mrcnn_model    last --fcn_model      init --opt            adam --fcn_arch       fcn32 --fcn_layers     all --sysout        screen --new_log_folder    \n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, math, io, time, gc, argparse, platform, pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "import mrcnn.model_mrcnn  as mrcnn_modellib\n",
    "import mrcnn.model_fcn    as fcn_modellib\n",
    "import mrcnn.visualize    as visualize\n",
    "import mrcnn.new_shapes   as shapes\n",
    "import mrcnn.utils        as utils\n",
    "\n",
    "from datetime           import datetime   \n",
    "from mrcnn.utils        import command_line_parser, Paths\n",
    "# from mrcnn.config       import Config\n",
    "# from mrcnn.dataset      import Dataset \n",
    "from mrcnn.datagen      import data_generator, load_image_gt, data_gen_simulate\n",
    "from mrcnn.prep_notebook import build_fcn_training_pipeline, run_fcn_training_pipeline\n",
    "from mrcnn.prep_notebook import get_inference_batch, get_image_batch, get_training_batch\n",
    "from mrcnn.coco          import prep_coco_dataset\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)\n",
    "start_time = datetime.now().strftime(\"%m-%d-%Y @ %H:%M:%S\")\n",
    "print()\n",
    "print('--> Execution started at:', start_time)\n",
    "print(\"    Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "####  Pass input parameters to argparse\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "## Parse command line arguments\n",
    "##------------------------------------------------------------------------------------\n",
    "parser = command_line_parser()\n",
    "input_parms = \"--epochs 2 --steps_in_epoch 32  --last_epoch 0 --batch_size 1 --lr 0.00001 --val_steps 8 \" \n",
    "# input_parms +=\"--mrcnn_logs_dir train_mrcnn_newshapes \"\n",
    "# input_parms +=\"--fcn_logs_dir   train_fcn8_newshapes \"\n",
    "input_parms +=\"--mrcnn_logs_dir train_mrcnn_coco \"\n",
    "input_parms +=\"--fcn_logs_dir   train_fcn32_coco \"\n",
    "input_parms +=\"--mrcnn_model    last \"\n",
    "input_parms +=\"--fcn_model      init \"\n",
    "input_parms +=\"--opt            adam \"\n",
    "input_parms +=\"--fcn_arch       fcn32 \" \n",
    "input_parms +=\"--fcn_layers     all \" \n",
    "input_parms +=\"--sysout        screen \"\n",
    "input_parms +=\"--new_log_folder    \"\n",
    "print(input_parms)\n",
    "\n",
    "args = parser.parse_args(input_parms.split())\n",
    "# args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T14:02:14.872926Z",
     "start_time": "2018-12-09T14:01:56.308803Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Execution started at: 12-09-2018 @ 15:01:56\n",
      "    Tensorflow Version: 1.8.0   Keras Version : 2.2.0 \n",
      "\n",
      "Arguments passed :\n",
      "--------------------\n",
      "batch_size                     1\n",
      "coco_classes                   None\n",
      "epochs                         2\n",
      "fcn_arch                       FCN32\n",
      "fcn_layers                     ['all']\n",
      "fcn_logs_dir                   train_fcn32_coco\n",
      "fcn_losses                     fcn_bce_loss\n",
      "fcn_model                      init\n",
      "last_epoch                     0\n",
      "lr                             0.00001\n",
      "mrcnn_exclude_layers           None\n",
      "mrcnn_logs_dir                 train_mrcnn_coco\n",
      "mrcnn_model                    last\n",
      "new_log_folder                 True\n",
      "opt                            ADAM\n",
      "scale_factor                   4\n",
      "steps_in_epoch                 32\n",
      "sysout                         SCREEN\n",
      "val_steps                      8\n",
      "\n",
      "\n",
      ">>> Initialize Paths\n",
      " windows  Windows\n",
      "\n",
      "Paths:\n",
      "-------------------------\n",
      "COCO_DATASET_PATH              F:\\MLDatasets\\coco2014\n",
      "COCO_HEATMAP_PATH              F:\\MLDatasets\\coco2014_heatmaps\n",
      "COCO_MODEL_PATH                F:\\PretrainedModels\\mask_rcnn_coco.h5\n",
      "DIR_DATASET                    F:\\MLDatasets\n",
      "DIR_PRETRAINED                 F:\\PretrainedModels\n",
      "DIR_ROOT                       F:\\\n",
      "DIR_TRAINING                   F:\\models\n",
      "FCN_TRAINING_PATH              F:\\models\\train_fcn32_coco\n",
      "FCN_VGG16_MODEL_PATH           F:\\PretrainedModels\\fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "MRCNN_TRAINING_PATH            F:\\models\\train_mrcnn_coco\n",
      "RESNET_MODEL_PATH              F:\\PretrainedModels\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "VGG16_MODEL_PATH               F:\\PretrainedModels\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "\n",
      ">>> Initialize ModelBase model \n",
      "   Mode      :  trainfcn\n",
      "   Model dir :  F:\\models\\train_mrcnn_coco\n",
      ">>> ModelBase initialiation complete\n",
      ">>> ---Initialize MRCNN model, mode:  trainfcn\n",
      "\n",
      "----------------------------\n",
      ">>> Resnet Graph \n",
      "----------------------------\n",
      "     Input_image shape : (?, 1024, 1024, 3)\n",
      "    After ZeroPadding2D            :  shape: (?, 1030, 1030, 3)    KB.shape:(None, 1030, 1030, 3)  Keras Tensor: True\n",
      "    After Conv2D padding :         :  shape: (?, 512, 512, 64)     KB.shape:(None, 512, 512, 64)  Keras Tensor: True\n",
      "    After BatchNorm                :  shape: (?, 512, 512, 64)     KB.shape:(None, 512, 512, 64)  Keras Tensor: True\n",
      "    C1                             :  shape: (?, 256, 256, 64)     KB.shape:(None, 256, 256, 64)  Keras Tensor: True\n",
      "    C2                             :  shape: (?, 256, 256, 256)    KB.shape:(None, 256, 256, 256)  Keras Tensor: True\n",
      "    C3                             :  shape: (?, 128, 128, 512)    KB.shape:(None, 128, 128, 512)  Keras Tensor: True\n",
      "    C4                             :  shape: (?, 64, 64, 1024)     KB.shape:(None, 64, 64, 1024)  Keras Tensor: True\n",
      "    C5                             :  shape: (?, 32, 32, 2048)     KB.shape:(None, 32, 32, 2048)  Keras Tensor: True\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "    FPN P2 shape :                 :  shape: (?, 256, 256, 256)    KB.shape:(None, 256, 256, 256)  Keras Tensor: True\n",
      "    FPN P3 shape :                 :  shape: (?, 128, 128, 256)    KB.shape:(None, 128, 128, 256)  Keras Tensor: True\n",
      "    FPN P4 shape :                 :  shape: (?, 64, 64, 256)      KB.shape:(None, 64, 64, 256)   Keras Tensor: True\n",
      "    FPN P5 shape :                 :  shape: (?, 32, 32, 256)      KB.shape:(None, 32, 32, 256)   Keras Tensor: True\n",
      "    FPN P6 shape :                 :  shape: (?, 16, 16, 256)      KB.shape:(None, 16, 16, 256)   Keras Tensor: True\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "     append Tensor(\"fpn_p2/BiasAdd:0\", shape=(?, 256, 256, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p3/BiasAdd:0\", shape=(?, 128, 128, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p4/BiasAdd:0\", shape=(?, 64, 64, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p5/BiasAdd:0\", shape=(?, 32, 32, 256), dtype=float32) to layer_outputs \n",
      "     append Tensor(\"fpn_p6/MaxPool:0\", shape=(?, 16, 16, 256), dtype=float32) to layer_outputs \n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (261888, 4)\n",
      "     Scores :  (1, 6000)\n",
      "     Deltas :  (1, 6000, 4)\n",
      "     Anchors:  (1, 6000, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Proposals shape :  (1, ?, ?) (1, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (1, ?, ?) (1, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (1, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "    INPUT: rois shape          : (1, ?, ?)\n",
      "    INPUT: No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 256, 256, 256)\n",
      "        feature_maps shape  : (?, 128, 128, 256)\n",
      "        feature_maps shape  : (?, 64, 64, 256)\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "    INPUT: image_shape         : [1024 1024    3]\n",
      "    INPUT: pool_size           : 7\n",
      "    INPUT: num_classes         : 81\n",
      "    roi_align_classifier           :  shape: (1, ?, 7, 7, 256)     KB.shape:(None, 200, 7, 7, 256)  Keras Tensor: True\n",
      "    mrcnn_class_conv1              :  shape: (?, 200, 1, 1, 1024)  KB.shape:(None, 200, 1, 1, 1024)  Keras Tensor: True\n",
      "    mrcnn_class_bn1                :  shape: (?, 200, 1, 1, 1024)  KB.shape:(None, 200, 1, 1, 1024)  Keras Tensor: True\n",
      "    mrcnn_class_relu1              :  shape: (?, 200, 1, 1, 1024)  KB.shape:(None, 200, 1, 1, 1024)  Keras Tensor: True\n",
      "    mrcnn_class_conv2              :  shape: (?, 200, 1, 1, 1024)  KB.shape:(None, 200, 1, 1, 1024)  Keras Tensor: True\n",
      "    mrcnn_class_bn2                :  shape: (?, 200, 1, 1, 1024)  KB.shape:(None, 200, 1, 1, 1024)  Keras Tensor: True\n",
      "    mrcnn_class_relu2              :  shape: (?, 200, 1, 1, 1024)  KB.shape:(None, 200, 1, 1, 1024)  Keras Tensor: True\n",
      "    pool_squeeze(Shared)           :  shape: (?, 200, 1024)        KB.shape:(None, 200, 1024)     Keras Tensor: True\n",
      "    mrcnn_class_logits             :  shape: (?, 200, 81)          KB.shape:(None, 200, 81)       Keras Tensor: True\n",
      "    mrcnn_class_logits (final)     :  shape: (?, 200, 81)          KB.shape:(None, 200, 81)       Keras Tensor: True\n",
      "    mrcnn_probs                    :  shape: (?, 200, 81)          KB.shape:(None, 200, 81)       Keras Tensor: True\n",
      "    mrcnn_probs (final)            :  shape: (?, 200, 81)          KB.shape:(None, 200, 81)       Keras Tensor: True\n",
      "    mrcnn_bbox_fc                  :  shape: (?, 200, 324)         KB.shape:(None, 200, 324)      Keras Tensor: True\n",
      "    mrcnn_bbox_fc reshaped output  :  shape: (?, 200, 81, 4)       KB.shape:(None, 200, 81, 4)    Keras Tensor: True\n",
      "    mrcnn_bbox (final)             :  shape: (?, 200, 81, 4)       KB.shape:(None, 200, 81, 4)    Keras Tensor: True\n",
      "--------------------------------\n",
      ">>>  CHM Layer  \n",
      "--------------------------------\n",
      "  > CHMLayer Call()  3\n",
      "    mrcnn_class.shape    : (?, 200, 81) (None, 200, 81)\n",
      "    mrcnn_bbox.shape     : (?, 200, 81, 4) (None, 200, 81, 4)\n",
      "    output_rois.shape    : (1, ?, ?) (None, 200, 4)\n",
      "\n",
      "  > build_pr_tensor()\n",
      "    num_rois               :  200\n",
      "    norm_input_rois.shape  :  <class 'tensorflow.python.framework.ops.Tensor'> (None, 200, 4)\n",
      "    scale.shape            :  <class 'tensorflow.python.framework.ops.Tensor'> (4,) (4,)\n",
      "    dup_scale.shape        :  <class 'tensorflow.python.framework.ops.Tensor'> (1, 200, 4) (1, 200, 4)\n",
      "\n",
      "    mrcnn_class shape      :  (None, 200, 81)\n",
      "    mrcnn_bbox.shape       :  (None, 200, 81, 4) (?, 200, 81, 4)\n",
      "    config image shape     :  [1024 1024    3] h: 1024 w: 1024\n",
      "    refined rois clipped   :  (1, 200, 4)\n",
      "    input_rois.shape       :  (1, 200, 4) (1, 200, 4)\n",
      "    refined_rois.shape     :  (1, 200, 4) (1, 200, 4)\n",
      "    shape of sequence      :  (?, 200, 1)\n",
      "    pred_array             :  (1, 200, 7)\n",
      "    scatter_ind            :  (1, 200, 3)\n",
      "    pred_scatter           :  (1, 81, 200, 7)\n",
      "    - Add normalized score --\n",
      "\n",
      "    normalizer             :  (1, 81, 1)\n",
      "    norm_score             :  (1, 81, 200, 1)\n",
      "    pred_scatter           :  (1, 81, 200, 8)\n",
      "    sort_inds              :  (1, 81, 200) Keras Tensor: False\n",
      "    class_grid             :  (1, 81, 200) Keras Tensor: False\n",
      "    batch_grid             :  (1, 81, 200) Keras Tensor: False\n",
      "    roi_grid shape         :  (1, 81, 200) Keras Tensor: False\n",
      "    gather_inds            :  (1, 81, 200, 3) Keras Tensor: False\n",
      "    pred_tensor            :  (1, 81, 200, 8) Keras Tensor: False\n",
      "\n",
      " \n",
      "  > build_pr_heatmap() for  ['pred_heatmap']\n",
      "    in_tensor shape        :  (1, 81, 200, 8)\n",
      "    num bboxes per class   :  200\n",
      "    heatmap scale        :  4 Dimensions:  w: 256  h: 256\n",
      "    pt2_sum shape  :  (1, 81, 200)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n",
      "    X/Y shapes : (256, 256) (256, 256)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (256, 256) =  (?, 256, 256)\n",
      "    ones_exp * Y (?, 1, 1) * (256, 256) =  (?, 256, 256)\n",
      "    pos_grid before transpse :  (?, 256, 256, 2)\n",
      "    pos_grid after transpose :  (256, 256, ?, 2)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (256, 256, ?, 2)\n",
      "     Prob_grid shape from mvn.probe:  (256, 256, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 256, 256)\n",
      "    << output probabilities shape  :  (?, 256, 256)\n",
      "    old_style_scores        : (1, 81, 200, 3) (1, 81, 200, 3)\n",
      "    prob_grid_clipped :  (?, 256, 256)\n",
      "\n",
      "    normalization ------------------------------------------------------\n",
      "    normalizer     :  (?, 1, 1)\n",
      "    prob_grid_cns: clipped/normed/scaled :  (?, 256, 256)\n",
      "    alt_scores_1    :  (None, 3)  Keras tensor  False\n",
      "    alt_scores_1(by class)       :  (1, 81, 200, 3)  Keras tensor  False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 81, 200, 3)\n",
      "         reduce_min shape :  (1, 81, 1, 3)\n",
      "         reduce_max shape :  (1, 81, 1, 3)\n",
      "             output shape :  (1, 81, 200, 3)\n",
      "\n",
      "    alt_scores_1_norm(by_class)  :  (1, 81, 200, 3) (1, 81, 200, 3)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape      :  (?, 3)\n",
      "    prob_grid_clippped :  (?, 256, 256)\n",
      "    gauss_heatmap      :  (1, 81, 200, 256, 256)\n",
      "\n",
      "    Reduce SUM based on class and normalize within each class -------------------------------------\n",
      "    gaussian_heatmap_sum :  (1, 81, 256, 256) Keras tensor  False\n",
      "    normalizer shape   :  (1, 81, 1, 1)\n",
      "    normalized heatmap :  (1, 81, 256, 256)  Keras tensor  False\n",
      "    hm_indices shape         : (?, 2) (None, 2)\n",
      "    pt2_heatmaps             : (?, 256, 256) (None, 256, 256)\n",
      "    alt_scores_2    :  (None, 3)  Keras tensor  False\n",
      "    alt_scores_2(scattered)       :  (1, 81, 200, 3)  Keras tensor  False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 81, 200, 3)\n",
      "         reduce_min shape :  (1, 81, 1, 3)\n",
      "         reduce_max shape :  (1, 81, 1, 3)\n",
      "             output shape :  (1, 81, 200, 3)\n",
      "\n",
      "    alt_scores_2_norm(by_class)  :  (1, 81, 200, 3) (1, 81, 200, 3)\n",
      "    reshaped heatmap   :  (1, 256, 256, 81)  Keras tensor  False\n",
      "    gauss_scores    :  (1, 81, 200, 23)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    pred_refined_heatmap        :  (1, 256, 256, 81) Keras tensor  False\n",
      "    pred_refnined_heatmap_scores:  (1, 81, 200, 23) Keras tensor  False\n",
      "    complete\n",
      "--------------------------------\n",
      ">>>  CHM Layer COMPUTE OUTPUT SHAPE \n",
      "--------------------------------\n",
      "<class 'list'> 3\n",
      "\n",
      "-----------------------------------------\n",
      ">>>  CHM Layer (Ground Truth Generation) \n",
      "-----------------------------------------\n",
      "  > CHMLayerTgt Call()  2\n",
      "    tgt_class_ids.shape  : (1, ?) (None, 200)\n",
      "    tgt_bboxes.shape     : (1, ?, ?) (None, 200, 4)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    num_bboxes             :  200 (building  gt_tensor )\n",
      "    gt_class_ids shape     :  (1, ?)    (None, 200)\n",
      "    norm_gt_bboxes.shape   :  (1, ?, ?)    (None, 200, 4)\n",
      "    gt_bboxes.shape        :  (1, 200, 4)    (1, 200, 4)\n",
      "    gt_classes_exp         :  (1, ?, 1)\n",
      "    gt_scores_exp          :  (1, ?, 1)\n",
      "    gt_array shape         :  (1, 200, 8) (1, 200, 8)\n",
      "    scatter_ind shape      :  (1, 200, 3) (1, 200, 3)\n",
      "    tf.shape(gt_array)[-1] :  8 (1, 200, 8)\n",
      "    gt_scatter shape       :  (1, 81, 200, 8) (1, 81, 200, 8)\n",
      "    sort_inds              :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    class_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    batch_grid             :  <class 'tensorflow.python.framework.ops.Tensor'>  shape  (1, 81, 200)\n",
      "    gather_inds            :  (1, 81, 200, 3)\n",
      "    gt_tensor.shape        :  (1, 81, 200, 8) (1, 81, 200, 8)\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['gt_heatmap']\n",
      "    in_tensor shape        :  (1, 81, 200, 8)\n",
      "    num bboxes per class   :  200\n",
      "    heatmap scale        :  4 Dimensions:  w: 256  h: 256\n",
      "    pt2_sum shape  :  (1, 81, 200)\n",
      "    pt2_ind shape  :  (?, 3)\n",
      "    pt2_dense shape:  (?, 8)\n",
      "     Prob_grid shape :  (?, 256, 256)\n",
      "    prob_grid_clipped      :  (?, 256, 256)\n",
      "    old_style_scores       :  (1, 81, 200, 3)  Keras tensor  False\n",
      "    alt_scores_1    :  (None, 3)  Keras tensor  False\n",
      "    alt_scores_1(by class)       :  (1, 81, 200, 3)  Keras tensor  False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 81, 200, 3)\n",
      "         reduce_min shape :  (1, 81, 1, 3)\n",
      "         reduce_max shape :  (1, 81, 1, 3)\n",
      "             output shape :  (1, 81, 200, 3)\n",
      "\n",
      "    alt_scores_1_norm(by_class)  :  (1, 81, 200, 3) (1, 81, 200, 3)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 256, 256)\n",
      "    gauss_heatmap   :  (1, 81, 200, 256, 256)\n",
      "\n",
      "    Reduce MAX based on class ---------------------------------------------\n",
      "    gaussian_heatmap :  (1, 81, 256, 256) Keras tensor  False\n",
      "    hm_indices shape         : (?, 2) (None, 2)\n",
      "    pt2_heatmaps             : (?, 256, 256) (None, 256, 256)\n",
      "    alt_scores_2    :  (None, 3)  Keras tensor  False\n",
      "    alt_scores_2(by class)       :  (1, 81, 200, 3)  Keras tensor  False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 81, 200, 3)\n",
      "         reduce_min shape :  (1, 81, 1, 3)\n",
      "         reduce_max shape :  (1, 81, 1, 3)\n",
      "             output shape :  (1, 81, 200, 3)\n",
      "\n",
      "    alt_scores_2_norm(by_class)  :  (1, 81, 200, 3) (1, 81, 200, 3)\n",
      "    gauss_heatmap :  (1, 256, 256, 81)  Keras tensor  False\n",
      "    gauss_scores    :  (1, 81, 200, 23)  Keras tensor  False\n",
      "    complete\n",
      "\n",
      "    gt_heatmap                  :  (1, 256, 256, 81) Keras tensor  False\n",
      "    gt_heatmap_scores           :  (1, 81, 200, 23) Keras tensor  False\n",
      "    complete\n",
      "    pr_hm                          :  shape: (1, 256, 256, 81)     KB.shape:(None, 1024, 1024, 81)  Keras Tensor: True\n",
      "    gt_hm                          :  shape: (1, 256, 256, 81)     KB.shape:(None, 1024, 1024, 81)  Keras Tensor: True\n",
      "\n",
      ">>> Build MaskRCNN build complete. mode:  trainfcn\n",
      ">>> MaskRCNN initialiation complete. Mode:  trainfcn\n",
      ">>> Initialize ModelBase model \n",
      "   Mode      :  training\n",
      "   Model dir :  F:\\models\\train_fcn32_coco\n",
      ">>> ModelBase initialiation complete\n",
      ">>> Initialize FCN model, mode:  training architecture:  FCN32\n",
      ">>> set_log_dir(): model_path:  None\n",
      "    set_log_dir(): model_path has NOT been provided : None \n",
      "                  NewFolder: False  config.NEW_LOG_FOLDER: True \n",
      "    set_log_dir(): weight file template (self.checkpoint_path): F:\\models\\train_fcn32_coco\\fcn20181209T1502\\fcn_{epoch:04d}.h5 \n",
      "    set_log_dir(): weight file dir      (self.log_dir)        : F:\\models\\train_fcn32_coco\\fcn20181209T1502 \n",
      "    set_log_dir(): Last completed epoch (self.epoch)          : 0 \n",
      "    arch set to FCN32\n",
      "<function fcn32_graph at 0x0000003F1DC762F0>\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      " Build FCN Model -  Arch:  FCN32  mode:  training\n",
      "---------------------------------------------------\n",
      "   active_class_ids  shape is :  (None, None)  Keras tensor  True\n",
      "\n",
      "---------------\n",
      ">>> FCN32 Layer - mode: training\n",
      "---------------\n",
      "     feature map      : (?, 256, 256, 81)\n",
      "     height : 256 width : 256 classes : 81\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "   FCN Block 11 shape is :  (?, 256, 256, 64)\n",
      "   FCN Block 12 shape is :  (?, 256, 256, 64)\n",
      "   FCN Block 13 shape is :  (?, 128, 128, 64)\n",
      "   FCN Block 21 shape is :  (?, 128, 128, 128)\n",
      "   FCN Block 22 shape is :  (?, 128, 128, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (?, 64, 64, 128)\n",
      "   FCN Block 31 shape is :  (?, 64, 64, 256)\n",
      "   FCN Block 32 shape is :  (?, 64, 64, 256)\n",
      "   FCN Block 33 shape is :  (?, 64, 64, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (?, 32, 32, 256)\n",
      "   FCN Block 41 shape is :  (?, 32, 32, 512)\n",
      "   FCN Block 42 shape is :  (?, 32, 32, 512)\n",
      "   FCN Block 43 shape is :  (?, 32, 32, 512)\n",
      "   FCN Block 44 (Max pooling) shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 51 shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 52 shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 53 shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 54 (Max pooling) shape is :  (?, 8, 8, 512)\n",
      "   FCN fully connected 1 (fcn_fc1) shape is :  (?, 8, 8, 4096)\n",
      "***** Call to Dropout Layer : Training is :  None\n",
      "***** in_train_phase() : Use_learning_phase:  True\n",
      "   FCN fully connected 2 (fcn_fc2) shape is :  (?, 8, 8, 4096)\n",
      "***** Call to Dropout Layer : Training is :  None\n",
      "***** in_train_phase() : Use_learning_phase:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FCN final conv2d (fcn_classify) shape is :  (?, 8, 8, 81)  keras_tensor  True\n",
      "   h_factor :  32.0 w_factor :  32.0\n",
      "    FCN fcn8_classify/heatmap  (Deconv(fuse_Pool4)):  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: True\n",
      "    fcn_hm (final)                 :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: True\n",
      "\n",
      "    fcn8_softmax                   :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: True\n",
      "    fcn_sm (final)                 :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: True\n",
      "\n",
      "    fcn_heatmap       :  (?, 256, 256, 81)  Keras tensor  True\n",
      "  * gt_hm_scores shape:  (None, 81, 200, 23)  Keras tensor  True\n",
      "  * pr_hm_scores shape:  (None, 81, 200, 23)  Keras tensor  True\n",
      "  * fcn_heatmap shape :  (None, 256, 256, 81)  Keras tensor  True\n",
      "  * fcn_softmax shape :  (None, 256, 256, 81)  Keras tensor  True\n",
      "\n",
      " \n",
      "----------------------\n",
      ">>> FCN Scoring Layer \n",
      "----------------------\n",
      "    in_heatmap.shape               :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: True\n",
      "    pr_hm_scores.shape             :  shape: (?, 81, 200, 23)      KB.shape:(None, 81, 200, 23)   Keras Tensor: True\n",
      "    detctions_per_image :  200 pr_scores shape (?, 81, 200, 23)\n",
      "    rois_per_image      :  200\n",
      "    config.DETECTION_MAX_INSTANCES   :  100\n",
      "    config.DETECTIONS_PER_CLASS      :  200\n",
      "    in_heatmap                     :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: True\n",
      "    pr_scores.shape                :  shape: (?, 81, 200, 23)      KB.shape:(None, 81, 200, 23)   Keras Tensor: True\n",
      "    pt2_sum shape                  :  shape: (?, 81, 200)          KB.shape:(None, 81, 200)       Keras Tensor: False\n",
      "    pt2_ind shape                  :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    pt2_dense shape                :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    hm_indices                     :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 81, 256, 256)     KB.shape:(None, 81, 256, 256)  Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 256, 256)         KB.shape:(None, 256, 256)      Keras Tensor: False\n",
      "    old_style_scores               :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1_scattered         :  shape: (1, 81, 200, 3)       KB.shape:(1, 81, 200, 3)       Keras Tensor: False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 81, 200, 3)\n",
      "         reduce_min shape :  (1, 81, 1, 3)\n",
      "         reduce_max shape :  (1, 81, 1, 3)\n",
      "             output shape :  (1, 81, 200, 3)\n",
      "\n",
      "    alt_scores_1_norm(by_class)    :  shape: (1, 81, 200, 3)       KB.shape:(1, 81, 200, 3)       Keras Tensor: False\n",
      "    alt_scores_1_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "\n",
      "    Normalize heatmap within each class !-------------------------------------\n",
      "    in_heatmap_norm :  (?, 81, 256, 256) Keras tensor  False\n",
      "    normalizer shape   :  (?, 81, 1, 1)\n",
      "    normalized heatmap :  (?, 81, 256, 256)  Keras tensor  False\n",
      "    hm_indices shape               :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 256, 256)         KB.shape:(None, 256, 256)      Keras Tensor: False\n",
      "    alt_scores_2                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_2(scattered)        :  shape: (1, 81, 200, 3)       KB.shape:(1, 81, 200, 3)       Keras Tensor: False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 81, 200, 3)\n",
      "         reduce_min shape :  (1, 81, 1, 3)\n",
      "         reduce_max shape :  (1, 81, 1, 3)\n",
      "             output shape :  (1, 81, 200, 3)\n",
      "\n",
      "    alt_scores_2_norm(by_class)    :  shape: (1, 81, 200, 3)       KB.shape:(1, 81, 200, 3)       Keras Tensor: False\n",
      "    alt_scores_2_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    fcn_scores_dense               :  shape: (?, 24)               KB.shape:(None, 24)            Keras Tensor: False\n",
      "    seq_ids                        :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    sscatter_ids                   :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    fcn_scores_by_class            :  shape: (1, 81, 200, 24)      KB.shape:(1, 81, 200, 24)      Keras Tensor: False\n",
      "    complete                       \n",
      "\n",
      " \n",
      "----------------------\n",
      ">>> FCN Scoring Layer \n",
      "----------------------\n",
      "    in_heatmap.shape               :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: False\n",
      "    pr_hm_scores.shape             :  shape: (?, 81, 200, 23)      KB.shape:(None, 81, 200, 23)   Keras Tensor: False\n",
      "    detctions_per_image :  200 pr_scores shape (?, 81, 200, 23)\n",
      "    rois_per_image      :  200\n",
      "    config.DETECTION_MAX_INSTANCES   :  100\n",
      "    config.DETECTIONS_PER_CLASS      :  200\n",
      "    in_heatmap                     :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: False\n",
      "    pr_scores.shape                :  shape: (?, 81, 200, 23)      KB.shape:(None, 81, 200, 23)   Keras Tensor: False\n",
      "    pt2_sum shape                  :  shape: (?, 81, 200)          KB.shape:(None, 81, 200)       Keras Tensor: False\n",
      "    pt2_ind shape                  :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    pt2_dense shape                :  shape: (?, 23)               KB.shape:(None, 23)            Keras Tensor: False\n",
      "    hm_indices                     :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 81, 256, 256)     KB.shape:(None, 81, 256, 256)  Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 256, 256)         KB.shape:(None, 256, 256)      Keras Tensor: False\n",
      "    old_style_scores               :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_1_scattered         :  shape: (1, 81, 200, 3)       KB.shape:(1, 81, 200, 3)       Keras Tensor: False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 81, 200, 3)\n",
      "         reduce_min shape :  (1, 81, 1, 3)\n",
      "         reduce_max shape :  (1, 81, 1, 3)\n",
      "             output shape :  (1, 81, 200, 3)\n",
      "\n",
      "    alt_scores_1_norm(by_class)    :  shape: (1, 81, 200, 3)       KB.shape:(1, 81, 200, 3)       Keras Tensor: False\n",
      "    alt_scores_1_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "\n",
      "    Normalize heatmap within each class !-------------------------------------\n",
      "    in_heatmap_norm :  (?, 81, 256, 256) Keras tensor  False\n",
      "    normalizer shape   :  (?, 81, 1, 1)\n",
      "    normalized heatmap :  (?, 81, 256, 256)  Keras tensor  False\n",
      "    hm_indices shape               :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    pt2_heatmaps                   :  shape: (?, 256, 256)         KB.shape:(None, 256, 256)      Keras Tensor: False\n",
      "    alt_scores_2                   :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    alt_scores_2(scattered)        :  shape: (1, 81, 200, 3)       KB.shape:(1, 81, 200, 3)       Keras Tensor: False\n",
      "\n",
      "       Normalize_scores() ------------------------------------------------------\n",
      "         input shape      :  (1, 81, 200, 3)\n",
      "         reduce_min shape :  (1, 81, 1, 3)\n",
      "         reduce_max shape :  (1, 81, 1, 3)\n",
      "             output shape :  (1, 81, 200, 3)\n",
      "\n",
      "    alt_scores_2_norm(by_class)    :  shape: (1, 81, 200, 3)       KB.shape:(1, 81, 200, 3)       Keras Tensor: False\n",
      "    alt_scores_2_norm(by_image)    :  shape: (?, 3)                KB.shape:(None, 3)             Keras Tensor: False\n",
      "    fcn_scores_dense               :  shape: (?, 24)               KB.shape:(None, 24)            Keras Tensor: False\n",
      "    seq_ids                        :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    sscatter_ids                   :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    fcn_scores_by_class            :  shape: (1, 81, 200, 24)      KB.shape:(1, 81, 200, 24)      Keras Tensor: False\n",
      "    complete                       \n",
      "  * fcn_scores shape:  (1, 81, 200, 24)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_MSE_loss_graph \n",
      "-------------------------------\n",
      "    target_masks : (?, 256, 256, 81) (None, 256, 256, 81) KerasTensor:  True\n",
      "    pred_heatmap : (?, 256, 256, 81) (None, 256, 256, 81) KerasTensor:  True\n",
      "    loss         : (?, 256, 256) (None, 256, 256) KerasTensor:  False\n",
      "    loss mean    : () () KerasTensor:  False\n",
      "    loss final   : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_MSE_loss_graph \n",
      "-------------------------------\n",
      "    target_masks : (?, 256, 256, 81) (None, 256, 256, 81) KerasTensor:  False\n",
      "    pred_heatmap : (?, 256, 256, 81) (None, 256, 256, 81) KerasTensor:  False\n",
      "    loss         : (?, 256, 256) (None, 256, 256) KerasTensor:  False\n",
      "    loss mean    : () () KerasTensor:  False\n",
      "    loss final   : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_CE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  : (None, 256, 256, 81)\n",
      "    pred_class_logits : (None, 256, 256, 81)\n",
      "    active_class_ids  : (None, None)\n",
      "    pred_class_ids    : (None, 256, 256) <dtype: 'int64'>\n",
      "    gt_class_ids      : (None, 256, 256) <dtype: 'int64'>\n",
      "    pred_active       : (None, 256, 256) <dtype: 'float32'>\n",
      "    loss              : (None, 256, 256) <dtype: 'float32'>\n",
      "    loss*pred_active  : (None, 256, 256) KerasTensor:  False\n",
      "    loss              : () () KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_CE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  : (None, 256, 256, 81)\n",
      "    pred_class_logits : (None, 256, 256, 81)\n",
      "    active_class_ids  : (None, None)\n",
      "    pred_class_ids    : (None, 256, 256) <dtype: 'int64'>\n",
      "    gt_class_ids      : (None, 256, 256) <dtype: 'int64'>\n",
      "    pred_active       : (None, 256, 256) <dtype: 'float32'>\n",
      "    loss              : (None, 256, 256) <dtype: 'float32'>\n",
      "    loss*pred_active  : (None, 256, 256) KerasTensor:  False\n",
      "    loss              : () () KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_BCE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  :            :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: True\n",
      "    pred_class_logits :            :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: True\n",
      "    trgt_heatmap                   :  shape: (?, 81, 256, 256)     KB.shape:(None, 81, 256, 256)  Keras Tensor: False\n",
      "    trgt_heatmap                   :  shape: (?, 81, 256, 256)     KB.shape:(None, 81, 256, 256)  Keras Tensor: False\n",
      "    tgt_hm_sum                     :  shape: (?, 81)               KB.shape:(None, 81)            Keras Tensor: False\n",
      "    class indeixes                 :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    active_tgt_heatmaps            :  shape: (?, 256, 256)         KB.shape:(None, 256, 256)      Keras Tensor: False\n",
      "    active_pred_heatmaps           :  shape: (?, 256, 256)         KB.shape:(None, 256, 256)      Keras Tensor: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y_true :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    y_pred :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    loss                           :  shape: <unknown>             KB.shape:None                  Keras Tensor: False\n",
      "    mean loss                      :  shape: ()                    KB.shape:()                    Keras Tensor: False\n",
      "    loss (final)                   :  shape: (1, 1)                KB.shape:(1, 1)                Keras Tensor: False\n",
      "    loss              : <unknown> None KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      "\n",
      "-------------------------------\n",
      ">>> fcn_heatmap_BCE_loss_graph  \n",
      "-------------------------------\n",
      "    target_class_ids  :            :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: False\n",
      "    pred_class_logits :            :  shape: (?, 256, 256, 81)     KB.shape:(None, 256, 256, 81)  Keras Tensor: False\n",
      "    trgt_heatmap                   :  shape: (?, 81, 256, 256)     KB.shape:(None, 81, 256, 256)  Keras Tensor: False\n",
      "    trgt_heatmap                   :  shape: (?, 81, 256, 256)     KB.shape:(None, 81, 256, 256)  Keras Tensor: False\n",
      "    tgt_hm_sum                     :  shape: (?, 81)               KB.shape:(None, 81)            Keras Tensor: False\n",
      "    class indeixes                 :  shape: (?, 2)                KB.shape:(None, 2)             Keras Tensor: False\n",
      "    active_tgt_heatmaps            :  shape: (?, 256, 256)         KB.shape:(None, 256, 256)      Keras Tensor: False\n",
      "    active_pred_heatmaps           :  shape: (?, 256, 256)         KB.shape:(None, 256, 256)      Keras Tensor: False\n",
      "    y_true :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    y_pred :                       :  shape: (?,)                  KB.shape:(None,)               Keras Tensor: False\n",
      "    loss                           :  shape: <unknown>             KB.shape:None                  Keras Tensor: False\n",
      "    mean loss                      :  shape: ()                    KB.shape:()                    Keras Tensor: False\n",
      "    loss (final)                   :  shape: (1, 1)                KB.shape:(1, 1)                Keras Tensor: False\n",
      "    loss              : <unknown> None KerasTensor:  False\n",
      "    loss mean         : () () KerasTensor:  False\n",
      "    loss final        : (1, 1) (1, 1) KerasTensor:  False\n",
      " ================================================================\n",
      " self.keras_model.losses :  0\n",
      " ================================================================\n",
      "\n",
      ">>> FCN build complete. mode:  training\n",
      ">>> FCN initialization complete. mode:  training\n",
      "\n",
      " MRCNN IO Layers \n",
      " --------------- \n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image:0                              Type: float32           Shape: (?, 1024, 1024, 3)\n",
      " index:  1    input name : input_image_meta:0                         Type: float32           Shape: (?, ?)\n",
      " index:  2    input name : input_rpn_match:0                          Type: int32             Shape: (?, ?, 1)\n",
      " index:  3    input name : input_rpn_bbox:0                           Type: float32           Shape: (?, ?, 4)\n",
      " index:  4    input name : input_gt_class_ids:0                       Type: int32             Shape: (?, ?)\n",
      " index:  5    input name : input_gt_boxes:0                           Type: float32           Shape: (?, ?, 4)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: cntxt_layer/pred_heatmap:0                 Type: float32           Shape: (1, 256, 256, 81)\n",
      " layer:  1    output name: cntxt_layer/pred_heatmap_scores:0          Type: float32           Shape: (1, 81, 200, 23)\n",
      " layer:  2    output name: cntxt_layer_gt/gt_heatmap:0                Type: float32           Shape: (1, 256, 256, 81)\n",
      " layer:  3    output name: cntxt_layer_gt/gt_heatmap_scores:0         Type: float32           Shape: (1, 81, 200, 23)\n",
      " layer:  4    output name: mrcnn_class_lambda/mrcnn_class:0           Type: float32           Shape: (?, 200, 81)\n",
      " layer:  5    output name: mrcnn_bbox_lambda/mrcnn_bbox:0             Type: float32           Shape: (?, 200, 81, 4)\n",
      " layer:  6    output name: proposal_targets/output_rois:0             Type: float32           Shape: (1, ?, ?)\n",
      " layer:  7    output name: proposal_targets/target_class_ids:0        Type: int32             Shape: (1, ?)\n",
      " layer:  8    output name: proposal_targets/roi_gt_boxes:0            Type: float32           Shape: (1, ?, ?)\n",
      " layer:  9    output name: mrcnn_logits_lambda/mrcnn_class_logits:0   Type: float32           Shape: (?, 200, 81)\n",
      " layer: 10    output name: active_class_ids/strided_slice_3:0         Type: float32           Shape: (?, ?)\n",
      "\n",
      " FCN IO Layers \n",
      " ------------- \n",
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image_meta_1:0                       Type: float32           Shape: (?, ?)\n",
      " index:  1    input name : input_pr_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  2    input name : input_pr_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 23)\n",
      " index:  3    input name : input_gt_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  4    input name : input_gt_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 23)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: fcn_heatmap_lambda/fcn_hm:0                Type: float32           Shape: (?, 256, 256, 81)\n",
      " layer:  1    output name: fcn_softmax_lambda/fcn_sm:0                Type: float32           Shape: (?, 256, 256, 81)\n",
      " layer:  2    output name: fcn_MSE_loss/fcn_MSE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  3    output name: fcn_BCE_loss/fcn_BCE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  4    output name: fcn_scoring/fcn_hm_scores:0                Type: float32           Shape: (1, 81, 200, 24)\n",
      "-----------------------------------------------\n",
      " Load Model with init parm: [ last ]\n",
      "-----------------------------------------------\n",
      " ---> last\n",
      ">>> load_weights() from : F:\\models\\train_mrcnn_coco\\mrcnn20181011T1100\\mrcnn_0103.h5\n",
      "    Weights file loaded: F:\\models\\train_mrcnn_coco\\mrcnn20181011T1100\\mrcnn_0103.h5 \n",
      "==========================================\n",
      "MRCNN  MODEL Load weight file COMPLETE \n",
      "==========================================\n",
      " FCN Training starting from randomly initialized weights ...\n"
     ]
    }
   ],
   "source": [
    "mrcnn_model, fcn_model = build_fcn_training_pipeline(args = args,verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build FCN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T14:02:53.292343Z",
     "start_time": "2018-12-09T14:02:52.993203Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image_meta_1:0                       Type: float32           Shape: (?, ?)\n",
      " index:  1    input name : input_pr_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  2    input name : input_pr_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 23)\n",
      " index:  3    input name : input_gt_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  4    input name : input_gt_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 23)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: fcn_heatmap_lambda/fcn_hm:0                Type: float32           Shape: (?, 256, 256, 81)\n",
      " layer:  1    output name: fcn_softmax_lambda/fcn_sm:0                Type: float32           Shape: (?, 256, 256, 81)\n",
      " layer:  2    output name: fcn_MSE_loss/fcn_MSE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  3    output name: fcn_BCE_loss/fcn_BCE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  4    output name: fcn_scoring/fcn_hm_scores:0                Type: float32           Shape: (1, 81, 200, 24)\n"
     ]
    }
   ],
   "source": [
    "# fcn_model.config.display()  \n",
    "fcn_model.display_layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T14:05:51.032551Z",
     "start_time": "2018-12-09T14:04:42.246517Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO loading annotations file F:\\MLDatasets\\coco2014\\annotations/instances_train2014.json  into memory...\n",
      "Done (t=21.85s)\n",
      "creating index...\n",
      "index created!\n",
      " loading  all classes\n",
      " image dir            :  F:\\MLDatasets\\coco2014\\train2014\n",
      " json_path_dir        :  F:\\MLDatasets\\coco2014\\annotations/instances_train2014.json\n",
      " number of images     :  82783\n",
      " image_ids[:10]       :  [262145, 131074, 131075, 393221, 393223, 393224, 524297, 393227, 393228, 262146]\n",
      " image_ids[1000:1010] :  [22098, 1518, 132591, 1522, 394739, 525813, 1526, 525815, 327935, 394748]\n",
      "COCO loading annotations file F:\\MLDatasets\\coco2014\\annotations/instances_valminusminival2014.json  into memory...\n",
      "Done (t=5.42s)\n",
      "creating index...\n",
      "index created!\n",
      " loading  all classes\n",
      " image dir            :  F:\\MLDatasets\\coco2014\\val2014\n",
      " json_path_dir        :  F:\\MLDatasets\\coco2014\\annotations/instances_valminusminival2014.json\n",
      " number of images     :  35504\n",
      " image_ids[:10]       :  [262148, 185686, 360073, 393225, 488823, 240301, 131089, 262162, 281512, 458778]\n",
      " image_ids[1000:1010] :  [1856, 221282, 279391, 382603, 371046, 315565, 395083, 460621, 460623, 264017]\n",
      "Prepares complete\n",
      "COCO loading annotations file F:\\MLDatasets\\coco2014\\annotations/instances_train2014.json  into memory...\n",
      "Done (t=19.25s)\n",
      "creating index...\n",
      "index created!\n",
      " loading  all classes\n",
      " image dir            :  F:\\MLDatasets\\coco2014\\train2014\n",
      " json_path_dir        :  F:\\MLDatasets\\coco2014\\annotations/instances_train2014.json\n",
      " number of images     :  82783\n",
      " image_ids[:10]       :  [262145, 131074, 131075, 393221, 393223, 393224, 524297, 393227, 393228, 262146]\n",
      " image_ids[1000:1010] :  [22098, 1518, 132591, 1522, 394739, 525813, 1526, 525815, 327935, 394748]\n",
      "COCO loading annotations file F:\\MLDatasets\\coco2014\\annotations/instances_valminusminival2014.json  into memory...\n",
      "Done (t=11.39s)\n",
      "creating index...\n",
      "index created!\n",
      " loading  all classes\n",
      " image dir            :  F:\\MLDatasets\\coco2014\\val2014\n",
      " json_path_dir        :  F:\\MLDatasets\\coco2014\\annotations/instances_valminusminival2014.json\n",
      " number of images     :  35504\n",
      " image_ids[:10]       :  [262148, 185686, 360073, 393225, 488823, 240301, 131089, 262162, 281512, 458778]\n",
      " image_ids[1000:1010] :  [1856, 221282, 279391, 382603, 371046, 315565, 395083, 460621, 460623, 264017]\n",
      "Prepares complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_class_ids = args.coco_classes\n",
    "dataset_train, train_generator  = prep_coco_dataset([\"train\", 'val35k'], mrcnn_model.config, generator = True, shuffle = False, return_coco =True, load_coco_classes=load_class_ids)\n",
    "dataset_val, val_generator  = prep_coco_dataset([\"train\", 'val35k'], mrcnn_model.config, generator = True, shuffle = False, return_coco =True, load_coco_classes=load_class_ids)\n",
    "# dataset_val, val_generator      = prep_coco_dataset(['minival'], mrcnn_config, generator = True) \n",
    "# class_names = dataset_train.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T14:06:36.865653Z",
     "start_time": "2018-12-09T14:06:36.557278Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inputs:\n",
      " -------\n",
      " index:  0    input name : input_image_meta_1:0                       Type: float32           Shape: (?, ?)\n",
      " index:  1    input name : input_pr_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  2    input name : input_pr_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 23)\n",
      " index:  3    input name : input_gt_hm_norm:0                         Type: float32           Shape: (?, 256, 256, 81)\n",
      " index:  4    input name : input_gt_hm_scores:0                       Type: float32           Shape: (?, 81, 200, 23)\n",
      " Outputs:\n",
      " --------\n",
      " layer:  0    output name: fcn_heatmap_lambda/fcn_hm:0                Type: float32           Shape: (?, 256, 256, 81)\n",
      " layer:  1    output name: fcn_softmax_lambda/fcn_sm:0                Type: float32           Shape: (?, 256, 256, 81)\n",
      " layer:  2    output name: fcn_MSE_loss/fcn_MSE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  3    output name: fcn_BCE_loss/fcn_BCE_loss:0                Type: float32           Shape: (1, 1)\n",
      " layer:  4    output name: fcn_scoring/fcn_hm_scores:0                Type: float32           Shape: (1, 81, 200, 24)\n"
     ]
    }
   ],
   "source": [
    "# mrcnn_model.config.EPOCHS_TO_RUN = 1\n",
    "# mrcnn_model.config.display()  \n",
    "# mrcnn_model.display_layer_info()\n",
    "fcn_model.display_layer_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Display image with Ground Truth bounding boxes and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T11:26:49.650497Z",
     "start_time": "2018-10-25T11:26:49.451199Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch size is : 2\n",
      " load image ud:  75040\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'image_id' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/git_projs/mrcnn3/mrcnn/datagen.py\u001b[0m in \u001b[0;36mdata_gen_simulate\u001b[0;34m(dataset, config, image_index)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' load image ud: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m             \u001b[0;31m# image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 75040 is out of bounds for axis 0 with size 4952",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-65ed07dd3f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatagen\u001b[0m  \u001b[0;32mimport\u001b[0m \u001b[0mdata_gen_simulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# train_batch_x, train_batch_y = next(train_generator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_batch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_gen_simulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrcnn_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m75040\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m89243\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mimgmeta_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_image_meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mimg_meta\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgmeta_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_projs/mrcnn3/mrcnn/datagen.py\u001b[0m in \u001b[0;36mdata_gen_simulate\u001b[0;34m(dataset, config, image_index)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0;31m# Log it and skip the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             logging.exception(\"Error processing image {}\".format(\n\u001b[0;32m--> 946\u001b[0;31m                 dataset.image_info[image_id]))\n\u001b[0m\u001b[1;32m    947\u001b[0m             \u001b[0merror_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'image_id' referenced before assignment"
     ]
    }
   ],
   "source": [
    "## 62642 (persons),   68539 (trucks) 36466 (surfers)  75040 (boat and persons)\n",
    "## 36466 surfers. 5498 basketbal players, 27711,30531\n",
    "## 5498 lots of motorcylces & persons - \n",
    "## Persons: #26026, #7719, 111864, 58240,  \n",
    "## 89243: Person, bicylce and traiffic lights\n",
    "## 35347 - laptops, keyboards and cat\n",
    "## items = [59199 , 102868]\n",
    "## 101623 (cake and forks), 41423 (elephant & people)\n",
    "from mrcnn.datagen  import data_gen_simulate\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "train_batch_x, train_batch_y = test_batch_x, test_batch_y = data_gen_simulate(dataset_train, mrcnn_config, [75040, 89243])\n",
    "imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(mrcnn_config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    print('Image meta  : ', img_meta[img_idx,:10])\n",
    "    print('Classes     : ', class_ids)\n",
    "    print(\"image_id    : \", image_id, ' Reference: ', dataset_train.image_reference(image_id))\n",
    "    print(' class_ids.shape[0]:', class_ids.shape[0], 'bbox.shape[0]:',bbox.shape[0])    \n",
    "    \n",
    "    class_names = [str(dataset_train.class_names[class_id]) for class_id in class_ids]\n",
    "    print('Class Names : ', class_names)\n",
    "    \n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)   \n",
    "    # Display image and instances\n",
    "    visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names, figsize =(8,8))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### other image displays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Display Training / Validation Training set information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T13:41:58.073076Z",
     "start_time": "2018-09-20T13:41:58.017365Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Train Dataset Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Training Dataset Class Count: {}\".format(dataset_train.num_classes))\n",
    "for i, info in enumerate(dataset_train.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "    \n",
    "    \n",
    "print(\"Validation Dataset Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Validation Dataset Class Count: {}\".format(dataset_val.num_classes))\n",
    "for i, info in enumerate(dataset_val.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display top masks for a random group of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T13:42:01.523874Z",
     "start_time": "2018-09-20T13:41:58.075930Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 7)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display a random image with instances and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T13:42:02.368569Z",
     "start_time": "2018-09-20T13:42:01.527170Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load random image and mask.\n",
    "# image_id = np.random.choice(dataset_train.image_ids)\n",
    "\n",
    "\n",
    "image    = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "# Compute Bounding box\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "# Display image and additional stats\n",
    "print(\"image_id \", image_id, dataset_train.image_reference(image_id))\n",
    "log(\"image\", image)\n",
    "log(\"mask\", mask)\n",
    "log(\"class_ids\", class_ids)\n",
    "log(\"bbox\", bbox)\n",
    "print(class_ids.shape[0], bbox.shape[0])\n",
    "# Display image and instances\n",
    "visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN `train_in_batches()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T14:07:39.155965Z",
     "start_time": "2018-12-09T14:07:38.794903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MRCNN-------------------------------------------------------\n",
      "Epochs to run       2 \n",
      "Steps per epochs    32 \n",
      "Batch size          1 \n",
      "Learning Rate       1e-05 \n",
      "Momentum            0.9 \n",
      "Weight Decay:       0.0001 \n",
      "VALIDATION_STEPS    50 \n",
      "--- FCN --------------------------------------------------------\n",
      "Epochs to run       4 \n",
      "Steps per epochs    32 \n",
      "Batch size          1 \n",
      "Learning Rate       0.1 \n",
      "Momentum            0.9 \n",
      "Weight Decay:       0.0002 \n",
      "VALIDATION_STEPS    8 \n",
      "Checkpoint Path:    F:\\models\\train_fcn32_coco\\fcn20181209T1502\\fcn_{epoch:04d}.h5 \n",
      "REDUCE_LR_FACTOR    0.5 \n",
      "REDUCE_LR_COOLDOWN  15 \n",
      "REDUCE_LR_PATIENCE  50 \n",
      "MIN_LR              1e-10 \n",
      "EARLY_STOP_PATIENCE 150 \n"
     ]
    }
   ],
   "source": [
    "from mrcnn.utils import log\n",
    "print('--- MRCNN-------------------------------------------------------')\n",
    "log(\"Epochs to run       {} \".format(mrcnn_model.config.EPOCHS_TO_RUN))\n",
    "log(\"Steps per epochs    {} \".format(mrcnn_model.config.STEPS_PER_EPOCH))\n",
    "log(\"Batch size          {} \".format(mrcnn_model.config.BATCH_SIZE))\n",
    "log(\"Learning Rate       {} \".format(mrcnn_model.config.LEARNING_RATE))\n",
    "log(\"Momentum            {} \".format(mrcnn_model.config.LEARNING_MOMENTUM))\n",
    "log(\"Weight Decay:       {} \".format(mrcnn_model.config.WEIGHT_DECAY       ))\n",
    "log(\"VALIDATION_STEPS    {} \".format(mrcnn_model.config.VALIDATION_STEPS   ))\n",
    "# log(\"Checkpoint Path:    {} \".format(mrcnn_model.checkpoint_path))\n",
    "# log(\"REDUCE_LR_FACTOR    {} \".format(mrcnn_model.config.REDUCE_LR_FACTOR   ))\n",
    "# log(\"REDUCE_LR_COOLDOWN  {} \".format(mrcnn_model.config.REDUCE_LR_COOLDOWN ))\n",
    "# log(\"REDUCE_LR_PATIENCE  {} \".format(mrcnn_model.config.REDUCE_LR_PATIENCE ))\n",
    "# log(\"MIN_LR              {} \".format(mrcnn_model.config.MIN_LR             ))\n",
    "# log(\"EARLY_STOP_PATIENCE {} \".format(mrcnn_model.config.EARLY_STOP_PATIENCE))     \n",
    "\n",
    "fcn_model.config.EPOCHS_TO_RUN  = 4\n",
    "fcn_model.config.LEARNING_RATE  = 0.1\n",
    "\n",
    "print('--- FCN --------------------------------------------------------')\n",
    "log(\"Epochs to run       {} \".format(fcn_model.config.EPOCHS_TO_RUN))\n",
    "log(\"Steps per epochs    {} \".format(fcn_model.config.STEPS_PER_EPOCH))\n",
    "log(\"Batch size          {} \".format(fcn_model.config.BATCH_SIZE))\n",
    "log(\"Learning Rate       {} \".format(fcn_model.config.LEARNING_RATE))\n",
    "log(\"Momentum            {} \".format(fcn_model.config.LEARNING_MOMENTUM))\n",
    "log(\"Weight Decay:       {} \".format(fcn_model.config.WEIGHT_DECAY       ))\n",
    "log(\"VALIDATION_STEPS    {} \".format(fcn_model.config.VALIDATION_STEPS   ))\n",
    "log(\"Checkpoint Path:    {} \".format(fcn_model.checkpoint_path))\n",
    "log(\"REDUCE_LR_FACTOR    {} \".format(fcn_model.config.REDUCE_LR_FACTOR   ))\n",
    "log(\"REDUCE_LR_COOLDOWN  {} \".format(fcn_model.config.REDUCE_LR_COOLDOWN ))\n",
    "log(\"REDUCE_LR_PATIENCE  {} \".format(fcn_model.config.REDUCE_LR_PATIENCE ))\n",
    "log(\"MIN_LR              {} \".format(fcn_model.config.MIN_LR             ))\n",
    "log(\"EARLY_STOP_PATIENCE {} \".format(fcn_model.config.EARLY_STOP_PATIENCE))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:46:20.890332Z",
     "start_time": "2018-12-09T14:08:27.017027Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fcn']\n",
      "['(fcn\\\\_.*)']\n",
      "layers regex : (fcn\\_.*)\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "   0  input_pr_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "   1  block1_conv1           (Conv2D              )   ............................not a layer we want to train ]\n",
      "   2  block1_conv2           (Conv2D              )   ............................not a layer we want to train ]\n",
      "   3  block1_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   4  block2_conv1           (Conv2D              )   ............................not a layer we want to train ]\n",
      "   5  block2_conv2           (Conv2D              )   ............................not a layer we want to train ]\n",
      "   6  block2_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "   7  block3_conv1           (Conv2D              )   ............................not a layer we want to train ]\n",
      "   8  block3_conv2           (Conv2D              )   ............................not a layer we want to train ]\n",
      "   9  block3_conv3           (Conv2D              )   ............................not a layer we want to train ]\n",
      "  10  block3_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  11  block4_conv1           (Conv2D              )   ............................not a layer we want to train ]\n",
      "  12  block4_conv2           (Conv2D              )   ............................not a layer we want to train ]\n",
      "  13  block4_conv3           (Conv2D              )   ............................not a layer we want to train ]\n",
      "  14  block4_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  15  block5_conv1           (Conv2D              )   ............................not a layer we want to train ]\n",
      "  16  block5_conv2           (Conv2D              )   ............................not a layer we want to train ]\n",
      "  17  block5_conv3           (Conv2D              )   ............................not a layer we want to train ]\n",
      "  18  block5_pool            (MaxPooling2D        )   ............................no weights to train ]\n",
      "  19  fc1                    (Conv2D              )   ............................not a layer we want to train ]\n",
      "  20  dropout_1              (Dropout             )   ............................no weights to train ]\n",
      "  21  fc2                    (Conv2D              )   ............................not a layer we want to train ]\n",
      "  22  dropout_2              (Dropout             )   ............................no weights to train ]\n",
      "  23  fcn_classify           (Conv2D              )   TRAIN \n",
      "  24  fcn8_heatmap           (Conv2DTranspose     )   ............................not a layer we want to train ]\n",
      "  25  fcn_heatmap_lambda     (Lambda              )   ............................no weights to train ]\n",
      "  26  input_gt_hm_norm       (InputLayer          )   ............................no weights to train ]\n",
      "  27  input_pr_hm_scores     (InputLayer          )   ............................no weights to train ]\n",
      "  28  fcn_softmax_lambda     (Lambda              )   ............................no weights to train ]\n",
      "  29  fcn_MSE_loss           (Lambda              )   ............................no weights to train ]\n",
      "  30  fcn_BCE_loss           (Lambda              )   ............................no weights to train ]\n",
      "  31  fcn_scoring            (Lambda              )   ............................no weights to train ]\n",
      "    learning rate :  0.1\n",
      "    momentum      :  0.9\n",
      "\n",
      "\n",
      "\n",
      "  Compile Model :\n",
      " ----------------\n",
      "    losses        :  ['fcn_BCE_loss']\n",
      "    optimizer     :  <keras.optimizers.Adam object at 0x0000003F21921748>\n",
      "    learning rate :  0.1\n",
      "    momentum      :  0.9\n",
      "\n",
      " Initial self.keras_model.losses :\n",
      " ---------------------------------\n",
      " losses passed to compile :  ['fcn_BCE_loss']\n",
      " self.keras_model.losses  : \n",
      "\n",
      " Add loss_functions to self.keras_model.losses\n",
      " -------------------------------------\n",
      " --  Loss: fcn_BCE_loss  Related Layer is : fcn_BCE_loss\n",
      "    >> Add add loss for  Tensor(\"fcn_BCE_loss/fcn_BCE_loss:0\", shape=(1, 1), dtype=float32)  to list of losses...\n",
      "\n",
      " self.keras_model.losses after adding loss_functions passed to compile() : \n",
      " ------------------------------------------------------------------------- \n",
      "      0    Tensor(\"Mean:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " --------------------\n",
      "      0    Tensor(\"Mean:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      " Final list of keras_model.losses, after adding L2 regularization as loss to list : \n",
      " ---------------------------------------------------------------------------------- \n",
      "      0    Tensor(\"Mean:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Compile \n",
      " --------\n",
      " Length of Keras_Model.outputs: 5\n",
      "\n",
      " Add Metrics for losses :\n",
      " -------------------------\n",
      " Initial Keras metric_names: ['loss']\n",
      "    Loss name : fcn_BCE_loss  Related Layer is : fcn_BCE_loss\n",
      "    >> Add metric  fcn_BCE_loss  with metric tensor:  fcn_BCE_loss/fcn_BCE_loss:0  to list of metrics ...\n",
      "\n",
      " Final Keras metric_names :\n",
      " --------------------------\n",
      "      0    loss\n",
      "      1    fcn_BCE_loss\n",
      "\n",
      " self.keras_model.losses after adding losses passed to compile() : \n",
      " ----------------------------------------------------------------- \n",
      "      0    Tensor(\"Mean:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._losses:\n",
      " ---------------------\n",
      "      0    Tensor(\"Mean:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      " Keras_model._per_input_losses:\n",
      " ------------------------------\n",
      "      0    None\n",
      "\n",
      "\n",
      " Post-compile out_labels from get_deduped_metrics_names() : \n",
      " ---------------------------------------------------------- \n",
      "     - loss\n",
      "     - fcn_BCE_loss\n",
      "\n",
      " Post-compile Callback metrics monitored by progbar :\n",
      " ----------------------------------------------------\n",
      "     - loss\n",
      "     - fcn_BCE_loss\n",
      "     - val_loss\n",
      "     - val_fcn_BCE_loss\n",
      "\n",
      " Post-compile Keras metric_names :\n",
      " ---------------------------------\n",
      "      0    loss\n",
      "      1    fcn_BCE_loss\n",
      "\n",
      " Post-compile Keras stateful_metric_names :\n",
      " ------------------------------------------\n",
      " \n",
      "Training Start Parameters:\n",
      "--------------------------\n",
      "Starting at epoch     0 of 4 epochs.\n",
      "Steps per epochs      32 \n",
      "Last epoch completed  0 \n",
      "Batch size            1 \n",
      "Learning Rate         0.1 \n",
      "Momentum              0.9 \n",
      "Weight Decay:         0.0002 \n",
      "VALIDATION_STEPS      8 \n",
      "REDUCE_LR_FACTOR      0.5 \n",
      "REDUCE_LR_COOLDOWN    15 \n",
      "REDUCE_LR_PATIENCE    50 \n",
      "MIN_LR                1e-10 \n",
      "EARLY_STOP_PATIENCE   150 \n",
      "Checkpoint Path:      F:\\models\\train_fcn32_coco\\fcn20181209T1502\\fcn_{epoch:04d}.h5 \n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:583: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/32 [============================>.] - ETA: 56s - loss: 0.0624 - fcn_BCE_loss: 0.0624 \n",
      "val_averages : [array([[0.0607]]), array([[0.0607]])]\n",
      "\n",
      "32/32 [==============================] - 2303s 72s/step - loss: 0.0617 - fcn_BCE_loss: 0.0617 - val_loss: 0.0607 - val_fcn_BCE_loss: 0.0607\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06069, saving model to F:\\models\\train_fcn32_coco\\fcn20181209T1502\\fcn_0001.h5\n",
      "Epoch 2/4\n",
      "31/32 [============================>.] - ETA: 53s - loss: 0.0674 - fcn_BCE_loss: 0.0674 \n",
      "val_averages : [array([[0.0443]]), array([[0.0443]])]\n",
      "\n",
      "32/32 [==============================] - 2155s 67s/step - loss: 0.0661 - fcn_BCE_loss: 0.0661 - val_loss: 0.0443 - val_fcn_BCE_loss: 0.0443\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06069 to 0.04433, saving model to F:\\models\\train_fcn32_coco\\fcn20181209T1502\\fcn_0002.h5\n",
      "Epoch 3/4\n",
      "31/32 [============================>.] - ETA: 1:00 - loss: 0.0729 - fcn_BCE_loss: 0.0729\n",
      "val_averages : [array([[0.065]]), array([[0.065]])]\n",
      "\n",
      "32/32 [==============================] - 2379s 74s/step - loss: 0.0718 - fcn_BCE_loss: 0.0718 - val_loss: 0.0650 - val_fcn_BCE_loss: 0.0650\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04433\n",
      "Epoch 4/4\n",
      "27/32 [========================>.....] - ETA: 7:53 - loss: 0.0648 - fcn_BCE_loss: 0.0648"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9d2d54406e4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mdataset_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             )\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN3\\mrcnn\\model_fcn.py\u001b[0m in \u001b[0;36mtrain_in_batches\u001b[1;34m(self, mrcnn_model, train_dataset, val_dataset, layers, losses, learning_rate, epochs, epochs_to_run, batch_size, steps_per_epoch, min_LR, shuffle, augment)\u001b[0m\n\u001b[0;32m   1408\u001b[0m                     \u001b[1;31m## Run prediction on MRCNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1410\u001b[1;33m                         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmrcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1411\u001b[0m                         \u001b[0mfcn_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_batch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1412\u001b[0m                         \u001b[0mfcn_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1170\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1172\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------------------------\n",
    "## Train the FCN only \n",
    "## Passing layers=\"heads\" freezes all layers except the head\n",
    "## layers. You can also pass a regular expression to select\n",
    "## which layers to train by name pattern.\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "train_layers = ['fcn']\n",
    "loss_names   = [\"fcn_BCE_loss\"]\n",
    "fcn_model.config.LAST_EPOCH_RAN = 0\n",
    "fcn_model.epoch = fcn_model.config.LAST_EPOCH_RAN\n",
    "\n",
    "fcn_model.train_in_batches(\n",
    "            mrcnn_model,    \n",
    "            dataset_train,\n",
    "            dataset_val, \n",
    "            layers = train_layers,\n",
    "            losses = loss_names\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T14:24:00.803567Z",
     "start_time": "2018-11-07T14:24:00.756959Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Simulate Train in Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run data through MRCNN and FCN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display model input / output information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:34:35.696820Z",
     "start_time": "2018-10-17T14:34:33.592738Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mrcnn_model.layer_info()\n",
    "print('\\n FCN')\n",
    "fcn_model.layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:34:33.590986Z",
     "start_time": "2018-10-17T14:33:20.870486Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "# model_output = get_layer_output_1(mrcnn_model.keras_model, train_batch_x, [4,5,6,7,9,10,11,12,13,14], 1)\n",
    "# model_output = get_layer_output_1(mrcnn_model.keras_model, train_batch_x, [0,1,2,3,4,5,6,7,9,10,11], 1)\n",
    "model_output = get_layer_output_1(mrcnn_model.keras_model, train_batch_x, [0,1,2,3,4,5], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input and output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:35:47.365657Z",
     "start_time": "2018-10-17T14:35:46.115830Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(model_output))\n",
    "\n",
    "# output_rois               = model_output[0]          # layer:  4   shape: (1, 200, 4)\n",
    "# target_class_ids          = model_output[1]          # layer:  5   shape: (1, 200)\n",
    "# target_bbox_deltas        = model_output[2]          # layer:  6   shape: (1, 200, 4)\n",
    "# roi_gt_boxes              = model_output[3]          # layer:  7   shape: (1, 200, 4)\n",
    "# mrcnn_class               = model_output[4]          # layer:  8   shape: (1, 200, 81)\n",
    "# mrcnn_bbox                = model_output[5]          # layer:  9   shape: (1, 200, 81, 4)\n",
    "# pred_refined_tensor       = model_output[6]          # layer: 16   shape: (1, 81, 25, 7)\n",
    "# output_rois               = model_output[0]          # layer:  0   shape: (2, 200, 4)\n",
    "# target_class_ids          = model_output[1]          # layer:  1   shape: (2, 200)\n",
    "# target_bbox_deltas        = model_output[2]          # layer:  2   shape: (2, 200, 4)\n",
    "# roi_gt_boxes              = model_output[3]          # layer:  3   shape: (2, 200, 4)\n",
    "# mrcnn_class               = model_output[4]          # layer:  4   shape: (2, 200, 81)\n",
    "# mrcnn_bbox                = model_output[5]          # layer:  5   shape: (2, 200, 81, 4)\n",
    "# model_pred_heatmap_norm         = model_output[6]          # layer:  6   shape: (2, 256, 256, 81)\n",
    "# model_pred_heatmap_scores       = model_output[7]          # layer:  7   shape: (2, 81, 25, 11)\n",
    "# model_gt_heatmap_scores         = model_output[8]          # layer:  9   shape: (2, 81, 25, 11)\n",
    "# model_pred_tensor               = model_output[9]          # layer: 10   shape: (2, 81, 25, 8)\n",
    "# model_gt_tensor                 = model_output[10]          # layer: 11   shape: (2, 81, 25, 8)\n",
    "\n",
    "pred_heatmap_norm         = model_output[0]          # layer:  0   shape: (2, 256, 256, 81)\n",
    "pred_heatmap_scores       = model_output[1]          # layer:  1   shape: (2, 81, 200, 11)\n",
    "gt_heatmap_norm           = model_output[2]          # layer:  2   shape: (2, 256, 256, 81)\n",
    "gt_heatmap_scores         = model_output[3]          # layer:  3   shape: (2, 81, 200, 11)\n",
    "pred_tensor               = model_output[4]          # layer:  4   shape: (2, 81, 200, 8)\n",
    "gt_tensor                 = model_output[5]          # layer:  5   shape: (2, 81, 200, 8)\n",
    "for i in model_output:\n",
    "    print( i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:37:20.794299Z",
     "start_time": "2018-10-17T14:37:17.275078Z"
    }
   },
   "outputs": [],
   "source": [
    "# fcn_input = [pred_heatmap_norm, pred_heatmap_scores, gt_heatmap_norm, gt_heatmap_scores] \n",
    "model_output2 = get_layer_output_1(fcn_model.keras_model, fcn_input, [0,1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T17:33:34.842266Z",
     "start_time": "2018-10-15T17:33:34.808415Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image          =  train_batch_x[0]\n",
    "input_image_meta     =  train_batch_x[1]\n",
    "# input_rpn_match      =  train_batch_x[2]\n",
    "# input_rpn_bbox       =  train_batch_x[3]\n",
    "input_gt_class_ids   =  train_batch_x[4]\n",
    "input_gt_bboxes      =  train_batch_x[5]\n",
    "print(' Input image shape is    :', input_image.shape)\n",
    "print(' input_image_meta        :', input_image_meta[0,:10])\n",
    "# print(' input_rpn_match         :', input_rpn_match.shape)\n",
    "# print(' input_rpn_bbox          :', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids      :', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes         :', input_gt_bboxes.shape)\n",
    "# h, w = input_image.shape[1], input_image.shape[2]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "# input_gt_bboxes_norm = tf.identity(input_gt_bboxes / [h,w,h,w])\n",
    "# print(' input_gt_bboxes_norm    :', input_gt_bboxes_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display output from model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `input_gt_class_ids`, `input_gt_bboxes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T17:34:03.805818Z",
     "start_time": "2018-10-15T17:34:02.696855Z"
    },
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(roi_gt_boxes[0,:50] * [1024,1024,1024,1024])\n",
    "print(input_gt_class_ids[0])\n",
    "print(input_gt_bboxes[0,:10])\n",
    "# for i in range(input_gt_class_ids.shape[1]):\n",
    "#     if input_gt_class_ids[0,i] == 1:\n",
    "#         print(input_gt_class_ids[0,i], '   ', input_gt_bboxes[0,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Display `output_rois`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:59:35.184714Z",
     "start_time": "2018-09-26T08:59:35.139366Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img = 0\n",
    "print(' output_rois')\n",
    "print(output_rois.shape)\n",
    "# print(output_rois[0,:40,:])\n",
    "print(output_rois [0,:40,:]* [1024, 1024, 1024, 1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  `max_mrcnn_class` , `argmax_mrcnn_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T16:46:21.282072Z",
     "start_time": "2018-09-22T16:46:21.216616Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "print(' mrcnn_class', mrcnn_class.shape)\n",
    "# print( mrcnn_class[0,0,:])\n",
    "# \n",
    "max_mrcnn_class    = np.max(mrcnn_class, axis = (0,2))\n",
    "argmax_mrcnn_class = np.argmax(mrcnn_class, axis = 2)\n",
    "\n",
    "# print()\n",
    "print('\\n mrcnn_class Max Values   : ', max_mrcnn_class.shape)\n",
    "print(max_mrcnn_class)\n",
    "\n",
    "# print()\n",
    "print(' mrcnn_class Argmax Values: ', argmax_mrcnn_class.shape)\n",
    "print(argmax_mrcnn_class[0])\n",
    "\n",
    "print(' target_class_ds    Values: ', target_class_ids.shape)\n",
    "print(target_class_ids[0])\n",
    "\n",
    "# for i in range(100):\n",
    "#     print('Predicted: ', argmax_mrcnn_class[0,i],  '  Actual ', target_class_ids[0,i])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Display  `target_class_ids()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T09:00:14.575438Z",
     "start_time": "2018-09-26T09:00:14.534931Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(' target_class_ids')\n",
    "print(target_class_ids.shape)\n",
    "print(target_class_ids[0,:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  apply `deltas` from predicted delta `mrcnn_bbox`  to  `output_rois` to obtain refined rois "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:52:01.206727Z",
     "start_time": "2018-09-21T12:52:01.068748Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img_idx = 0 \n",
    "\n",
    "print('output_rois',output_rois.shape, 'deltas ', deltas.shape)\n",
    "cls = 1\n",
    "for i in range(input_gt_class_ids.shape[1]):\n",
    "    if input_gt_class_ids[0,i] == cls:\n",
    "        print(input_gt_class_ids[0,i], '   ', input_gt_bboxes[0,i])\n",
    "\n",
    "        \n",
    "print()        \n",
    "for i in range(output_rois.shape[1]):\n",
    "    if classes[0,i] ==cls:\n",
    "        print(' i ', i, 'class: ',classes[0,i])\n",
    "#         print('   orig           : ', output_rois[0,i])\n",
    "        d1 = deltas[0,i] * mrcnn_config.BBOX_STD_DEV\n",
    "#         print('   delta          : ', deltas[0,i],'   delta * std dev: ', d1)\n",
    "        d2 = utils.apply_box_delta(output_rois[0,i],d1)\n",
    "#         print('   refined        : ', d2)\n",
    "#         print()\n",
    "        print('   orig           : ',output_rois[0,i] * [1024,1024,1024,1024])\n",
    "        print('   refined        : ', d2 * [1024,1024,1024,1024]) \n",
    "        print('   roi_gt_bboxes  : ', roi_gt_boxes[0,i]* [1024,1024,1024,1024]) \n",
    "        print()\n",
    "        print('   pred delta     : ', deltas[0,i] )\n",
    "        print('   tgt delta      : ', target_bbox_deltas[0,i] )\n",
    "        \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Display roi_gt_boxes , and class_ids vs. output_bbox and prediceted class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T16:34:41.699530Z",
     "start_time": "2018-09-22T16:34:41.650195Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(ref_out_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T16:35:45.777944Z",
     "start_time": "2018-09-22T16:35:45.598528Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ref_out_roi1 = ref_out_roi * [1024,1024,1024,1024]\n",
    "print(ref_out_roi1)\n",
    "window = np.array([0,0,1024,1024], dtype =float)\n",
    "print(window.shape)\n",
    "ref_out_roi2  = utils.clip_to_window_np( window, ref_out_roi1)\n",
    "print(ref_out_roi2.shape)\n",
    "for i in range(200):\n",
    "    print(ref_out_roi1[i],' --- ', ref_out_roi2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Display pred_refined_tensor and gt_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T10:00:33.070168Z",
     "start_time": "2018-10-16T10:00:33.031739Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for cls in [1]:\n",
    "    for box in range(20):\n",
    "        print(pred_tensor[0,cls,box])\n",
    "        print(gt_tensor[0,cls,box])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display roi_gt_boxes along with corresponding refined/clipped output_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:41:23.457232Z",
     "start_time": "2018-10-08T13:41:22.950711Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "print(roi_gt_boxes[0].shape, target_class_ids[0].shape , np.expand_dims(target_class_ids[0],axis=-1).shape)\n",
    "classes, deltas = utils.get_predicted_mrcnn_deltas(mrcnn_class, mrcnn_bbox, verbose=True)\n",
    "deltas *= mrcnn_config.BBOX_STD_DEV\n",
    "print('classes.shape: ',classes.shape, ' deltas.shape: ',deltas.shape)\n",
    "\n",
    "ref_out_roi = utils.apply_box_deltas_np(output_rois[img_id],deltas[img_id])\n",
    "#     ##   Clip boxes to image window    \n",
    "# print(ref_out_roi.shape)\n",
    "window = np.array([0,0,1024,1024], dtype =float)\n",
    "clipped_out_roi  = utils.clip_to_window_np( window, ref_out_roi*[1024,1024,1024,1024])\n",
    "\n",
    "for i in range(200):\n",
    "#     ref_out_roi = utils.apply_box_delta_np(output_rois[0],d1[0])\n",
    "#     if classes[img_id,i] == 1 or target_class_ids[img_id,i] == 1 :\n",
    "\n",
    "    print('idx: ',200-i,' GT Cls: ', target_class_ids[img_id,i]  , ' -', roi_gt_boxes[img_id,i]*[1024,1024,1024,1024], \n",
    "                    ' PR Cls: ', classes[img_id,i],' - ', ref_out_roi[i]*[1024.0,1024.0,1024.0,1024.0] ,\n",
    "                     'ClpdCls: ', clipped_out_roi[i]   ) #) *[1024,1024,1024,1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display gt_heatmap_scores and pred_heatmap_scores outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T10:22:55.077601Z",
     "start_time": "2018-10-16T10:22:54.959295Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=200, suppress=True)\n",
    "# print(' gt_tensor')\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[img,:,:10])\n",
    "img_id = 1\n",
    "print(' GT Heatmap Scores')\n",
    "\n",
    "print('gt_heatmap_scores: ', gt_heatmap_scores.dtype,  gt_heatmap_scores.shape)\n",
    "print('pred_heatmap_scores: ', pred_heatmap_scores.dtype,  pred_heatmap_scores.shape)\n",
    "\n",
    "# print(gt_heatmap_scores[img,1])\n",
    "# for img_id in range(mrcnn_config.BATCH_SIZE):\n",
    "\n",
    "for img_id in [0]:    # print(pred_refined_heatmap_scores[img_id,:4])\n",
    "    pr_class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    gt_class_ids = np.unique(gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist() \n",
    "    union_class_ids = np.union1d(pr_class_ids, gt_class_ids)\n",
    "    print('-'*56)\n",
    "    print('Image : {}  GT ClassIds: {}   PR ClassIds: {} '.format(img_id, gt_class_ids, pr_class_ids))\n",
    "    print('Image : {}  Union ClassIds: {}'.format(img_id, union_class_ids))\n",
    "    print('-'*56)\n",
    "    for cls in union_class_ids:  \n",
    "        print()\n",
    "        for i in range(25):\n",
    "#             print(' GT: img_id:',img_id, ' cls: ',cls, ' -',gt_tensor[img_id, cls,i]) #, gt_heatmap_scores[img_id, cls,i,7] )\n",
    "#             print(' PR: img_id:',img_id, ' cls: ',cls, ' -',pred_tensor[img_id,cls,i]) #,pred_refined_heatmap_scores[img_id,cls,i,7])\n",
    "\n",
    "            print(' GT: img/cls:',img_id, '/',cls, ' -',gt_heatmap_scores[img_id, cls,i]) #, gt_heatmap_scores[img_id, cls,i,7] )\n",
    "            print(' PR: img/cls:',img_id, '/',cls, ' -',pred_heatmap_scores[img_id,cls,i]) #,pred_refined_heatmap_scores[img_id,cls,i,7])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Display `Pred_Tensor`, `Pred_heatmap`, `mrcnn_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-19T13:55:40.491731Z",
     "start_time": "2018-09-19T13:55:40.409332Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=4, threshold=None, linewidth=150, suppress=True)\n",
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img = 0\n",
    "\n",
    "# max_score = np.max(mrcnn_class, axis = -1)\n",
    "# max_class = np.argmax(mrcnn_class, axis = -1)\n",
    "# # print(' output_rois[',img,'] \\n', output_rois[1]*[128,128,128,128])\n",
    "# print('max class shape:',max_class.shape, 'max score shape: ',max_score.shape)\n",
    "# print('max class[',img,']\\n',max_class[img])\n",
    "# print('max score[',img,']\\n',max_score[img])\n",
    "# print('mrcnn class.shape ',mrcnn_class.shape)\n",
    "# print('mrcnn_class[',img,',:]\\n',mrcnn_class[img,:])\n",
    "# print(output_rois[1])\n",
    "\n",
    "print('input_gt_class_ids')\n",
    "print(input_gt_class_ids[0])\n",
    "\n",
    "# print(' rpn_bbox')\n",
    "# print(rpn_bbox.shape)\n",
    "# print(rpn_bbox[0,:100,:])\n",
    "\n",
    "# print(' rpn_roi_proposals')\n",
    "# print(rpn_roi_proposals.shape)\n",
    "# print(rpn_roi_proposals[0,:100,:])\n",
    "\n",
    "print(' output_rois')\n",
    "print(output_rois.shape)\n",
    "# print(output_rois[0,:40,:])\n",
    "print(output_rois [0,:40,:]* [1024, 1024, 1024, 1024])\n",
    "\n",
    "print(' target_class_ids')\n",
    "print(target_class_ids.shape)\n",
    "print(target_class_ids[0,:40])\n",
    "# print(output_rois [0,:40,:]* [1024, 1024, 1024, 1024])\n",
    "\n",
    "# print(' Pred_tensor')\n",
    "# print(pred_tensor.shape)\n",
    "# print(pred_tensor[img,:,:10])\n",
    "\n",
    "# print(' gt_tensor')\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[img,:,:10])\n",
    "\n",
    "# print(' mrcnn_class')\n",
    "# print( mrcnn_class.shape)\n",
    "# print( mrcnn_class[0,:,:])\n",
    "\n",
    "# print(' mrcnn_bbox')\n",
    "# print( mrcnn_bbox.shape)\n",
    "# print( mrcnn_bbox)\n",
    "\n",
    "# print(' roi_gt_boxes')\n",
    "# print(roi_gt_boxes.shape)\n",
    "# print(roi_gt_boxes[img,:,:])\n",
    "\n",
    "# print(' Pred Heatmap Scores')\n",
    "# print(pred_heatmap_scores.dtype, pred_heatmap_scores.shape)\n",
    "# print(pred_heatmap_scores[img,1])\n",
    "\n",
    "# print(' FCN Scores')\n",
    "# print(fcn_scores.dtype)\n",
    "# for cls in range(4):\n",
    "#     print(pred_heatmap_scores[img,cls,:10])\n",
    "#     print(fcn_scores[img,cls,:10,2:])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "####  Display `output_rois` for visual check - passed on to  `build_pred_tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:48:00.011050Z",
     "start_time": "2018-10-08T13:47:59.957418Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('output_rois shape is ', output_rois.shape)\n",
    "img = 0\n",
    "for img in [0]:\n",
    "    print('Image ', img , ' ------------')\n",
    "    print(output_rois[img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "####  Display  - `pred_refined_tensor` which is passed on to  `build_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T15:34:53.538773Z",
     "start_time": "2018-10-08T15:34:53.480026Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "img_id = 0\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('model_pred_tensor shape is ', model_pred_tensor.shape)\n",
    "print(input_image_meta[0,:10])\n",
    "pr_class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('Image : {}  PR ClassIds: {} '.format(img_id, pr_class_ids))\n",
    "for k in pr_class_ids:\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(model_pred_tensor[img,k,:30])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Compare  `pred_heatmap_scores` vs. `pred_refined_heatmap_scores`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "##  `build_predictions()`\n",
    "\n",
    "`pred_tensor[:,:,:,1:7]`  == `[116.9736  21.8213  36.2715  45.6026   0.    0.9139   ]`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:52:40.296416Z",
     "start_time": "2018-09-21T12:52:40.217876Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "print('pred_refined_heatmap_scores',pred_refined_heatmap_scores.shape)\n",
    "cls = 1\n",
    "for i in range(input_gt_class_ids.shape[1]):\n",
    "    if input_gt_class_ids[0,i] == cls:\n",
    "        print(input_gt_class_ids[0,i], '   ', input_gt_bboxes[0,i])\n",
    "print()        \n",
    "for i in range(pred_heatmap_scores.shape[2]):\n",
    "#     print(' ref_ten   : ', pred_refined_tensor[0,1,i])\n",
    "    print(' hm_scr    : ', pred_heatmap_scores[0,1,i])\n",
    "    print(' ref_hm_scr: ', pred_refined_heatmap_scores[0,1,i])\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  Setup tensors to be passed to `build_predictions ()`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T13:52:33.994332Z",
     "start_time": "2018-09-26T13:52:33.946512Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mrcnn_bbox  = tf.identity(mrcnn_bbox)\n",
    "mrcnn_class = tf.identity(mrcnn_class)\n",
    "norm_input_rois = tf.identity(output_rois)\n",
    "config      = mrcnn_config\n",
    "sess = KB.get_session()\n",
    "print(' Keras session :', sess)\n",
    "import mrcnn.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T13:52:44.564731Z",
     "start_time": "2018-09-26T13:52:43.827682Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "# def build_refined_predictions(norm_input_rois, mrcnn_class, mrcnn_bbox, config):\n",
    "    '''\n",
    "    Split output_rois by class id, and add class_id and class_score \n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    \n",
    "    pred_tensor:        [ Batchsz, Num_Classes, Num_Rois, 7: (y1, x1, y2, x2, class_id, class_score, normalized class score)]\n",
    "                        \n",
    "                        y1,x1, y2,x2 are in image dimension format\n",
    "    '''\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES\n",
    "    h, w            = config.IMAGE_SHAPE[:2]\n",
    "    # num_rois        = config.TRAIN_ROIS_PER_IMAGE\n",
    "    num_cols        = 6\n",
    "    num_rois        = KB.int_shape(norm_input_rois)[1]\n",
    "    scale           = tf.constant([h,w,h,w], dtype = tf.float32)\n",
    "    # dup_scale       = tf.reshape(tf.tile(scale, [num_rois]),[num_rois,-1])\n",
    "    dup_scale       = scale * tf.ones([batch_size, num_rois, 1], dtype = 'float32')\n",
    "\n",
    "    det_per_class   = config.TRAIN_ROIS_PER_IMAGE ## config.DETECTION_PER_CLASS\n",
    "    \n",
    "    print()\n",
    "    print('  > build_predictions()')\n",
    "    print('    num_rois               : ', num_rois )\n",
    "    print('    norm_input_rois.shape  : ', type(norm_input_rois), KB.int_shape(norm_input_rois))\n",
    "    print('    scale.shape            : ', type(scale), KB.int_shape(scale), scale.get_shape())\n",
    "    print('    dup_scale.shape        : ', type(dup_scale), KB.int_shape(dup_scale), dup_scale.get_shape())\n",
    "    print()\n",
    "    print('    mrcnn_class shape      : ', KB.int_shape(mrcnn_class))\n",
    "    print('    mrcnn_bbox.shape       : ', KB.int_shape(mrcnn_bbox), mrcnn_bbox.shape )\n",
    "    print('    config image shape     : ', config.IMAGE_SHAPE, 'h:',h,'w:',w)\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    # Build a meshgrid for image id and bbox to use in gathering of bbox delta information \n",
    "    #---------------------------------------------------------------------------\n",
    "    batch_grid, bbox_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32),\n",
    "                                         tf.range(num_rois, dtype=tf.int32), indexing = 'ij' )\n",
    "\n",
    "    #------------------------------------------------------------------------------------\n",
    "    # use the argmaxof each row to determine the dominating (predicted) class\n",
    "    #------------------------------------------------------------------------------------\n",
    "    pred_classes     = tf.argmax( mrcnn_class,axis=-1,output_type = tf.int32)\n",
    "    pred_classes_exp = tf.to_float(tf.expand_dims(pred_classes ,axis=-1))    \n",
    "    #     print('    pred_classes : ', pred_classes.shape)\n",
    "    #     print(pred_classes.eval())\n",
    "    #     print('    pred_scores  : ', pred_scores.shape ,'\\n', pred_scores.eval())\n",
    "    #     print('    pred_classes_exp : ', pred_classes_exp.shape)\n",
    "    \n",
    "    gather_ind   = tf.stack([batch_grid , bbox_grid, pred_classes],axis = -1)\n",
    "    pred_scores  = tf.gather_nd(mrcnn_class, gather_ind)\n",
    "    pred_deltas  = tf.gather_nd(mrcnn_bbox , gather_ind)\n",
    "\n",
    "    #------------------------------------------------------------------------------------\n",
    "    # 22-05-2018 - stopped using the following code as it was clipping too many bouding \n",
    "    # boxes to 0 or 128 causing zero area generation\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    ## apply delta refinements to the  rois,  based on deltas provided by the mrcnn head \n",
    "    ##------------------------------------------------------------------------------------\n",
    "    pred_deltas  = tf.multiply(pred_deltas, config.BBOX_STD_DEV, name = 'pred_deltas')\n",
    "    input_rois   = tf.multiply(norm_input_rois , dup_scale )\n",
    "\n",
    "    ## compute \"refined rois\"  utils.apply_box_deltas_tf(input_rois, pred_deltas)\n",
    "    refined_rois   = utils.apply_box_deltas_tf(input_rois, pred_deltas)\n",
    "\n",
    "    ##   Clip boxes to image window    \n",
    "    window = tf.constant([[0,0,h,w]], dtype = tf.float32)\n",
    "    clipped_rois  = utils.clip_to_window_tf( window, refined_rois)\n",
    "    \n",
    "    print('    input_rois.shape       : ', type(input_rois), KB.int_shape(input_rois), input_rois.get_shape())\n",
    "    print('    refined_rois.shape     : ', type(refined_rois), KB.int_shape(refined_rois), refined_rois.get_shape())\n",
    "    print('    refined rois clipped   : ', clipped_rois.shape)\n",
    "    # print('    mrcnn_class : ', mrcnn_class.shape, mrcnn_class)\n",
    "    # print('    gather_ind  : ', gather_ind.shape, gather_ind)\n",
    "    # print('    pred_scores : ', pred_scores.shape )\n",
    "    # print('    pred_deltas : ', pred_deltas.shape )   \n",
    "    # print('    input_rois : ', input_rois.shape, input_rois)\n",
    "    # print('    refined rois: ', refined_rois.shape, refined_rois)\n",
    "        \n",
    "\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    ##  Build Pred_Scatter: tensor of bounding boxes by Image / Class\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    ## sequence id is used to preserve the order of rois as passed to this routine\n",
    "    ##  This may be important in the post matching process but for now it's not being used.\n",
    "    ## 22-09-18 : We need to use this sequence as the sort process based on score will cause\n",
    "    ##            mismatch between the bboxes from output_rois and roi_gt_bboxes\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    sequence = tf.ones_like(pred_classes, dtype = tf.int32) * (bbox_grid[...,::-1] + 1) \n",
    "    sequence = tf.to_float(tf.expand_dims(sequence, axis = -1))   \n",
    "    print('    shape of sequence      : ', sequence.shape)\n",
    "    pred_array  = tf.concat([ clipped_rois, pred_classes_exp , tf.expand_dims(pred_scores, axis = -1), sequence], axis=-1, name = 'pred_array')\n",
    "     \n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # pred_array  = tf.concat([refined_rois, pred_classes_exp , tf.expand_dims(pred_scores, axis = -1)], axis=-1)\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    scatter_ind = tf.stack([batch_grid , pred_classes, bbox_grid],axis = -1)\n",
    "    pred_scatt  = tf.scatter_nd(scatter_ind, pred_array, [batch_size, num_classes, num_rois, pred_array.shape[-1]])\n",
    "    print('    pred_array             : ', pred_array.shape)  \n",
    "    print('    scatter_ind            : ', type(scatter_ind), 'shape', scatter_ind.shape)\n",
    "    print('    pred_scatter           : ', pred_scatt.get_shape())\n",
    "    \n",
    "\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ##  Apply a per class score normalization\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    normalizer   = tf.reduce_max(pred_scatt[...,5], axis = -1, keepdims=True)\n",
    "    normalizer   = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    norm_score   = tf.expand_dims(pred_scatt[...,5]/normalizer, axis = -1)\n",
    "    pred_scatt   = tf.concat([pred_scatt, norm_score],axis = -1)   \n",
    "    print('    - Add normalized score --\\n')\n",
    "    print('    normalizer             : ', normalizer.shape)  \n",
    "    print('    norm_score             : ', norm_score.shape)\n",
    "    print('    pred_scatter           : ', pred_scatt.get_shape())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    ## sort pred_scatter in each class dimension based on bbox scores (last column)\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    _, sort_inds = tf.nn.top_k(pred_scatt[...,6], k=pred_scatt.shape[2])\n",
    "    \n",
    "    # build indexes to gather rows from pred_scatter based on sort order    \n",
    "    class_grid, batch_grid, roi_grid = tf.meshgrid(tf.range(num_classes),tf.range(batch_size), tf.range(num_rois))\n",
    "    roi_grid_exp = tf.to_float(tf.expand_dims(roi_grid, axis = -1))\n",
    "    gather_inds  = tf.stack([batch_grid , class_grid, sort_inds],axis = -1)\n",
    "    \n",
    "    pred_array   = tf.gather_nd(pred_scatt, scatter_ind )\n",
    "    pred_tensor  = tf.gather_nd(pred_scatt, gather_inds[...,:det_per_class,:], name = 'pred_tensor')    \n",
    "\n",
    "    # append an index to the end of each row --- commented out 30-04-2018\n",
    "    # pred_tensor  = tf.concat([pred_tensor, roi_grid_exp], axis = -1)\n",
    "\n",
    "    print('    sort_inds              : ', type(sort_inds)   , ' shape ', sort_inds.shape)\n",
    "    print('    class_grid             : ', type(class_grid)  , ' shape ', class_grid.get_shape())\n",
    "    print('    batch_grid             : ', type(batch_grid)  , ' shape ', batch_grid.get_shape())\n",
    "    print('    roi_grid shape         : ', type(roi_grid)    , ' shape ', roi_grid.get_shape()) \n",
    "    print('    roi_grid_exp           : ', type(roi_grid_exp), ' shape ', roi_grid_exp.get_shape())\n",
    "    print('    gather_inds            : ', type(gather_inds) , ' shape ', gather_inds.get_shape())\n",
    "    print('    pred_array             : ', pred_array.shape, pred_array.get_shape())\n",
    "    print('    pred_tensor            : ', pred_tensor.get_shape())\n",
    "\n",
    "#     return  pred_tensor    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T10:44:44.849028Z",
     "start_time": "2018-09-24T10:44:44.805566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Reshape pred_scatt??  No, doesn't work well as the reshape will convert into [batch_sz, #classes x # bboxes, 8]\n",
    "# btch_sz, cls_sz, bbox_sz, col_sz = pred_scatt.shape\n",
    "# print(btch_sz, cls_sz, bbox_sz, col_sz )\n",
    "# reshape = tf.reshape(pred_scatt, [btch_sz, -1, col_sz])\n",
    "# print(reshape.shape)\n",
    "\n",
    "### This works well, converts pred_scatter back to pred_array (with added normzalized score column)\n",
    "# \n",
    "# reshape = tf.gather_nd(pred_scatt, scatter_ind )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Display `pred_tensor`  from model code and code above, `pred_heatmap_scores`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T13:53:33.492334Z",
     "start_time": "2018-09-26T13:53:33.004813Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_tensor            : ', pred_tensor.get_shape() )\n",
    "print('pred tensor from model : ', model_pred_tensor.shape)\n",
    "with sess.as_default():\n",
    "    r_pred_tensor = pred_tensor.eval()\n",
    "    \n",
    "    \n",
    "for img in range(2):\n",
    "    class_ids = np.unique(r_pred_tensor[img,:,:,4]).astype(int).tolist()    \n",
    "    print('Classids: ', class_ids)\n",
    "    for i in class_ids:\n",
    "        print('Image ', img , '/ Class ',i,' ------------')\n",
    "        for j in range(25):\n",
    "            print(r_pred_tensor[img,i,j])\n",
    "            print(model_pred_tensor[img,i,j])\n",
    "            print(model_pred_heatmap_scores[img,i,j])\n",
    "#             print(pred_heatmap_scores[img,i,j])\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T10:03:58.910808Z",
     "start_time": "2018-09-25T10:03:58.726130Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "with sess.as_default():\n",
    "    print(scatter_ind.shape)\n",
    "    print(pred_scatt.shape)\n",
    "    print(pred_array.shape)\n",
    "#     r_clipped_rois = clipped_rois.eval()\n",
    "    r_pred_array = pred_array.eval()\n",
    "for i in range(200):\n",
    "#     print()\n",
    "#     print('input_ro:  ', r0[0,i]) \n",
    "#     print('original (clipped) :  ', r_clipped_rois[0,i])\n",
    "    print('pred_array         :  ', r_pred_array[0,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T10:05:06.237621Z",
     "start_time": "2018-09-25T10:05:06.190986Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "\n",
    "# with sess.as_default():\n",
    "#     print(pred_scores.eval())\n",
    "#     print(pred_classes.eval())\n",
    "#     print(scatter_ind.eval()[0])\n",
    "#     print(norm_score.eval()[0,9])\n",
    "#     print(pred_array.eval()[0,:200])\n",
    "#     print(scatter_ind.shape)\n",
    "#     print(pred_scatt.shape)\n",
    "#     print(pred_array.shape)\n",
    "#     r_clipped_rois = clipped_rois.eval()\n",
    "#     r_pred_array   = pred_array.eval()\n",
    "#     print(pred_scatt.eval()[0,1,0:200])\n",
    "#     print(normalizer.eval()[0,9])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Some tests on the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Test that refined_rois is correctly working in `clip_to_window_tf` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T13:42:38.351532Z",
     "start_time": "2018-05-18T13:42:37.820120Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    test_np = refined_rois.eval()\n",
    "    test_tf = refined_rois_clipped.eval()\n",
    "    window_np = np.array([0,0,128,128])\n",
    " \n",
    "    print(window_np.shape)\n",
    "    for i in range(5):\n",
    "#         print('Before', i)\n",
    "#         print(test_np[i])\n",
    "        test_np[i] = clip_to_window(window_np, test_np[i])\n",
    "#         print('After', i)\n",
    "#         print(test_np[i])\n",
    "#         print('   tensor flow')\n",
    "#         print(test_tf[i])\n",
    "        \n",
    "    for i in range(5):\n",
    "      all_equal = np.all(test_np == refined_rois_clipped.eval())\n",
    "      print('i: ', i, '--- EQUAL : ', all_equal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Test that pred_classes and pred_deltas have been properly selected when using tf.gather_nd ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T13:32:01.297444Z",
     "start_time": "2018-05-18T13:32:00.765661Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    tmp0 = pred_classes.eval()\n",
    "    tmp1 = mrcnn_bbox.eval()\n",
    "    tmp2 = pred_deltas.eval()\n",
    "    tmp4 = mrcnn_class.eval()\n",
    "    tmp3 = pred_scores2.eval()\n",
    "    tmp5 = pred_scores.eval()\n",
    "    \n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(32):\n",
    "        print('i: ', i, ' j :', j,'--- class: ',tmp0[i,j],'---------------')\n",
    "    #     print(tmp0[i,j])\n",
    "        print(tmp1[i,j])\n",
    "        print(' ===> ', tmp2[i,j])\n",
    "        print(' mrcnn_score: ', tmp4[i,j,tmp0[i,j]], ' pred_score:', tmp5[i,j,0], 'pred_score2: ', tmp3[i,j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false
   },
   "source": [
    "####  Verify refined_rois generated by TF and NP are equal when using `apply_box_deltas_tf( )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T10:48:35.696940Z",
     "start_time": "2018-05-18T10:48:34.824880Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import apply_box_deltas, apply_box_deltas_tf\n",
    "with sess.as_default():\n",
    "    refined_rois_tf = apply_box_deltas_3d(output_rois, pred_deltas).eval()\n",
    "    print(' refined rois_tf: ', refined_rois_tf.shape, refined_rois_tf.dtype)\n",
    "    tmp = []\n",
    "    bxs = output_rois.eval()\n",
    "    dlt = pred_deltas.eval()\n",
    "    for i in range(5):\n",
    "        tmp.append(apply_box_deltas(bxs[i], dlt[i]))\n",
    "    refined_rois_np = np.asarray(tmp)\n",
    "    print(' refined rois_np: ', refined_rois_np.shape,refined_rois_np.dtype)\n",
    "    print(' refined rois_np == refined rois_tf ?? :', np.all(refined_rois_tf[0,1] == refined_rois_np[0,1]))\n",
    "\n",
    "#     for i in range(5):\n",
    "#         for j in range(32):\n",
    "#             all_eq = np.all(refined_rois_tf[0,1] == refined_rois_np[0,1])\n",
    "#             if ~all_eq:\n",
    "#                 print(' Not equal : ',i,'/',j)\n",
    "#                 print(refined_rois_tf[i,j])\n",
    "#                 print(refined_rois_np[i,j])\n",
    "#             else:\n",
    "#                 print(' equal : ',i,'/',j)\n",
    "print(refined_rois_tf[0])\n",
    "print(refined_rois_np[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Prepare values to pass to build_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:50:29.488452Z",
     "start_time": "2018-10-08T13:50:29.445281Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "# def build_heatmap(in_tensor, config, names = None):\n",
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "print(model_pred_tensor.shape)\n",
    "in_tensor = tf.identity(model_pred_tensor)\n",
    "# in_tensor   = pred_tensor\n",
    "# in_array    = pred_array \n",
    "sess = KB.get_session()\n",
    "config = mrcnn_model.config\n",
    "names = ['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  `build_heatmap()` - part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:49:28.181644Z",
     "start_time": "2018-10-08T14:48:56.921962Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():    \n",
    "# def build_heatmap(in_tensor, config, names = None):    \n",
    "    num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "    img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "    heatmap_scale   = config.HEATMAP_SCALE_FACTOR\n",
    "    rois_per_image  = (in_tensor.shape)[2]  \n",
    "    grid_h, grid_w  = config.IMAGE_SHAPE[:2] // heatmap_scale\n",
    "    \n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "    # strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "    print('\\n ')\n",
    "    print('  > NEW build_heatmap() for ', names )\n",
    "    print('    in_tensor shape      : ', in_tensor.shape)       \n",
    "    print('    num bboxes per class : ', rois_per_image )\n",
    "    print('    heatmap scale        : ', heatmap_scale, 'Dimensions:  w:', grid_w,' h:', grid_h)\n",
    "\n",
    "    #-----------------------------------------------------------------------------    \n",
    "    ## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "    #-----------------------------------------------------------------------------\n",
    "    # pt2_ind shape is [?, 3]. \n",
    "    #   pt2_ind[0] corresponds to image_index \n",
    "    #   pt2_ind[1] corresponds to class_index \n",
    "    #   pt2_ind[2] corresponds to roi row_index \n",
    "    # pt2_dense shape is [?, 6]\n",
    "    #    pt2_dense[0] is image index\n",
    "    #    pt2_dense[1:4]  roi cooridnaytes \n",
    "    #    pt2_dense[5]    is class id \n",
    "    #-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,0:4]), axis=-1)\n",
    "    pt2_ind = tf.where(pt2_sum > 0)\n",
    "    pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "    print('    pt2_sum shape ',pt2_sum.shape)\n",
    "    print('    pt2_ind shape :', pt2_ind.shape)\n",
    "    print('    pt2_dense shape ',pt2_dense.get_shape())\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates  \n",
    "    #-----------------------------------------------------------------------------\n",
    "    X = tf.range(grid_w , dtype=tf.int32)\n",
    "    Y = tf.range(grid_h , dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "\n",
    "    # duplicate (repeat) X and Y into a  batch_size x rois_per_image tensor\n",
    "    print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "    ones = tf.ones([tf.shape(pt2_dense)[0] , 1, 1], dtype = tf.int32)\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    print('    Ones:    ', ones.shape)                \n",
    "    print('    ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    print('    ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    pos_grid = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    print('    before transpse ', pos_grid.get_shape())\n",
    "    pos_grid = tf.transpose(pos_grid,[1,2,0,3])\n",
    "    print('    after transpose ', pos_grid.get_shape())    \n",
    "    \n",
    "    pt2_dense_scaled = pt2_dense[:,:4]/heatmap_scale\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "    ##-----------------------------------------------------------------------------\n",
    "    width  = pt2_dense_scaled[:,3] - pt2_dense_scaled[:,1]      # x2 - x1\n",
    "    height = pt2_dense_scaled[:,2] - pt2_dense_scaled[:,0]\n",
    "    cx     = pt2_dense_scaled[:,1] + ( width  / 2.0)\n",
    "    cy     = pt2_dense_scaled[:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)\n",
    "\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ##  Compute Normal Distribution for bounding boxes\n",
    "    ##-----------------------------------------------------------------------------    \n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag(loc = means,  scale_diag = covar)\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    print('    Prob_grid shape before tanspose: ',prob_grid.get_shape())\n",
    "    prob_grid = tf.transpose(prob_grid,[2,0,1])\n",
    "    print('    Prob_grid shape after tanspose : ',prob_grid.get_shape())    \n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## (1) apply normalization per bbox heatmap instance\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    print('\\n    normalization ------------------------------------------------------')   \n",
    "    normalizer = tf.reduce_max(prob_grid, axis=[-2,-1], keepdims = True)\n",
    "    normalizer = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    print('    normalizer     : ', normalizer.shape) \n",
    "    prob_grid_norm = prob_grid / normalizer\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## (2) multiply normalized heatmap by normalized score in in_tensor/ (pt2_dense column 7)\n",
    "    ##     broadcasting : https://stackoverflow.com/questions/49705831/automatic-broadcasting-in-tensorflow\n",
    "    ##---------------------------------------------------------------------------------------------    \n",
    "#  Using the double tf.transpose, we dont need this any more    \n",
    "#     scr = tf.expand_dims(tf.expand_dims(pt2_dense[:,7],axis = -1), axis =-1)\n",
    "\n",
    "    prob_grid_norm_scaled = tf.transpose(tf.transpose(prob_grid_norm) * pt2_dense[:,7])\n",
    "    print('    prob_grid_norm_scaled : ', prob_grid_norm_scaled.shape)\n",
    "#     maxes2 = tf.reduce_max(prob_grid_norm_scaled, axis=[-2,-1], keepdims = True)\n",
    "#     print('    shape of maxes2       : ', maxes2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:38:38.183662Z",
     "start_time": "2018-10-08T14:38:13.395724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    # print(prob_grid_norm.shape)\n",
    "    # r_normalizer = normalizer.eval()    \n",
    "#     r_prob_grid = prob_grid.eval()\n",
    "#     r_prob_grid_norm = prob_grid_norm.eval()\n",
    "#     r_prob_grid_norm_scaled = prob_grid_norm_scaled.eval()\n",
    "    r_maxes2 = maxes2.eval()\n",
    "    r_score  = pt2_dense[:,7].eval()\n",
    "#     r_pt2_dense = pt2_dense.eval()\n",
    "#     r_cx, r_cy  = cx.eval(), cy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:39:12.390360Z",
     "start_time": "2018-10-08T14:39:12.338513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(r_normalizer.shape)\n",
    "# print(r_prob_grid.shape, r_prob_grid_norm.shape)\n",
    "# print(r_maxes0.shape)\n",
    "# print(r_maxes1.shape)\n",
    "print(r_maxes2.shape)\n",
    "print(r_score.shape)\n",
    "# print(r_pt2_dense[:50])\n",
    "for i in range(20):\n",
    "    print('   ', r_score[i], '   ', r_maxes2[i],'  ') # , r_pt2_dense[i],r_cx[i], r_cy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T15:32:15.735805Z",
     "start_time": "2018-09-26T15:32:15.682892Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for y in [111,112,113]:\n",
    "    print(r_prob_grid[0,y,95:115])\n",
    "    print(r_prob_grid_norm[0,y,95:115])\n",
    "    print(r_prob_grid_norm_scaled[0,y,95:115])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T15:49:07.091492Z",
     "start_time": "2018-09-26T15:49:05.482516Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_2d_gaussian, plot_3d_gaussian\n",
    "box = 23\n",
    "plot_3d_gaussian(r_prob_grid[box], zlim = 0.1)\n",
    "plot_3d_gaussian(r_prob_grid_norm[box])\n",
    "plot_3d_gaussian(r_prob_grid_norm_scaled[box])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###   `build_heatmap()` - part 2 - Calculate heatmap sum using old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:50:17.448359Z",
     "start_time": "2018-10-08T14:50:17.355565Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## IMPORTANT: kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "    ## which cause singular sigma cov matrices\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    #     prob_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    ## (3) scatter out the probability distributions based on class \n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    print('\\n    Scatter out the probability distributions based on class --------------') \n",
    "    gauss_scatt   = tf.scatter_nd(pt2_ind, prob_grid_norm_scaled, [batch_size, num_classes, rois_per_image, grid_w, grid_h], name = 'gauss_scatter')\n",
    "    print('    pt2_ind shape   : ', pt2_ind.shape)  \n",
    "    print('    prob_grid shape : ', prob_grid.shape)  \n",
    "    print('    gauss_scatt     : ', gauss_scatt.shape)   # batch_sz , num_classes, num_rois, image_h, image_w\n",
    "    \n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    ## (4) SUM : Reduce and sum up gauss_scattered by class  \n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "    gauss_heatmap = tf.reduce_sum(gauss_scatt, axis=2, name='pred_heatmap2')\n",
    "    # force small sums to zero - for now (09-11-18) commented out but could reintroduce based on test results\n",
    "    # gauss_heatmap = tf.where(gauss_heatmap < 1e-12, gauss_heatmap, tf.zeros_like(gauss_heatmap), name='Where1')\n",
    "    print('    gaussian_heatmap shape     : ', gauss_heatmap.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_heatmap) )      \n",
    "    \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## (5) heatmap normalization\n",
    "    ##     normalizer is set to one when the max of class is zero     \n",
    "    ##     this prevents elements of gauss_heatmap_norm computing to nan\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    print('\\n    normalization ------------------------------------------------------')   \n",
    "    normalizer = tf.reduce_max(gauss_heatmap, axis=[-2,-1], keepdims = True)\n",
    "    print('    normalizer shape       : ', normalizer.shape)    \n",
    "    normalizer = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    gauss_heatmap_norm = gauss_heatmap / normalizer\n",
    "    print('    gauss norm            : ', gauss_heatmap_norm.shape   ,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap_norm) )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Alternative method: use `scatter_nd_add` to build guassian sum\n",
    "requires definition of tf.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:51:09.679531Z",
     "start_time": "2018-10-08T13:51:09.587607Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "#   kvar = KB.variable(value = KB.zeros([batch_size, num_classes, grid_w, grid_h], dtype = 'float32'))\n",
    "#   kvar = tf.scatter_nd_add(kvar, pt2_ind[:,:2],prob_grid)\n",
    "\n",
    "#   kvar_norm  = KB.variable(value = KB.zeros([batch_size, num_classes, grid_w, grid_h], dtype = 'float32'))\n",
    "#   kvar_norm = tf.scatter_nd_add(kvar_norm, pt2_ind[:,:2],prob_grid)\n",
    "\n",
    "    kvar_norm_scaled = KB.variable(value = KB.zeros([batch_size, num_classes, grid_w, grid_h], dtype = 'float32'))\n",
    "    kvar_norm_scaled = KB.zeros([batch_size, num_classes, grid_w, grid_h])\n",
    "    kvar_norm_scaled = tf.scatter_nd_add(kvar_norm_scaled, pt2_ind[:,:2],prob_grid_norm_scaled)\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## heatmap normalization\n",
    "    ## normalizer is set to one when the max of class is zero     \n",
    "    ## this prevents elements of gauss_heatmap_norm computing to nan\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    print('\\n    normalization ------------------------------------------------------')   \n",
    "    normalizer = tf.reduce_max(kvar_norm_scaled, axis=[-2,-1], keepdims = True)\n",
    "    normalizer = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    gaussian_heatmap_norm = kvar_norm_scaled / normalizer\n",
    "    # gauss_heatmap_norm    = gauss_heatmap / tf.reduce_max(gauss_heatmap, axis=[-2,-1], keepdims = True)\n",
    "    # gauss_heatmap_norm    = tf.where(tf.is_nan(gauss_heatmap_norm),  tf.zeros_like(gauss_heatmap_norm), gauss_heatmap_norm, name = 'Where2')\n",
    "    print('    gauss norm            : ', gaussian_heatmap_norm.shape  )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:31:20.741468Z",
     "start_time": "2018-09-26T16:29:40.444137Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "#     r_ghm  = gauss_heatmap.eval()\n",
    "    r_kvar = KB.eval(kvar)\n",
    "    r_kvar_norm = KB.eval(kvar_norm)\n",
    "    r_kvar_norm_scaled = KB.eval(kvar_norm_scaled)\n",
    "    r_kvar_final = kvar_final.eval()\n",
    "#     r_kvar = kvar.eval()\n",
    "#     r_kvar_norm = kvar_norm.eval()\n",
    "#     r_kvar_norm_scaled = kvar_norm_scaled.eval()\n",
    "#     r_kvar_final = kvar_final.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:31:20.835850Z",
     "start_time": "2018-09-26T16:31:20.791378Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(r_kvar.shape, r_kvar_norm.shape, r_kvar_norm_scaled.shape, r_kvar_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:31:20.789145Z",
     "start_time": "2018-09-26T16:31:20.744504Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=4, threshold=30000, linewidth=260, suppress=True)\n",
    "# print(r_kvar.shape, r_ghm.shape)\n",
    "# print(kvar, gauss_heatmap)\n",
    "# for  i in [9]:  #range(81):\n",
    "#     for j in range(256):\n",
    "#         print(' Col: ', j, ': ',np.all(r_kvar[0,i,j] == r_ghm[0,i,j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:32:02.165855Z",
     "start_time": "2018-09-26T16:31:54.694866Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_2d_gaussian, plot_3d_gaussian\n",
    "cls = 1\n",
    "plot_3d_gaussian(r_ghm[0,cls])\n",
    "plot_3d_gaussian(r_kvar[0,cls])\n",
    "plot_3d_gaussian(r_kvar_norm[0,cls])\n",
    "plot_3d_gaussian(r_kvar_final[0,cls])\n",
    "\n",
    "# for i in range(81):\n",
    "#     print(np.max(r_kvar[0,i]), np.max(r_ghm[0,i]), np.sum(r_kvar[0,i]),np.sum(r_ghm[0,i]))\n",
    "# plot_3d_gaussian(r_prob_grid_norm_scaled[box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T09:14:52.264821Z",
     "start_time": "2018-09-26T09:14:52.218973Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(linewidth=150, precision=6)\n",
    "# # print('scatter shape is ', pred_scatt.get_shape())\n",
    "# print('pt2_dense shape is ', pt2_dense.get_shape() )\n",
    "# with sess.as_default():\n",
    "#     r_pt2_ind   = pt2_ind.eval()\n",
    "#     r_pt2_dense = pt2_dense.eval()\n",
    "#     X1,Y1 = tf.meshgrid(tf.range(batch_size, dtype=tf.int32), tf.range(num_detections, dtype=tf.int32), indexing = 'ij')\n",
    "#     r_X1 = X1.eval()\n",
    "#     r_Y1 = Y1.eval()\n",
    "# print(r_X1.shape , Y1.shape)\n",
    "# print(r_X1)\n",
    "# print(r_Y1)\n",
    "# print(r_pt2_ind.shape)\n",
    "# where_to_go = np.stack([r_pt2_ind[:,0],r_pt2_dense[:,4], r_pt2_dense[:,6]],axis =-1)\n",
    "# print(where_to_go.shape)\n",
    "# print(where_to_go)\n",
    "\n",
    "# class_ids = np.unique(r_pt2_dense[:,4]).astype(int).tolist()    \n",
    "# print('Classids: ', class_ids)\n",
    "\n",
    "# for box in range(r_pt2_ind.shape[0]):\n",
    "#     print(r_pt2_ind[box],'      ', r_pt2_dense[box,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T13:17:02.166622Z",
     "start_time": "2018-09-25T13:17:02.123433Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "#     gauss_sum = tf.zeros([batch_size, num_classes, rois_per_image, img_w//scale, img_h//scale])\n",
    "#     print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )      \n",
    "\n",
    "#     counter = 0\n",
    "#     limit   = batch_size * rois_per_image\n",
    "#     c = lambda i, j, k,l: tf.less_equal(i, pt2_ind.get_shape()[0])\n",
    "#     b = lambda i, j, k,l: tf.add(j[k[i]], l[i])\n",
    "#     loop_vars = [counter, gauss_sum, pt2_ind, prob_grid]\n",
    "#     tf.while_loop(c, b, loop_vars)\n",
    "\n",
    "\n",
    "#     print('pt2_dense shape',pt2_dense.shape)\n",
    "#     for i in range(pt2_dense.shape[0]):\n",
    "#         print('i', i, 'pt2_ind[i]',pt2_ind[i].shape)\n",
    "#         gauss_sum[pt2_ind[i,:]] += prob_grid[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:05:49.554110Z",
     "start_time": "2018-09-26T16:05:14.827455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "#     init_sum.initializer()\n",
    "    r_ghm_norm  = gauss_heatmap_norm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:06:14.623280Z",
     "start_time": "2018-09-26T16:06:13.539432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_2d_gaussian, plot_3d_gaussian\n",
    "box = 23\n",
    "plot_3d_gaussian(r_ghm_norm[0,1])\n",
    "plot_3d_gaussian(r_ghm[0,1])\n",
    "# for i in range(81):\n",
    "#     print(np.max(r_kvar[0,i]), np.max(r_ghm[0,i]), np.sum(r_kvar[0,i]),np.sum(r_ghm[0,i]))\n",
    "# plot_3d_gaussian(r_prob_grid_norm_scaled[box])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  `build_heatmap()` - part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:50:35.860403Z",
     "start_time": "2018-10-08T14:50:35.535087Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ##  Generate scores using prob_grid and pt2_dense - NEW METHOD\n",
    "    ##  added 09-21-2018\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    scores_from_sum2 = tf.map_fn(build_hm_score, [prob_grid, pt2_dense_scaled, pt2_dense[:,7]], dtype = tf.float32, swap_memory = True)\n",
    "    scores_scattered = tf.scatter_nd(pt2_ind, scores_from_sum2, [batch_size, num_classes, rois_per_image, 3], name = 'scores_scattered')\n",
    "    gauss_scores = tf.concat([in_tensor, scores_scattered], axis = -1,name = names[0]+'_scores')\n",
    "    print('    scores_scattered shape : ', scores_scattered.shape) \n",
    "    print('    gauss_scores           : ', gauss_scores.shape, ' Name:   ', gauss_scores.name)\n",
    "    print('    gauss_scores  (FINAL)  : ', gauss_scores.shape, ' Keras tensor ', KB.is_keras_tensor(gauss_scores) )      \n",
    "    \n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ##   Normalization is already perfored on the scores at a per_class leve, so we dont use this \n",
    "    ##  code below anympre\n",
    "    ##\n",
    "    ##  This is a regular normalization that moves everything between [0, 1]. \n",
    "    ##  This causes negative values to move to -inf, which is a problem in FCN scoring. \n",
    "    ##  To address this a normalization between [-1 and +1] was introduced in FCN.\n",
    "    ##  Not sure how this will work with training tho.\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    #     normalizer   = tf.reduce_max(scores_scatt[...,-1], axis = -1, keepdims=True)\n",
    "    #     print('norm',normalizer.shape)\n",
    "    #     normalizer   = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    #     norm_score2   = tf.expand_dims(scores_scatt[...,-1]/normalizer, axis = -1)\n",
    "    #     print('norm_SCORE2',norm_score2.shape)\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    #  Generate scores using GAUSS_SUM -- OLD METHOD\n",
    "    #  removed 09-21-2018\n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    #   Generate scores : \n",
    "    #   -----------------\n",
    "    #  NOTE: Score is generated on NORMALIZED gaussian distributions (GAUSS_NORM)\n",
    "    #        If want to do this on NON-NORMALIZED, we need to apply it on GAUSS_SUM\n",
    "    #        Testing demonstated that the NORMALIZED score generated from using GAUSS_SUM \n",
    "    #        and GAUSS_NORM are the same. \n",
    "    #        For now we will use GAUSS_SUM score and GAUSS_NORM heatmap. The reason being that \n",
    "    #        the raw score generated in GAUSS_SUM is much smaller. \n",
    "    #        We may need to change this base on the training results from FCN \n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #   duplicate GAUSS_NORM <num_roi> times to pass along with bboxes to map_fn function\n",
    "    # \n",
    "    #   Here we have a choice to calculate scores using the GAUSS_SUM (unnormalized) or GAUSS_NORM (normalized)\n",
    "    #   after looking at the scores and ratios for each option, I decided to go with the normalized \n",
    "    #   as the numbers are larger\n",
    "    #\n",
    "    #   Examples>\n",
    "    #   Using GAUSS_SUM\n",
    "    # [   3.660313    3.513489   54.475536   52.747402    1.   0.999997    4.998889 2450.          0.00204     0.444867]\n",
    "    # [   7.135149    1.310972   50.020126   44.779854    1.   0.999991    4.981591 1892.          0.002633    0.574077]\n",
    "    # [  13.401865    0.         62.258957   46.636948    1.   0.999971    4.957398 2303.          0.002153    0.469335]\n",
    "    # [   0.          0.         66.42349    56.123024    1.   0.999908    4.999996 3696.          0.001353    0.294958]\n",
    "    # [   0.          0.         40.78952    60.404335    1.   0.999833    4.586552 2460.          0.001864    0.406513]    \n",
    "    #                                                       \n",
    "    #   Using GAUSS_NORM:                             class   r-cnn scr   \n",
    "    # [   3.660313    3.513489   54.475536   52.747402    1.   0.999997 1832.9218   2450.          0.748131    0.479411]\n",
    "    # [   7.135149    1.310972   50.020126   44.779854    1.   0.999991 1659.3965   1892.          0.877059    0.56203 ]\n",
    "    # [  13.401865    0.         62.258957   46.636948    1.   0.999971 1540.4974   2303.          0.668909    0.428645]\n",
    "    # [   0.          0.         66.42349    56.123024    1.   0.999908 1925.3267   3696.          0.520922    0.333813]\n",
    "    # [   0.          0.         40.78952    60.404335    1.   0.999833 1531.321    2460.          0.622488    0.398898]\n",
    "    # \n",
    "    #  to change the source, change the following line gauss_heatmap_norm <--> gauss_heatmap\n",
    "    #---------------------------------------------------------------------------------------------------------------------------\n",
    "    # flatten guassian scattered and input_tensor, and pass on to build_bbox_score routine \n",
    "    # in_shape = tf.shape(in_tensor)\n",
    "    # print('    shape of in_tensor is : ', KB.int_shape(in_tensor))\n",
    "    # in_tensor_flattened  = tf.reshape(in_tensor, [-1, in_shape[-1]])  <-- not a good reshape style!! \n",
    "    # replaced with following line:\n",
    "    # in_tensor_flattened  = tf.reshape(in_tensor, [-1, in_tensor.shape[-1]])\n",
    "    #\n",
    "    #  bboxes = tf.to_int32(tf.round(in_tensor_flattened[...,0:4]))\n",
    "    #\n",
    "    # print('    in_tensor             : ', in_tensor.shape)\n",
    "    # print('    in_tensor_flattened   : ', in_tensor_flattened.shape)\n",
    "    # print('    Rois per class        : ', rois_per_image)\n",
    "    #\n",
    "    #     print('\\n    Scores from gauss_heatmap ----------------------------------------------')\n",
    "    #     temp = tf.expand_dims(gauss_heatmap, axis =2)\n",
    "    #     print('    temp expanded          : ', temp.shape)\n",
    "    #     temp = tf.tile(temp, [1,1, rois_per_image ,1,1])\n",
    "    #     print('    temp tiled shape       : ', temp.shape)\n",
    "    # \n",
    "    #     temp = KB.reshape(temp, (-1, temp.shape[-2], temp.shape[-1]))\n",
    "    #     \n",
    "    #     print('    temp flattened         : ', temp.shape)\n",
    "    #     print('    in_tensor_flattened    : ', in_tensor_flattened.shape)\n",
    "    # \n",
    "    #     scores_from_sum = tf.map_fn(build_hm_score, [temp, in_tensor_flattened], dtype=tf.float32)\n",
    "    #     scores_shape    = [in_tensor.shape[0], in_tensor.shape[1], in_tensor.shape[2], -1]\n",
    "    #     scores_from_sum = tf.reshape(scores_from_sum, scores_shape)    \n",
    "    #     print('    reshaped scores        : ', scores_from_sum.shape)\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    #  tf.reduce_max(scores_from_sum[...,-1], axis = -1, keepdims=True) result is [num_imgs, num_class, 1]\n",
    "    #\n",
    "    #  This is a regular normalization that moves everything between [0, 1]. \n",
    "    #  This causes negative values to move to -inf, which is a problem in FCN scoring. \n",
    "    #  To address this a normalization between [-1 and +1] was introduced in FCN.\n",
    "    #  Not sure how this will work with training tho.\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    #     normalizer   = tf.reduce_max(scores_from_sum[...,-1], axis = -1, keepdims=True)\n",
    "    #     normalizer   = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    #     norm_score   = tf.expand_dims(scores_from_sum[...,-1]/normalizer, axis = -1)\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # Append `in_tensor` and `scores_from_sum` to form `bbox_scores`\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    #     gauss_scores = tf.concat([in_tensor, scores_from_sum, norm_score], axis = -1,name = names[0]+'_scores')\n",
    "    #     print('    scores_from_sum final  : ', scores_from_sum.shape)    \n",
    "    #     print('    norm_score             : ', norm_score.shape)\n",
    "    #     print('    gauss_scores           : ', gauss_scores.shape,  '   name:   ', gauss_scores.name)\n",
    "    #     print('    gauss_scores  (FINAL)  : ', gauss_scores.shape, ' Keras tensor ', KB.is_keras_tensor(gauss_scores) )    \n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:51:30.100497Z",
     "start_time": "2018-10-08T14:51:30.050615Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## //create heatmap Append `in_tensor` and `scores_from_sum` to form `bbox_scores`\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "#     gauss_heatmap      = tf.transpose(gauss_heatmap,[0,2,3,1], name = names[0])\n",
    "###    gauss_heatmap_norm = tf.transpose(gauss_heatmap_norm,[0,2,3,1], name = names[0]+'_norm')\n",
    "\n",
    "### Use heatmap computed from KVAR\n",
    "    gauss_heatmap_norm = tf.transpose(gaussian_heatmap_norm,[0,2,3,1], name = names[0]+'_norm')\n",
    "    \n",
    "    # print('    gauss_heatmap       shape : ', gauss_heatmap.shape     ,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap) )  \n",
    "    # print('    gauss_heatmap_norm  shape : ', gauss_heatmap_norm.shape,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap_norm) )  \n",
    "#     print('    gauss_heatmap       shape : ', gauss_heatmap.shape     ,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap) )  \n",
    "    print('    gauss_heatmap_norm  shape : ', gauss_heatmap_norm.shape,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap_norm) )  \n",
    "    print('    complete')\n",
    "\n",
    "#     return   gauss_heatmap_norm, gauss_scores  # , gauss_heatmap   gauss_heatmap_L2norm    # [gauss_heatmap, gauss_scatt, means, covar]    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:44:31.437678Z",
     "start_time": "2018-10-08T14:44:31.393338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "#     print(pred_array.shape)\n",
    "#     pt2_sum2 = tf.reduce_sum(tf.abs(pred_array[:,:,0:4]), axis=-1)\n",
    "#     r_dense = pt2_dense.eval()\n",
    "#     r_sum = pt2_sum.eval()\n",
    "#     r_ind = pt2_ind.eval()\n",
    "#     r_pred_scores = gauss_scores.eval()\n",
    "# print(r_dense.shape)\n",
    "# print(r_sum.shape)\n",
    "# print(r_ind.shape)\n",
    "# print(r_ind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  `build_hm_score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:51:32.685181Z",
     "start_time": "2018-10-08T13:51:32.605522Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------------------------------------------------          \n",
    "##\n",
    "##----------------------------------------------------------------------------------------------------------------------          \n",
    "    \n",
    "def build_hm_score(input_list):\n",
    "    '''\n",
    "    Inputs:\n",
    "    -----------\n",
    "        heatmap_tensor :    [ image height, image width ]\n",
    "        input_row      :    [y1, x1, y2, x2] in absolute (non-normalized) scale\n",
    "        input_norm_score:   Normalzied score from pred_tensor \n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "        gaussian_sum :      sum of gaussian heatmap vlaues over the area covered by the bounding box\n",
    "        bbox_area    :      bounding box area (in pixels)\n",
    "        weighted_sum :      gaussian_sum * bbox_score\n",
    "    '''\n",
    "    heatmap_tensor, input_bbox, input_norm_score = input_list\n",
    "    \n",
    "    with tf.variable_scope('mask_routine'):\n",
    "        y_extent     = tf.range(input_bbox[0], input_bbox[2])\n",
    "        x_extent     = tf.range(input_bbox[1], input_bbox[3])\n",
    "        Y,X          = tf.meshgrid(y_extent, x_extent)\n",
    "        bbox_mask    = tf.stack([Y,X],axis=2)        \n",
    "        mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "        mask_indices = tf.to_int32(mask_indices)\n",
    "        mask_size    = tf.shape(mask_indices)[0]\n",
    "        mask_updates = tf.ones([mask_size], dtype = tf.float32)    \n",
    "        mask         = tf.scatter_nd(mask_indices, mask_updates, tf.shape(heatmap_tensor))\n",
    "        # mask_sum    =  tf.reduce_sum(mask)\n",
    "        mask_applied = tf.multiply(heatmap_tensor, mask, name = 'mask_applied')\n",
    "        bbox_area    = tf.to_float((input_bbox[2]-input_bbox[0]) * (input_bbox[3]-input_bbox[1]))\n",
    "        gaussian_sum = tf.reduce_sum(mask_applied)\n",
    "\n",
    "#         Multiply gaussian_sum by score to obtain weighted sum    \n",
    "#         weighted_sum = gaussian_sum * input_row[5]\n",
    "\n",
    "#       Replaced lines above with following lines 21-09-2018\n",
    "        # Multiply gaussian_sum by normalized score to obtain weighted_norm_sum \n",
    "        weighted_norm_sum = gaussian_sum * input_norm_score    # input_list[7]\n",
    "\n",
    "    return tf.stack([gaussian_sum, bbox_area, weighted_norm_sum], axis = -1)\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Evaluate results from `build_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:53:08.736373Z",
     "start_time": "2018-10-08T14:51:37.298067Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "with sess.as_default():\n",
    "#     sess.run( tf.global_variables_initializer())\n",
    "#     gauss_scatt         = gauss_scatt.eval()\n",
    "#     pred_heatmap        = gauss_sum.eval()\n",
    "    r_normalizer        = normalizer.eval()\n",
    "    pred_heatmap_norm   = gauss_heatmap_norm.eval()\n",
    "    pred_heatmap_scores = gauss_scores.eval()\n",
    "#     prob_grid           = prob_grid.eval()\n",
    "#     r_scores_from_sum2 = scores_from_sum2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:54:15.949083Z",
     "start_time": "2018-10-08T14:54:15.899465Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img = 0\n",
    "# print(gauss_sum.shape)\n",
    "# print(gauss_scatt.shape)\n",
    "# print(pred_heatmap.shape)\n",
    "print(r_normalizer.shape)\n",
    "print(pred_heatmap_norm.shape)\n",
    "print(model_pred_heatmap_norm.shape)\n",
    "# print(r_scores_from_sum2.shape)\n",
    "print(pred_heatmap_scores.shape)\n",
    "print(model_pred_heatmap_scores.shape)\n",
    "# print(pred_heatmap_scores[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T15:22:09.189978Z",
     "start_time": "2018-10-08T15:22:09.037994Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=250, suppress=True)    \n",
    "# np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "for img in [0]:\n",
    "    class_ids = np.unique(pred_heatmap_scores[img,:,:,4]).astype(int).tolist()    \n",
    "    print('\\n Class ids for img', i, ':',class_ids, '\\n')\n",
    "    for i in class_ids:\n",
    "        print('Image ', img , '/ Class ',i,' ------------ ')        \n",
    "        for j in range(25):\n",
    "            print(' gt    score : ', model_gt_heatmap_scores[img,i,j]) \n",
    "            print(' pred  score : ', pred_heatmap_scores[img,i,j])\n",
    "            print(' model score2: ', model_pred_heatmap_scores[img,i,j])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### compare results of `pred_heatmap_scores` from code above and program file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T15:08:26.001000Z",
     "start_time": "2018-10-08T15:08:25.706504Z"
    },
    "hidden": true,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    " \n",
    "print('pred_heatmap_scores shape is       ', pred_heatmap_scores.shape )\n",
    "print('pred_heatmap_scores from model is :', model_pred_heatmap_scores.shape)\n",
    "# with sess.as_default():\n",
    "#     r_pred_tensor = pred_tensor.eval()\n",
    "for img in [0]:\n",
    "    class_ids = np.unique(pred_heatmap_scores[img,:,:,4]).astype(int).tolist()    \n",
    "    print('Classids: ', class_ids)\n",
    "    for i in class_ids:\n",
    "        print('Image ', img , '/ Class ',i,' ------------ normalizer:', r_normalizer[img,i])\n",
    "        for j in range(200):\n",
    "            print(pred_heatmap_scores[img,i,j])\n",
    "            print(model_pred_heatmap_scores[img,i,j])\n",
    "            if (pred_heatmap_scores[img,i,j,-1] == model_pred_heatmap_scores[img,i,j,-1] == 0):\n",
    "                break\n",
    "#         print(pred_refined_tensor[img,i,j])\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Run TF graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with sess1.as_default():\n",
    "# FeedList = [positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_class_ids, roi_gt_boxes, roi_gt_box_assignment ]\n",
    "# FeedList = [ rois, roi_gt_class_ids,  roi_gt_deltas, roi_gt_boxes]\n",
    "Fetches  = [ pred_heatmap, pred_heatmap_norm, pred_heatmap_scores]\n",
    "tt = sess.run(Fetches)\n",
    "print(type(tt), len(tt))\n",
    "for i in tt:\n",
    "    print(type(i), i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  Plot heatmaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Plot 2D heatmap of  one `pred_heatmap` distribution generated in `build_heatmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:52:41.062772Z",
     "start_time": "2018-10-15T19:52:41.012103Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_one_bbox_heatmap, plot_3d_heatmap, plot_3d_heatmap_all_classes, plot_2d_heatmap, plot_2d_heatmap_with_bboxes\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "print('Image id: ',image_id)\n",
    "img_id = 0\n",
    "class_names = dataset_train.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2D plot of `pred_heatmap_norm` returned from model : `model_pred_heatmap_norm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:17:10.937230Z",
     "start_time": "2018-10-15T19:17:10.901319Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ## range(mrcnn_config.BATCH_SIZE):\n",
    "    # print(pred_refined_heatmap_scores[img_id,:4])\n",
    "    print(pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    \n",
    "#     plot_2d_heatmap_with_bboxes(model_pred_heatmap_norm, model_pred_heatmap_scores, \n",
    "#                                 img_id, [0], width=6, height=6, class_names = class_names, scale = 4)\n",
    "#     plot_2d_heatmap_with_bboxes( pred_heatmap_norm,  pred_heatmap_scores, \n",
    "#                                 img_id, [0], width=6, height=6, class_names = class_names, scale = 4)    \n",
    "    \n",
    "#     plot_2d_heatmap(pred_heatmap_norm, img_id, class_ids, width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  2D plot of `pred_heatmap_norm` returned from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:52:46.738329Z",
     "start_time": "2018-10-15T19:52:46.285921Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [1]:     ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_2d_heatmap_with_bboxes( pred_heatmap_norm,  pred_heatmap_scores, \n",
    "                                img_id, class_ids, width=6, height=6, class_names = class_names, scale = 4)      \n",
    "#     plot_2d_heatmap(model_pred_heatmap_norm, img_id, class_ids, width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  2D plot of `gt_heatmap_norm` returned from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:52:54.964969Z",
     "start_time": "2018-10-15T19:52:54.531072Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [1]:     ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(gt_heatmap_norm.shape)\n",
    "    class_ids = np.unique(gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_2d_heatmap_with_bboxes(gt_heatmap_norm, gt_heatmap_scores, \n",
    "                                img_id, class_ids, width=6, height=6, class_names = class_names, scale = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D plot of `model_pred_heatmap_norm` returned form model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:20:52.897723Z",
     "start_time": "2018-10-15T19:20:52.803582Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(model_pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(model_pred_heatmap_norm, img_id, [37], width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D plot of  `pred_heatmap_norm` returned form code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:53:38.910183Z",
     "start_time": "2018-10-15T19:53:37.370021Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ## range(mrcnn_config.BATCH_SIZE):\n",
    "    print(pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(pred_heatmap_norm, img_id, class_ids, width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D plot of  `gt_heatmap_norm` returned form code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:53:48.031070Z",
     "start_time": "2018-10-15T19:53:43.844950Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [1]: ## range(mrcnn_config.BATCH_SIZE):\n",
    "    print(gt_heatmap_norm.shape)\n",
    "    class_ids = np.unique(gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(gt_heatmap_norm, img_id, class_ids, width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Verfiy max and min of gaussian heatmaps are 1.0 and 0.0, respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:44:33.238584Z",
     "start_time": "2018-10-15T19:44:33.136281Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=200, suppress=True)\n",
    "print(pred_heatmap_norm.shape)\n",
    "hm_max = np.max(pred_heatmap_norm, axis = (1,2))\n",
    "hm_min = np.min(pred_heatmap_norm, axis = (1,2))\n",
    "print(hm_max.shape)\n",
    "for img_id in range(mrcnn_config.BATCH_SIZE):\n",
    "    # print(pred_refined_heatmap_scores[img_id,:4])\n",
    "    class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('\\n Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    print('-'*38)\n",
    "    for cls in class_ids: \n",
    "        print(' class: {}   max: {}  min: {}'.format(cls, hm_max[img_id,cls], hm_min[img_id,cls]))\n",
    "#         print(pred_heatmap_scores[img_id, cls])\n",
    "\n",
    "print(gt_heatmap_norm.shape)\n",
    "hm_max = np.max(gt_heatmap_norm, axis = (1,2))\n",
    "hm_min = np.min(gt_heatmap_norm, axis = (1,2))\n",
    "print(hm_max.shape)\n",
    "for img_id in range(mrcnn_config.BATCH_SIZE):\n",
    "    # print(pred_refined_heatmap_scores[img_id,:4])\n",
    "    class_ids = np.unique(gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('\\n Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    print('-'*38)\n",
    "    for cls in class_ids: \n",
    "        print(' class: {}   max: {}  min: {}'.format(cls, hm_max[img_id,cls], hm_min[img_id,cls]))\n",
    "#         print(pred_heatmap_scores[img_id, cls])\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Display `pred_scatter` heatmaps for all bounding boxes of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:12.230708Z",
     "start_time": "2018-05-20T14:13:10.485070Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "print('Image id: ',image_id , '    Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "img = 1\n",
    "print(pred_heatmap_scores[img,0,0])\n",
    "plot_bbox_heatmaps(gauss_scatt[img], pred_tensor[img], width = 15, height=25, num_bboxes=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Display `gauss_heatmap` heatmap (not normalized, normlized, L2 normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-19T12:54:21.168641Z",
     "start_time": "2018-09-19T12:54:21.110294Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib notebook\n",
    "print('Image id: ',image_id , '    Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "img = 0\n",
    "print(pred_heatmap_scores[img,0,0])\n",
    "# plot_one_heatmap(pred_heatmap[img], pred_heatmap_scores[img], width=19, num_bboxes = 10, title='Non-normalized')\n",
    "plot_gaussian(pred_heatmap_norm[img,:,:,1],0, \n",
    "plot_one_heatmap(pred_heatmap_norm[img], pred_heatmap_scores[img], width=19, num_bboxes = 10, title='normalized')\n",
    "# plot_one_heatmap(pred_heatmap_L2norm[img], pred_heatmap_scores[img], width=19, num_bboxes = 10, title='L2-normalized')\n",
    "# plot_heatmaps(pred_heatmap, pred_heatmap_scores, width = 15, num_bboxes=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Display `gauss_heatmap` 3D heatmap (not normalized, normlized, L2 normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:43:53.940653Z",
     "start_time": "2018-05-20T14:43:52.360486Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_3d_heatmap\n",
    "%matplotlib notebook\n",
    "print('Image id: ',image_id , '    Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "img = 1\n",
    "print(pred_heatmap_scores[img,cls,:10])\n",
    "\n",
    "ttl = 'Non-normalized - image: {}'.format(img)\n",
    "plot_3d_heatmap(pred_heatmap[img], title = ttl, width = 20)\n",
    "plot_one_heatmap(pred_heatmap[img], pred_heatmap_scores[img], width=15, title=ttl)\n",
    "\n",
    "ttl = 'Normalized - image: {}'.format(img)\n",
    "plot_3d_heatmap(pred_heatmap[img], title = ttl, width = 20)\n",
    "plot_one_heatmap(pred_heatmap[img], pred_heatmap_scores[img], width=15, title=ttl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Find maximum of gaussian distributions for the pred_heatmap\n",
    "Potentially use this as our heatmap scores \n",
    "Found out that using MAX values from the class heatmap (currently generated from the pred_tensor that itself is generated form output_rois and mrcnn_class) is not a viable option, because mutlple max values tend to congreagate around the peak of the gaussian distribution. \n",
    "This is also the case for gt_heatmaps.\n",
    "This will probably also be the case for the FCN output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### pred_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:23:37.739059Z",
     "start_time": "2018-05-11T13:23:37.484900Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "\n",
    "print(pred_hm.shape)\n",
    "cls_hm = pred_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print(pred_hm_norm.shape)\n",
    "cls_hm_norm = pred_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:09:06.929477Z",
     "start_time": "2018-05-11T13:09:06.655253Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### gt_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:12.185707Z",
     "start_time": "2018-05-11T13:24:11.932533Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "print(pred_hm.shape)\n",
    "cls_hm = gt_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print('---- norm -----')\n",
    "print(gt_hm_norm.shape)\n",
    "cls_hm_norm = gt_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:14.243495Z",
     "start_time": "2018-05-11T13:24:13.965220Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:48:39.739236Z",
     "start_time": "2018-05-11T11:48:39.479040Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "max_a = np.max(cls_pred_heatmap)\n",
    "print(max_a.shape)\n",
    "\n",
    "print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "print()\n",
    "\n",
    "print(' covar ', covar_sqrd)\n",
    "print(prob_b[35:50, 45:54])\n",
    "max_b = np.max(prob_b)\n",
    "print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "##  `development build_heatmap_tf ()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "### Generate Multivariate Normal Distribution from Pred_Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Prepare values to pass to build_gaussian_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "####  Display for visual check - `pred_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "####  Display for visual check - `gt_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "\n",
    "### Plot heatmap produced by network `fcn_bilinear` and compare with `pred_gaussian`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:56:18.789494Z",
     "start_time": "2018-05-19T20:56:18.196391Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_gaussian, plot_gaussian_2d\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "img = 2\n",
    "cls = 2\n",
    "image_id = input_image_meta[img,0]\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "Zout1 = pred_heatmap     # gt_gaussiam \n",
    "Zout2 = pred_heatmap_norm  # fcn_bilinear\n",
    "Zout3 = pred_heatmap_L2norm  # fcn_bilinear\n",
    "\n",
    "print(Zout1.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "print(pred_tensor[img,cls,:10])\n",
    "print(pred_tensor.shape)\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "\n",
    "width = 9\n",
    "# for j in [cls] : #range(num_classes):\n",
    "print(pred_heatmap_scores[img,cls,:10])\n",
    "ttl = 'Pred_hm      - image :  {} class: {} '.format(img,j)\n",
    "plot_gaussian_2d(Zout1[img,:,:,j], title = ttl, width = width)\n",
    "\n",
    "ttl = 'pred_norm - image :  {} class: {} '.format(img,j)     \n",
    "plot_gaussian_2d(Zout2[img,:,:,j], title = ttl, width = width)  \n",
    "\n",
    "ttl = 'pred_norm_L2 - image :  {} class: {} '.format(img,j)     \n",
    "plot_gaussian_2d(Zout3[img,:,:,j], title = ttl, width = width)  \n",
    "\n",
    "\n",
    "from mrcnn.visualize import display_gt_bboxes, display_roi_proposals\n",
    "model_info = [model, config, dataset_train, train_generator]\n",
    "display_roi_proposals(model_info, input_image_meta, pred_tensor, [cls], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:03:17.009403Z",
     "start_time": "2018-05-19T13:03:16.778767Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "width = 12\n",
    "plot_gaussian2([pred_heatmap_norm, fcn_heatmap_norm], image_idx = 0, title = ttl, width = width)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Test `means`, `covar`, `gauss_grid`, and `gauss_sum ` between development version and final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:10.133108Z",
     "start_time": "2018-05-02T11:10:09.386212Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(means.get_shape(), means.get_shape())\n",
    "tst1 = means.eval()\n",
    "tst2 = means2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:14.482950Z",
     "start_time": "2018-05-02T11:10:14.205020Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = st.eval()\n",
    "tst2 = st2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:18.158709Z",
     "start_time": "2018-05-02T11:10:17.474806Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_grid.eval()\n",
    "tst2 = gauss_grid2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,0,:10])\n",
    "print()\n",
    "print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:23.859635Z",
     "start_time": "2018-05-02T11:10:23.164182Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_sum.eval()\n",
    "tst2 = gauss_sum2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "# print(tst1[0,0,:10])\n",
    "# print()\n",
    "# print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T19:52:46.002369Z",
     "start_time": "2018-05-19T19:52:45.737646Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "from scipy.stats import  multivariate_normal\n",
    "# Build mesh-grid to hold pixel coordinates ----------------------------------\n",
    "XX = np.arange(0, img_w, 1)\n",
    "YY = np.arange(0, img_h, 1)\n",
    "XX, YY = np.meshgrid(XX, YY)\n",
    "print('XX shape', XX.shape)\n",
    "pos  = np.empty(XX.shape + (2,))   # concatinate shape of x to make ( x.rows, x.cols, 2)\n",
    "pos[:,:,0] = XX;\n",
    "pos[:,:,1] = YY;\n",
    "print('XX')\n",
    "print(XX)\n",
    "print('YY')\n",
    "print(YY)\n",
    "print(pos[0,:,:])\n",
    "print(pos[0])\n",
    "print(grid[0].eval())\n",
    "print(' pos type    ', type(pos), type(grid))\n",
    "print(' grid shape ', pos.shape, grid.shape)\n",
    "print(np.all(pos == grid.eval()))\n",
    "mean = np.array([1,2])\n",
    "covar = np.array([[1,0],[0,1]])\n",
    "print(' mean  ', mean)\n",
    "print(' covar ', covar)\n",
    "mvna   = multivariate_normal(mean, covar)\n",
    "prob_a = mvna.pdf(pos)\n",
    "\n",
    "# mvnb = multivariate_normal(mean, covar_sqrd)\n",
    "# prob_b = mvnb.pdf(pos)\n",
    "\n",
    "# print(prob_a[35:50, 45:54])\n",
    "# max_a = np.max(prob_a)\n",
    "# print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "# print()\n",
    "\n",
    "# print(' covar ', covar_sqrd)\n",
    "# print(prob_b[35:50, 45:54])\n",
    "# max_b = np.max(prob_b)\n",
    "# print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "# print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:08:23.894913Z",
     "start_time": "2018-05-19T20:08:22.044145Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates  \n",
    "    #-----------------------------------------------------------------------------\n",
    "    X = tf.range(80, dtype=tf.int32)\n",
    "    Y = tf.range(80, dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "\n",
    "    # duplicate (repeat) X and Y into a  batch_size x rois_per_image tensor\n",
    "    print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "    ones = tf.ones([1, 1, 1], dtype = tf.int32)\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    print('    Ones:    ', ones.shape)                \n",
    "    print('    ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    print('    ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    print('    before transpse ', tf.shape(bef_pos).eval())\n",
    "    pos_grid = tf.transpose(bef_pos,[1,2,0,3])\n",
    "    print('    after transpose ', tf.shape(pos_grid).eval())    \n",
    "    pt2_den = tf.constant([[10,10,30,70]], dtype = tf.float32)\n",
    "    print(type(pt2_den))\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "    #-----------------------------------------------------------------------------\n",
    "    width  = pt2_den[:,3] - pt2_den[:,1]      # x2 - x1\n",
    "    height = pt2_den[:,2] - pt2_den[:,0]\n",
    "    print(width.eval(), type(width))\n",
    "    print(height.eval(), type(height))\n",
    "    cx     = pt2_den[:,1] + tf.div( width  , 2.0)\n",
    "    cy     = pt2_den[:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)\n",
    "    print(means.eval())\n",
    "    print(covar.eval())\n",
    "\n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    print('     Prob_grid shape before tanspose: ',prob_grid.get_shape())\n",
    "    prob_grid = tf.transpose(prob_grid,[2,0,1])\n",
    "    print('     Prob_grid shape after tanspose: ',prob_grid.get_shape())    \n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot Image with bounding boxes from `output_rois`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:53:03.431815Z",
     "start_time": "2018-09-21T12:53:03.337488Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "image_id = input_image_meta[img_idx,0]\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "log(\"image\", image)\n",
    "log(\"mask\", mask)\n",
    "log(\"class_ids\", class_ids)\n",
    "log(\"bbox\", bbox)\n",
    "\n",
    "# class_names = [str(dataset_train.class_names[class_id]) for class_id in class_ids]\n",
    "class_names = dataset_train.class_names\n",
    "# visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print('Classes     : ', class_ids)\n",
    "print(\"image_id    : \", image_id, ' Reference: ', dataset_train.image_reference(image_id))\n",
    "print(' class_ids    : ', class_ids.shape[0])\n",
    "print(' bbox         : ', bbox.shape[0])\n",
    "print(' output_rois: : ', output_rois.shape)\n",
    "print(' Image id     : ', image_id , '  Image meta', img_meta[img_idx,:10])\n",
    "print(' Classes      : ', [class_names[i] for i in class_ids])\n",
    "print(' Image window : ', img_meta[0, 4:8])\n",
    "print(' Image shape  : ', image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display `output_roi` without  delta refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:55:18.047596Z",
     "start_time": "2018-09-21T12:55:17.482833Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unormalized_rois = output_rois[img_idx] * [1024,1024,1024,1024]\n",
    "unrefined_rois   = utils.boxes_to_image_domain(unormalized_rois, img_meta[0] )\n",
    "visualize.draw_rois(image, unrefined_rois, target_class_ids[0], class_names, limit=5) #, random = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display `output_rois` with after clipping to image boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T13:08:25.467820Z",
     "start_time": "2018-09-21T13:08:24.905458Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clipped_rois = utils.clip_to_window_np(img_meta[0, 4:8], unormalized_rois)\n",
    "clipped_rois = utils.boxes_to_image_domain(clipped_rois, img_meta[0] )\n",
    "visualize.draw_rois(image, clipped_rois , target_class_ids[0], class_names, bbox_ids = [0,1,2]) # or , limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Displayt `output_rois` after applying `target_bbox_deltas`\n",
    "\n",
    "NOTE: MUST BE MULTIPLIED BY BBOX_STD_DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T13:08:57.332574Z",
     "start_time": "2018-09-21T13:08:56.776213Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(' Target_bbox_deltas: ',target_bbox_deltas.shape)\n",
    "## 1- Apply Bounding Box Standard Deviation and apply to output_rois\n",
    "apply_deltas = target_bbox_deltas[img_idx] * mrcnn_config.BBOX_STD_DEV\n",
    "refined_rois = utils.apply_box_deltas_np(output_rois[img_idx], apply_deltas)\n",
    "print(' Refined ROIs shape: ',refined_rois.shape)\n",
    "# print(refined_rois[:20])\n",
    "\n",
    "## 3- Clip to image windoow boundaries:\n",
    "refined_rois = refined_rois * [1024,1024,1024,1024]\n",
    "refined_rois = utils.clip_to_window_np(img_meta[0, 4:8], refined_rois)\n",
    "\n",
    "## 4- Transfer to image coordniates :\n",
    "refined_rois = utils.boxes_to_image_domain(refined_rois, img_meta[0] )\n",
    "## 5- Visualize\n",
    "visualize.draw_rois(image, refined_rois, target_class_ids[0], class_names,bbox_ids = [0,1,2], limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Apply predicted `mrcnn_bbox` delta refinements to `output_rois` and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T13:10:07.212107Z",
     "start_time": "2018-09-21T13:10:06.133701Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create un\n",
    "unormalized_rois = output_rois[img_idx] * [1024,1024,1024,1024]\n",
    "clipped_rois = utils.clip_to_window_np(img_meta[0, 4:8], unormalized_rois)\n",
    "unrefined_rois   = utils.boxes_to_image_domain(clipped_rois, img_meta[0] )\n",
    "\n",
    "## 1- Extract predicted deltas from mrcnn_bbox\n",
    "classes, deltas = get_predicted_mrcnn_deltas(mrcnn_class, mrcnn_bbox, verbose = False)\n",
    "# print(classes.shape, deltas.shape)\n",
    "# print(classes[0,:20])\n",
    "# print(deltas[0,:20])\n",
    "\n",
    "\n",
    "## 2- Apply Bounding Box Standard Deviation and apply to output_rois\n",
    "apply_deltas = deltas[0] * mrcnn_config.BBOX_STD_DEV\n",
    "refined_rois = utils.apply_box_deltas_np(output_rois[img_idx], apply_deltas)\n",
    "print(' Refined ROIs shape: ',refined_rois.shape)\n",
    "# print(refined_rois[:20])\n",
    "\n",
    "## 3- Clip to image windoow boundaries:\n",
    "refined_rois = refined_rois * [1024,1024,1024,1024]\n",
    "refined_rois = utils.clip_to_window_np(img_meta[0, 4:8], refined_rois)\n",
    "\n",
    "## 4- Transfer to image coordniates :\n",
    "refined_rois = utils.boxes_to_image_domain(refined_rois, img_meta[0] )\n",
    "\n",
    "# Visualize\n",
    "visualize.draw_rois(image, unrefined_rois, target_class_ids[0], class_names,  limit=5)\n",
    "visualize.draw_rois(image, refined_rois, target_class_ids[0], class_names,  limit=5)\n",
    "# visualize.draw_rois_with_refinements(image, unrefined_rois, refined_rois, target_class_ids[0], class_names, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display `image_gt_bboxes` provided by data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T13:00:26.348261Z",
     "start_time": "2018-09-21T13:00:25.813073Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display image and instances\n",
    "# visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names)   \n",
    "\n",
    "# print(input_gt_bboxes[0,:20])\n",
    "gt_bboxes = utils.boxes_to_image_domain(input_gt_bboxes[0], img_meta[0] )\n",
    "visualize.draw_rois(image, gt_bboxes[:20], input_gt_class_ids[0,:20], class_names, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## misc code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### sparse to dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    tf_dense = tf.sparse_to_dense(pt2_ind), in_tensor.shape[:-1], 1,0)\n",
    "    r_tf_dense = tf_dense.eval()\n",
    "print(r_tf_dense.shape)    \n",
    "print(r_tf_dense[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "####  Display for visual check - `pred_heatmap_norm` is the final result from  `build_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T17:29:35.708474Z",
     "start_time": "2018-05-21T17:29:35.418691Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pred_heatmap_norm.shape)\n",
    "temp = pred_heatmap_norm\n",
    "np.set_printoptions(linewidth=150, threshold=10000, suppress=False)\n",
    "print('  Temp shape :',  temp.shape)\n",
    "temp_sum = np.sum(temp,axis=(1,2))\n",
    "print('temp_sum is ', temp_sum.shape)\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        print('img ',i,' class ', j, ' sum:',temp_sum[i,j],  ' max: ',np.max(temp[i,:,:,j]),' mean: ', np.mean(temp[i,:,:,j]),' min: ', np.min(temp[i,:,:,j]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T18:56:20.286127Z",
     "start_time": "2018-05-21T18:56:19.956192Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6, suppress=True)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_heatmap_scores shape is ', pred_heatmap_scores.shape)\n",
    "for img in [0,1,2]:\n",
    "    for k in range(4):\n",
    "        print('Image ', img , '/ Class ',k,' ------------')\n",
    "        print(np.min(pred_heatmap_scores[img,k,:,8]))\n",
    "        print(pred_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T17:25:18.661505Z",
     "start_time": "2018-05-20T17:25:18.406810Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "print('gt_heatmap_scores shape is ', gt_heatmap_scores.shape)\n",
    "img = 1\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(gt_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T17:12:28.879203Z",
     "start_time": "2018-05-21T17:12:28.616104Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "    temp = fcn_heatmap\n",
    "    np.set_printoptions(linewidth=150, threshold=10000)\n",
    "    print('  output shapes :',  temp.get_shape())\n",
    "    temp_sum = tf.reduce_sum(temp, [2,3])\n",
    "    temp_min = tf.reduce_min(temp, [2,3])\n",
    "    temp_max = tf.reduce_max(temp, [2,3])\n",
    "    temp_avg = tf.reduce_mean(temp, [2,3])\n",
    "    print('temp_sum is ', temp_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "                print('img/cls ',i,'/', j,'  sum:',temp_sum[i,j], 'min',temp_min[i,j] ,'max',temp_max[i,j] ,'avg',temp_avg[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "#### `byclas_to_byimage()` reshape tensor / numpy array from per_class to per image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T18:35:36.921742Z",
     "start_time": "2018-09-25T18:35:36.852068Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def byclass_to_byimage_np(in_array, seqid_column):    \n",
    "    ''' \n",
    "    convert a by class tensor shaped  [batch_size, num_classes, num_bboxes, columns ] to \n",
    "            a by image tensor shaped  [batch_size, num_bboxes, columns]\n",
    "    '''\n",
    "    #     np_sum = np.sum(np.abs(model_gt_heatmap_scores[:,:,:,0:4]), axis=-1)\n",
    "    #     print(np_sum.shape)\n",
    "    #     a,b,c = np.where(np_sum > 0)\n",
    "    a,b,c = np.where(in_array[...,seqid_column]>0)\n",
    "\n",
    "    output = np.zeros((in_array.shape[0],in_array.shape[-2],in_array.shape[-1]))\n",
    "#     print(' output shape is ',output.shape)\n",
    "#     print(a.shape, b.shape,c.shape)\n",
    "    \n",
    "    for img, cls , box in zip(a, b,c):\n",
    "#         print( img,cls, box, 200 - in_array[img, cls, box,6].astype(int))\n",
    "        output[img, 200 - in_array[img, cls, box,6].astype(int)] = in_array[img, cls, box]\n",
    "\n",
    "    return output\n",
    "\n",
    "def byclass_to_byimage_tf(in_array, seqid_column):    \n",
    "    ''' \n",
    "    convert a by class tensor shaped  [batch_size, num_classes, num_bboxes, columns ] to \n",
    "            a by image tensor shaped  [batch_size, num_bboxes, columns]\n",
    "    '''\n",
    "    aa = tf.reshape(in_array, [in_array.shape[0], -1, in_array.shape[-1]])\n",
    "    _ , sort_inds = tf.nn.top_k(tf.abs(aa[:,:,seqid_column]), k= in_array.shape[2])\n",
    "    batch_grid, bbox_grid = tf.meshgrid(tf.range(in_array.shape[0]), tf.range(in_array.shape[2]),indexing='ij')\n",
    "    gather_inds = tf.stack([batch_grid, sort_inds],axis = -1)\n",
    "    output = tf.gather_nd(aa, gather_inds )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Try `byclass_to_byimage()` on `gt_heatmap_scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T18:20:28.345294Z",
     "start_time": "2018-09-25T18:20:27.629896Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print(gt_heatmap_scores.shape)\n",
    "# outp = byclass_to_byimage_tf(gt_heatmap_scores,6)\n",
    "# with sess.as_default():\n",
    "#      r_outp = outp.eval()\n",
    "# print(r_outp.shape)\n",
    "# print(r_outp[0])\n",
    "# print(r_outp[1])\n",
    "\n",
    "\n",
    "# print(tf_model_pred_heatmap_scores.shape, tf_model_pred_heatmap_scores)\n",
    "# outp = byclass_to_byimage_tf(tf_model_pred_heatmap_scores,6)\n",
    "# with sess.as_default():\n",
    "#      r_outp = outp.eval()\n",
    "# print(r_outp.shape)\n",
    "# print(r_outp[0])\n",
    "# print(r_outp[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Try `byclass_to_byimage()` on `pred_heatmap_scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T18:35:43.684389Z",
     "start_time": "2018-09-25T18:35:42.799114Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "\n",
    "tf_model_pred_heatmap_scores = tf.constant(model_pred_heatmap_scores) \n",
    "\n",
    "print('pred_heatmap_scores shape is       ', pred_heatmap_scores.shape )\n",
    "print('pred_heatmap_scores from model is :', tf_model_pred_heatmap_scores.shape,tf_model_pred_heatmap_scores)\n",
    "r_out2 = byclass_to_byimage_np(pred_heatmap_scores,6)\n",
    "\n",
    "with sess.as_default():\n",
    "    r_out1 = byclass_to_byimage_tf(tf_model_pred_heatmap_scores,6).eval()\n",
    "\n",
    "for img in range(2):\n",
    "    class_ids = np.unique(pred_heatmap_scores[img,:,:,4]).astype(int).tolist()    \n",
    "    print('Classids: ', class_ids)\n",
    "    print('Image ', img ,' ------------')\n",
    "    for j in range(200):\n",
    "        print('tf: ',r_out1[img,j])\n",
    "        print('np: ',r_out2[img,j])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### ground work for writing `byclass_to_by_image()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T17:12:56.458588Z",
     "start_time": "2018-09-25T17:12:55.776329Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(pred_heatmap_scores.shape)\n",
    "# gt_heatmap_scores = tf.identity(model_gt_heatmap_scores)\n",
    "# aa = tf.reshape(gt_heatmap_scores, [gt_heatmap_scores.shape[0], -1, gt_heatmap_scores.shape[-1]])\n",
    "# _ , sort_inds = tf.nn.top_k(tf.abs(aa[:,:,6]), k=gt_heatmap_scores.shape[2])\n",
    "# print(sort_inds.shape)\n",
    "# batch_grid, bbox_grid = tf.meshgrid(tf.range(batch_size), tf.range(gt_heatmap_scores.shape[2]),indexing='ij')\n",
    "# gather_inds = tf.stack([batch_grid, sort_inds],axis = -1)\n",
    "# print(aa.shape)\n",
    "# print(bb.shape)\n",
    "# cc = tf.gather_nd(aa, gather_inds )\n",
    "# print('cc : ',cc.shape)\n",
    "# with sess.as_default():\n",
    "# #     r_pred_heatmap_scores = gauss_scores.eval()\n",
    "#     r_aa = aa.eval()\n",
    "#     r_sort_inds = sort_inds.eval()\n",
    "#     r_gather_inds = gather_inds.eval()\n",
    "# #     r_bb = bb.eval()\n",
    "#     r_cc = cc.eval()\n",
    "# #     r_dd = dd.eval()\n",
    "# # print(r_pred_heatmap_scores[0,1])\n",
    "# print('cc: ',r_cc.shape)\n",
    "# print('bb: ',r_bb.shape)\n",
    "# print('aa: ',r_aa.shape)\n",
    "# # print(r_sort_inds)\n",
    "# print(r_gather_inds)\n",
    "# # print(r_bb)\n",
    "# print(r_cc[0])\n",
    "print(r_cc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Convert `pred_heatmap_scores` using `byclass_to_byimage_np`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T16:03:29.189366Z",
     "start_time": "2018-09-25T16:03:29.110660Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print(model_pred_heatmap_scores.shape)\n",
    "print(model_pred_heatmap_scores[0,0,0])\n",
    "outp = byclass_to_byimage_np(model_pred_heatmap_scores,6)\n",
    "print(outp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Convert `gt_heatmap_scores` using `byclass_to_byimage_np`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T15:51:19.844675Z",
     "start_time": "2018-09-25T15:51:19.746388Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "\n",
    "# print('pred_heatmap_scores shape is       ', gt_heatmap_scores.shape )\n",
    "print('pred_heatmap_scores from model is :', model_gt_heatmap_scores.shape)\n",
    "print(model_gt_heatmap_scores[0,1])\n",
    "\n",
    "# with sess.as_default():\n",
    "#     r_pred_tensor = pred_tensor.eval()\n",
    "# for img in range(2):\n",
    "#     class_ids = np.unique(model_gt_heatmap_scores[img,:,:,4]).astype(int).tolist()    \n",
    "#     print('Classids: ', class_ids)\n",
    "#     for i in class_ids:\n",
    "#         print('Image ', img , '/ Class ',i,' ------------')\n",
    "#         for j in range(200):\n",
    "#             print(gt_heatmap_scores[img,i,j])\n",
    "#             print(model_gt_heatmap_scores[img,i,j])\n",
    "# #         print(pred_refined_tensor[img,i,j])\n",
    "#         print()\n",
    " \n",
    "outp = byclass_to_byimage_np(model_gt_heatmap_scores,6)\n",
    "print(outp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "####  Display for visual check - `pred_heatmap_scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T16:49:31.958039Z",
     "start_time": "2018-05-19T16:49:31.945996Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_heatmap_scores shape is ', pred_heatmap_scores.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(pred_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "####  Display for visual check - `pred_heatmap_norm`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T20:33:24.888916Z",
     "start_time": "2018-05-17T20:33:24.652795Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(pred_heatmap_norm.shape)\n",
    "temp = pred_heatmap_norm\n",
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "print('  Temp shape :',  temp.shape)\n",
    "temp_sum = np.sum(temp,axis=(1,2))\n",
    "print('temp_sum is ', temp_sum.shape)\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "            print('img ',i,' class ', j, ' sum:',temp_sum[i,j])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF]",
   "language": "python",
   "name": "conda-env-TF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
