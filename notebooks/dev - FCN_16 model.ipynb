{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Development notebook  FCN model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T11:36:00.986512Z",
     "start_time": "2018-10-23T11:36:00.896146Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      " Linx  Linux\n",
      "Tensorflow Version: 1.8.0   Keras Version : 2.1.6 \n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "# %matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os, random, pprint\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.utils as utils\n",
    "from mrcnn.datagen         import data_generator, load_image_gt, data_gen_simulate\n",
    "from mrcnn.callbacks       import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils           import mask_string, parse_image_meta, apply_box_deltas_tf\n",
    "from mrcnn.prep_notebook   import mrcnn_coco_test, mrcnn_coco_train, fcn_coco_train, prep_coco_dataset\n",
    "\n",
    "from mrcnn.coco         import CocoDataset, CocoConfig, CocoInferenceConfig, evaluate_coco, build_coco_results\n",
    "import mrcnn.model_fcn    as fcn_modellib\n",
    "from mrcnn.utils           import log, Paths\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4,threshold=1000, suppress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Setup MRCNN model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T14:20:03.241004Z",
     "start_time": "2018-10-20T14:19:29.379849Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mrcnn_model, mrcnn_config = mrcnn_coco_train(mode = 'trainfcn')\n",
    "dataset_val, val_generator = prep_coco_dataset(['train', 'val35k'], mrcnn_config, generator = True)\n",
    "dataset_train, train_generator = prep_coco_dataset(['minival'], mrcnn_config, generator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T14:20:18.094188Z",
     "start_time": "2018-10-20T14:20:13.091350Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# exclude=[\"mrcnn_class_logits\"] # ,\"mrcnn_bbox_fc\"]   #, \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "mrcnn_model.load_model_weights(init_with = 'last', exclude = None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T14:13:47.951408Z",
     "start_time": "2018-10-20T14:13:47.900527Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mrcnn_model.config.EPOCHS_TO_RUN = 1\n",
    "mrcnn_model.config.display()  \n",
    "mrcnn_model.layer_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Display Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  Display image with Ground Truth bounding boxes and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T14:21:01.431810Z",
     "start_time": "2018-10-20T14:20:59.633184Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 62642 (persons),   68539 (trucks) 36466 (surfers)  75040 (boat and persons)\n",
    "## 36466 surfers. 5498 basketbal players, 27711,30531\n",
    "## 5498 lots of motorcylces & persons - \n",
    "## Persons: #26026, #7719, 111864, 58240,  \n",
    "## 89243: Person, bicylce and traiffic lights\n",
    "## 35347 - laptops, keyboards and cat\n",
    "## items = [59199 , 102868]\n",
    "## 101623 (cake and forks), 41423 (elephant & people)\n",
    "from mrcnn.datagen  import data_gen_simulate\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "train_batch_x, train_batch_y = test_batch_x, test_batch_y = data_gen_simulate(dataset_train, mrcnn_config, [75040, 89243])\n",
    "imgmeta_idx = mrcnn_model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(mrcnn_config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    print('Image meta  : ', img_meta[img_idx,:10])\n",
    "    print('Classes     : ', class_ids)\n",
    "    print(\"image_id    : \", image_id, ' Reference: ', dataset_train.image_reference(image_id))\n",
    "    print(' class_ids.shape[0]:', class_ids.shape[0], 'bbox.shape[0]:',bbox.shape[0])    \n",
    "    \n",
    "    class_names = [str(dataset_train.class_names[class_id]) for class_id in class_ids]\n",
    "    print('Class Names : ', class_names)\n",
    "    \n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)   \n",
    "    # Display image and instances\n",
    "    visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names, figsize =(8,8))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### other image displays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Display Training / Validation Training set information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T13:41:58.073076Z",
     "start_time": "2018-09-20T13:41:58.017365Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Train Dataset Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Training Dataset Class Count: {}\".format(dataset_train.num_classes))\n",
    "for i, info in enumerate(dataset_train.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "    \n",
    "    \n",
    "print(\"Validation Dataset Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Validation Dataset Class Count: {}\".format(dataset_val.num_classes))\n",
    "for i, info in enumerate(dataset_val.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display top masks for a random group of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T13:42:01.523874Z",
     "start_time": "2018-09-20T13:41:58.075930Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 7)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display a random image with instances and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T13:42:02.368569Z",
     "start_time": "2018-09-20T13:42:01.527170Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load random image and mask.\n",
    "# image_id = np.random.choice(dataset_train.image_ids)\n",
    "\n",
    "\n",
    "image    = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "# Compute Bounding box\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "# Display image and additional stats\n",
    "print(\"image_id \", image_id, dataset_train.image_reference(image_id))\n",
    "log(\"image\", image)\n",
    "log(\"mask\", mask)\n",
    "log(\"class_ids\", class_ids)\n",
    "log(\"bbox\", bbox)\n",
    "print(class_ids.shape[0], bbox.shape[0])\n",
    "# Display image and instances\n",
    "visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load FCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T11:51:23.904630Z",
     "start_time": "2018-10-23T11:51:23.813363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initialize Paths\n",
      " Linx  Linux\n",
      "\n",
      "Paths:\n",
      "-------------------------\n",
      "COCO_DATASET_PATH              /home/kbardool/MLDatasets/coco2014\n",
      "COCO_MODEL_PATH                /home/kbardool/PretrainedModels/mask_rcnn_coco.h5\n",
      "DIR_DATASET                    /home/kbardool/MLDatasets\n",
      "DIR_PRETRAINED                 /home/kbardool/PretrainedModels\n",
      "DIR_ROOT                       /home/kbardool/git_projs/mrcnn3/notebooks\n",
      "DIR_TRAINING                   /home/kbardool/models\n",
      "FCN_TRAINING_PATH              /home/kbardool/models/train_fcn_coco\n",
      "FCN_VGG16_MODEL_PATH           /home/kbardool/PretrainedModels/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "RESNET_MODEL_PATH              /home/kbardool/PretrainedModels/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "TRAINING_PATH                  /home/kbardool/models/train_mrcnn_coco\n",
      "VGG16_MODEL_PATH               /home/kbardool/PretrainedModels/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            50\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [256 256]\n",
      "FCN_VGG16_MODEL_PATH           /home/kbardool/PretrainedModels/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.01\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "NAME                           fcn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    81\n",
      "OPTIMIZER                      ADAGRAD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             50\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             33\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                4\n",
      "SYSOUT                         screen\n",
      "TRAINING_PATH                  /home/kbardool/models/train_fcn_coco\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build configuration for FCN model\n",
    "##------------------------------------------------------------------------------------\n",
    "paths = Paths()\n",
    "fcn_config = CocoConfig()\n",
    "# fcn_config.IMAGE_MAX_DIM        = 600\n",
    "# fcn_config.IMAGE_MIN_DIM        = 480      \n",
    "fcn_config.NAME                 = 'fcn'              \n",
    "fcn_config.BATCH_SIZE           = 1 # mrcnn_config.BATCH_SIZE                 # Batch size is 2 (# GPUs * images/GPU).\n",
    "fcn_config.IMAGES_PER_GPU       = 1 # mrcnn_config.BATCH_SIZE               # Must match BATCH_SIZE\n",
    "\n",
    "fcn_config.FCN_INPUT_SHAPE      = fcn_config.IMAGE_SHAPE[0:2] // 4            # mrcnn_config.HEATMAP_SCALE_FACTOR \n",
    "fcn_config.FCN_VGG16_MODEL_PATH = paths.FCN_VGG16_MODEL_PATH\n",
    "fcn_config.TRAINING_PATH        = paths.FCN_TRAINING_PATH\n",
    " \n",
    "fcn_config.STEPS_PER_EPOCH      = 4\n",
    "fcn_config.EPOCHS_TO_RUN        = 2\n",
    "fcn_config.LEARNING_RATE        = 0.01 \n",
    "fcn_config.LAST_EPOCH_RAN       = 0\n",
    "fcn_config.WEIGHT_DECAY         = 2.0e-4\n",
    "fcn_config.VALIDATION_STEPS     = 5\n",
    "fcn_config.REDUCE_LR_FACTOR     = 0.5\n",
    "fcn_config.REDUCE_LR_COOLDOWN   = 50\n",
    "fcn_config.REDUCE_LR_PATIENCE   = 33\n",
    "fcn_config.EARLY_STOP_PATIENCE  = 50\n",
    "fcn_config.EARLY_STOP_MIN_DELTA = 1.0e-4\n",
    "fcn_config.MIN_LR               = 1.0e-10\n",
    "fcn_config.NEW_LOG_FOLDER       = True  \n",
    "fcn_config.OPTIMIZER            = 'ADAGRAD'\n",
    "fcn_config.SYSOUT               = 'screen'\n",
    "\n",
    "paths.display()\n",
    "fcn_config.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T11:51:34.919640Z",
     "start_time": "2018-10-23T11:51:34.388581Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initialize ModelBase model \n",
      "   Mode      :  training\n",
      "   Model dir :  /home/kbardool/models/train_fcn_coco\n",
      ">>> ModelBase initialiation complete\n",
      ">>> Initialize FCN model, mode:  training architecture:  FCN32\n",
      "NewFolder: False  config.NEW_LOG_FOLDER: True \n",
      "  set_log_dir(): self.Checkpoint_path: /home/kbardool/models/train_fcn_coco/fcn20181023T1151/fcn_{epoch:04d}.h5 \n",
      "  set_log_dir(): self.log_dir        : /home/kbardool/models/train_fcn_coco/fcn20181023T1151 \n",
      "  set_log_dir(): Last completed epoch (self.epoch): 0 \n",
      "arch set to FCN32\n",
      "<function fcn32_graph at 0x7fc632629048>\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "   Arch:  FCN32  Adding  FCN layers\n",
      "---------------------------------------------------\n",
      "\n",
      ">>> FCN Layer \n",
      "     feature map      : (?, 256, 256, 81)\n",
      "     height : 256 width : 256 classes : 81\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "   FCN Block 11 shape is :  (?, 256, 256, 64)\n",
      "   FCN Block 12 shape is :  (?, 256, 256, 64)\n",
      "   FCN Block 13 shape is :  (?, 128, 128, 64)\n",
      "   FCN Block 21 shape is :  (?, 128, 128, 128)\n",
      "   FCN Block 22 shape is :  (?, 128, 128, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (?, 64, 64, 128)\n",
      "   FCN Block 31 shape is :  (?, 64, 64, 256)\n",
      "   FCN Block 32 shape is :  (?, 64, 64, 256)\n",
      "   FCN Block 33 shape is :  (?, 64, 64, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (?, 32, 32, 256)\n",
      "   FCN Block 41 shape is :  (?, 32, 32, 512)\n",
      "   FCN Block 42 shape is :  (?, 32, 32, 512)\n",
      "   FCN Block 43 shape is :  (?, 32, 32, 512)\n",
      "   FCN Block 44 (Max pooling) shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 51 shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 52 shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 53 shape is :  (?, 16, 16, 512)\n",
      "   FCN Block 54 (Max pooling) shape is :  (?, 8, 8, 512)\n",
      "   FCN fully connected 1 (fcn_fc1) shape is :  (?, 8, 8, 4096)\n",
      "   FCN fully connected 2 (fcn_fc2) shape is :  (?, 8, 8, 4096)\n",
      "   FCN final conv2d (fcn_classify) shape is :  (?, 8, 8, 81)  keras_tensor  True\n",
      "   h_factor :  32.0 w_factor :  32.0\n",
      "\n",
      ">>> BilinearUpSampling2D layer\n",
      "     data_format :  channels_last\n",
      "     size        :  (32.0, 32.0)\n",
      "     target_size :  None\n",
      "     input_spec  :  [InputSpec(ndim=4)]\n",
      "     call resize_images_bilinear with size:  (32.0, 32.0)\n",
      "     CHANNELS LAST: X:  (?, 8, 8, 81)  KB.int_shape() :  (None, 8, 8, 81)\n",
      "     target_height   :  None  target_width  :  None\n",
      "     new_shape (2):  (2,) (2,)\n",
      "     new_shape (3):  (2,) (2,)\n",
      "     X after image.resize_bilinear:  (?, ?, ?, 81)\n",
      "     Dimensions of X after set_shape() :  (?, 256, 256, 81)\n",
      "     BilinearUpSampling2D. compute_output_shape()\n",
      "     Bilinear output shape is: None , 256 , 256 , 81\n",
      "   FCN Bilinear upsmapling layer  shape is :  (?, 256, 256, 81)  Keras tensor  True\n",
      "\n",
      "    fcn_heatmap       :  (?, 256, 256, 81)  Keras tensor  True\n",
      "   fcn_heatmap      :  (None, 256, 256, 81)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      ">>> fcn_heatmap_loss_graph \n",
      "---------------------------\n",
      "    target_masks : (?, 256, 256, 81) Tensor(\"fcn_heatmap_loss_4/Shape:0\", shape=(4,), dtype=int32) KerasTensor:  True\n",
      "    pred_heatmap : (?, 256, 256, 81) Tensor(\"fcn_heatmap_loss_4/Shape_1:0\", shape=(4,), dtype=int32) KerasTensor:  True\n",
      "    loss      : (?, 256, 256) Tensor(\"fcn_heatmap_loss_4/Shape_2:0\", shape=(3,), dtype=int32) KerasTensor:  False\n",
      "    loss mean : () Tensor(\"fcn_heatmap_loss_4/Shape_3:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      "\n",
      "---------------------------\n",
      ">>> fcn_heatmap_loss_graph \n",
      "---------------------------\n",
      "    target_masks : (?, 256, 256, 81) Tensor(\"fcn_heatmap_loss_4/Shape_4:0\", shape=(4,), dtype=int32) KerasTensor:  False\n",
      "    pred_heatmap : (?, 256, 256, 81) Tensor(\"fcn_heatmap_loss_4/Shape_5:0\", shape=(4,), dtype=int32) KerasTensor:  False\n",
      "    loss      : (?, 256, 256) Tensor(\"fcn_heatmap_loss_4/Shape_6:0\", shape=(3,), dtype=int32) KerasTensor:  False\n",
      "    loss mean : () Tensor(\"fcn_heatmap_loss_4/Shape_7:0\", shape=(0,), dtype=int32) KerasTensor:  False\n",
      " ================================================================\n",
      " self.keras_model.losses :  16\n",
      "0      Tensor(\"block2_conv2_4/add:0\", shape=(), dtype=float32)\n",
      "1      Tensor(\"block3_conv3_4/add:0\", shape=(), dtype=float32)\n",
      "2      Tensor(\"block5_conv1_4/add:0\", shape=(), dtype=float32)\n",
      "3      Tensor(\"fc1_4/add:0\", shape=(), dtype=float32)\n",
      "4      Tensor(\"block2_conv1_4/add:0\", shape=(), dtype=float32)\n",
      "5      Tensor(\"block3_conv2_4/add:0\", shape=(), dtype=float32)\n",
      "6      Tensor(\"block4_conv1_4/add:0\", shape=(), dtype=float32)\n",
      "7      Tensor(\"block4_conv3_4/add:0\", shape=(), dtype=float32)\n",
      "8      Tensor(\"block5_conv3_4/add:0\", shape=(), dtype=float32)\n",
      "9      Tensor(\"block4_conv2_4/add:0\", shape=(), dtype=float32)\n",
      "10      Tensor(\"block1_conv2_4/add:0\", shape=(), dtype=float32)\n",
      "11      Tensor(\"block5_conv2_4/add:0\", shape=(), dtype=float32)\n",
      "12      Tensor(\"fc2_4/add:0\", shape=(), dtype=float32)\n",
      "13      Tensor(\"block3_conv1_4/add:0\", shape=(), dtype=float32)\n",
      "14      Tensor(\"fcn_classify/add:0\", shape=(), dtype=float32)\n",
      "15      Tensor(\"block1_conv1_4/add:0\", shape=(), dtype=float32)\n",
      " ================================================================\n",
      "\n",
      ">>> FCN build complete. mode:  training\n",
      ">>> FCN initialization complete. mode:  training\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Build FCN Model in Training Mode\n",
    "##------------------------------------------------------------------------------------\n",
    "try :\n",
    "    del fcn_model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass    \n",
    "fcn_model = fcn_modellib.FCN(mode=\"training\", arch = 'FCN32', config=fcn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T11:43:40.112768Z",
     "start_time": "2018-10-23T11:43:40.054726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_pr_hm_norm (InputLayer)   (None, 256, 256, 81) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 256, 256, 64) 46720       input_pr_hm_norm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 8, 8, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Conv2D)                    (None, 8, 8, 4096)   102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 8, 8, 4096)   0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Conv2D)                    (None, 8, 8, 4096)   16781312    dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8, 8, 4096)   0           fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fcn32_classify (Conv2D)         (None, 8, 8, 81)     331857      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "score2 (Conv2DTranspose)        (None, 16, 16, 81)   105057      fcn32_classify[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "score_pool4 (Conv2D)            (None, 16, 16, 81)   41553       block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fuse_pool4 (Add)                (None, 16, 16, 81)   0           score2[0][0]                     \n",
      "                                                                 score_pool4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fcn_heatmap (Conv2DTranspose)   (None, 256, 256, 81) 6718545     fuse_pool4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_hm_norm (InputLayer)   (None, 256, 256, 81) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fcn_heatmap_loss (Lambda)       ()                   0           input_gt_hm_norm[0][0]           \n",
      "                                                                 fcn_heatmap[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 141,502,484\n",
      "Trainable params: 141,502,484\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fcn_model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T11:17:55.993502Z",
     "start_time": "2018-10-23T11:17:32.923920Z"
    }
   },
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------------------------\n",
    "## Load FCN Model weights  \n",
    "##------------------------------------------------------------------------------------\n",
    "fcn_model.load_model_weights(init_with = 'last') # 'fcn_config.VGG16_MODEL_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T11:42:49.145980Z",
     "start_time": "2018-10-23T11:42:49.091212Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EARLY_STOP_MIN_DELTA           0.0001\n",
      "EARLY_STOP_PATIENCE            50\n",
      "EPOCHS_TO_RUN                  2\n",
      "FCN_INPUT_SHAPE                [256 256]\n",
      "FCN_VGG16_MODEL_PATH           /home/kbardool/PretrainedModels/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.01\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MIN_LR                         1e-10\n",
      "NAME                           fcn\n",
      "NEW_LOG_FOLDER                 True\n",
      "NUM_CLASSES                    81\n",
      "OPTIMIZER                      ADAGRAD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "REDUCE_LR_COOLDOWN             50\n",
      "REDUCE_LR_FACTOR               0.5\n",
      "REDUCE_LR_PATIENCE             33\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROI_PROPOSAL_AREA_THRESHOLD    0\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                4\n",
      "SYSOUT                         screen\n",
      "TRAINING_PATH                  /home/kbardool/models/train_fcn_coco\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fcn_model.config.display()  \n",
    "# fcn_model.layer_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN `train_in_batches()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T15:08:50.586136Z",
     "start_time": "2018-10-20T15:08:50.498292Z"
    }
   },
   "outputs": [],
   "source": [
    "print('--- MRCNN-------------------------------------------------------')\n",
    "log(\"Epochs to run       {} \".format(mrcnn_model.config.EPOCHS_TO_RUN))\n",
    "log(\"Steps per epochs    {} \".format(mrcnn_model.config.STEPS_PER_EPOCH))\n",
    "log(\"Batch size          {} \".format(mrcnn_model.config.BATCH_SIZE))\n",
    "log(\"Learning Rate       {} \".format(mrcnn_model.config.LEARNING_RATE))\n",
    "log(\"Momentum            {} \".format(mrcnn_model.config.LEARNING_MOMENTUM))\n",
    "log(\"Weight Decay:       {} \".format(mrcnn_model.config.WEIGHT_DECAY       ))\n",
    "log(\"VALIDATION_STEPS    {} \".format(mrcnn_model.config.VALIDATION_STEPS   ))\n",
    "# log(\"Checkpoint Path:    {} \".format(mrcnn_model.checkpoint_path))\n",
    "# log(\"REDUCE_LR_FACTOR    {} \".format(mrcnn_model.config.REDUCE_LR_FACTOR   ))\n",
    "# log(\"REDUCE_LR_COOLDOWN  {} \".format(mrcnn_model.config.REDUCE_LR_COOLDOWN ))\n",
    "# log(\"REDUCE_LR_PATIENCE  {} \".format(mrcnn_model.config.REDUCE_LR_PATIENCE ))\n",
    "# log(\"MIN_LR              {} \".format(mrcnn_model.config.MIN_LR             ))\n",
    "# log(\"EARLY_STOP_PATIENCE {} \".format(mrcnn_model.config.EARLY_STOP_PATIENCE))     \n",
    "\n",
    "fcn_config.EPOCHS_TO_RUN  = 4\n",
    "fcn_config.LEARNING_RATE  = 0.1\n",
    "\n",
    "print('--- FCN --------------------------------------------------------')\n",
    "log(\"Epochs to run       {} \".format(fcn_model.config.EPOCHS_TO_RUN))\n",
    "log(\"Steps per epochs    {} \".format(fcn_model.config.STEPS_PER_EPOCH))\n",
    "log(\"Batch size          {} \".format(fcn_model.config.BATCH_SIZE))\n",
    "log(\"Learning Rate       {} \".format(fcn_model.config.LEARNING_RATE))\n",
    "log(\"Momentum            {} \".format(fcn_model.config.LEARNING_MOMENTUM))\n",
    "log(\"Weight Decay:       {} \".format(fcn_model.config.WEIGHT_DECAY       ))\n",
    "log(\"VALIDATION_STEPS    {} \".format(fcn_model.config.VALIDATION_STEPS   ))\n",
    "log(\"Checkpoint Path:    {} \".format(fcn_model.checkpoint_path))\n",
    "log(\"REDUCE_LR_FACTOR    {} \".format(fcn_model.config.REDUCE_LR_FACTOR   ))\n",
    "log(\"REDUCE_LR_COOLDOWN  {} \".format(fcn_model.config.REDUCE_LR_COOLDOWN ))\n",
    "log(\"REDUCE_LR_PATIENCE  {} \".format(fcn_model.config.REDUCE_LR_PATIENCE ))\n",
    "log(\"MIN_LR              {} \".format(fcn_model.config.MIN_LR             ))\n",
    "log(\"EARLY_STOP_PATIENCE {} \".format(fcn_model.config.EARLY_STOP_PATIENCE))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T15:47:17.692834Z",
     "start_time": "2018-10-20T15:27:20.058837Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------------------------\n",
    "## Train the FCN only \n",
    "## Passing layers=\"heads\" freezes all layers except the head\n",
    "## layers. You can also pass a regular expression to select\n",
    "## which layers to train by name pattern.\n",
    "##----------------------------------------------------------------------------------------------            \n",
    "train_layers = ['fcn']\n",
    "loss_names   = [\"fcn_heatmap_loss\"]\n",
    "fcn_config.LAST_EPOCH_RAN = 56\n",
    "fcn_model.epoch = fcn_config.LAST_EPOCH_RAN\n",
    "\n",
    "fcn_model.train_in_batches(\n",
    "            mrcnn_model,    \n",
    "            dataset_train,\n",
    "            dataset_val, \n",
    "            layers = train_layers,\n",
    "            losses = loss_names\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run data through model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display model input / output information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:34:35.696820Z",
     "start_time": "2018-10-17T14:34:33.592738Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mrcnn_model.layer_info()\n",
    "print('\\n FCN')\n",
    "fcn_model.layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:34:33.590986Z",
     "start_time": "2018-10-17T14:33:20.870486Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "# model_output = get_layer_output_1(mrcnn_model.keras_model, train_batch_x, [4,5,6,7,9,10,11,12,13,14], 1)\n",
    "# model_output = get_layer_output_1(mrcnn_model.keras_model, train_batch_x, [0,1,2,3,4,5,6,7,9,10,11], 1)\n",
    "model_output = get_layer_output_1(mrcnn_model.keras_model, train_batch_x, [0,1,2,3,4,5], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input and output tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:35:47.365657Z",
     "start_time": "2018-10-17T14:35:46.115830Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(model_output))\n",
    "\n",
    "# output_rois               = model_output[0]          # layer:  4   shape: (1, 200, 4)\n",
    "# target_class_ids          = model_output[1]          # layer:  5   shape: (1, 200)\n",
    "# target_bbox_deltas        = model_output[2]          # layer:  6   shape: (1, 200, 4)\n",
    "# roi_gt_boxes              = model_output[3]          # layer:  7   shape: (1, 200, 4)\n",
    "# mrcnn_class               = model_output[4]          # layer:  8   shape: (1, 200, 81)\n",
    "# mrcnn_bbox                = model_output[5]          # layer:  9   shape: (1, 200, 81, 4)\n",
    "# pred_refined_tensor       = model_output[6]          # layer: 16   shape: (1, 81, 25, 7)\n",
    "# output_rois               = model_output[0]          # layer:  0   shape: (2, 200, 4)\n",
    "# target_class_ids          = model_output[1]          # layer:  1   shape: (2, 200)\n",
    "# target_bbox_deltas        = model_output[2]          # layer:  2   shape: (2, 200, 4)\n",
    "# roi_gt_boxes              = model_output[3]          # layer:  3   shape: (2, 200, 4)\n",
    "# mrcnn_class               = model_output[4]          # layer:  4   shape: (2, 200, 81)\n",
    "# mrcnn_bbox                = model_output[5]          # layer:  5   shape: (2, 200, 81, 4)\n",
    "# model_pred_heatmap_norm         = model_output[6]          # layer:  6   shape: (2, 256, 256, 81)\n",
    "# model_pred_heatmap_scores       = model_output[7]          # layer:  7   shape: (2, 81, 25, 11)\n",
    "# model_gt_heatmap_scores         = model_output[8]          # layer:  9   shape: (2, 81, 25, 11)\n",
    "# model_pred_tensor               = model_output[9]          # layer: 10   shape: (2, 81, 25, 8)\n",
    "# model_gt_tensor                 = model_output[10]          # layer: 11   shape: (2, 81, 25, 8)\n",
    "\n",
    "pred_heatmap_norm         = model_output[0]          # layer:  0   shape: (2, 256, 256, 81)\n",
    "pred_heatmap_scores       = model_output[1]          # layer:  1   shape: (2, 81, 200, 11)\n",
    "gt_heatmap_norm           = model_output[2]          # layer:  2   shape: (2, 256, 256, 81)\n",
    "gt_heatmap_scores         = model_output[3]          # layer:  3   shape: (2, 81, 200, 11)\n",
    "pred_tensor               = model_output[4]          # layer:  4   shape: (2, 81, 200, 8)\n",
    "gt_tensor                 = model_output[5]          # layer:  5   shape: (2, 81, 200, 8)\n",
    "for i in model_output:\n",
    "    print( i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:37:20.794299Z",
     "start_time": "2018-10-17T14:37:17.275078Z"
    }
   },
   "outputs": [],
   "source": [
    "# fcn_input = [pred_heatmap_norm, pred_heatmap_scores, gt_heatmap_norm, gt_heatmap_scores] \n",
    "model_output2 = get_layer_output_1(fcn_model.keras_model, fcn_input, [0,1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T17:33:34.842266Z",
     "start_time": "2018-10-15T17:33:34.808415Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image          =  train_batch_x[0]\n",
    "input_image_meta     =  train_batch_x[1]\n",
    "# input_rpn_match      =  train_batch_x[2]\n",
    "# input_rpn_bbox       =  train_batch_x[3]\n",
    "input_gt_class_ids   =  train_batch_x[4]\n",
    "input_gt_bboxes      =  train_batch_x[5]\n",
    "print(' Input image shape is    :', input_image.shape)\n",
    "print(' input_image_meta        :', input_image_meta[0,:10])\n",
    "# print(' input_rpn_match         :', input_rpn_match.shape)\n",
    "# print(' input_rpn_bbox          :', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids      :', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes         :', input_gt_bboxes.shape)\n",
    "# h, w = input_image.shape[1], input_image.shape[2]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "# input_gt_bboxes_norm = tf.identity(input_gt_bboxes / [h,w,h,w])\n",
    "# print(' input_gt_bboxes_norm    :', input_gt_bboxes_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Display output from model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  `input_gt_class_ids`, `input_gt_bboxes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T17:34:03.805818Z",
     "start_time": "2018-10-15T17:34:02.696855Z"
    },
    "hidden": true,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(roi_gt_boxes[0,:50] * [1024,1024,1024,1024])\n",
    "print(input_gt_class_ids[0])\n",
    "print(input_gt_bboxes[0,:10])\n",
    "# for i in range(input_gt_class_ids.shape[1]):\n",
    "#     if input_gt_class_ids[0,i] == 1:\n",
    "#         print(input_gt_class_ids[0,i], '   ', input_gt_bboxes[0,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Display `output_rois`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:59:35.184714Z",
     "start_time": "2018-09-26T08:59:35.139366Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img = 0\n",
    "print(' output_rois')\n",
    "print(output_rois.shape)\n",
    "# print(output_rois[0,:40,:])\n",
    "print(output_rois [0,:40,:]* [1024, 1024, 1024, 1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  `max_mrcnn_class` , `argmax_mrcnn_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T16:46:21.282072Z",
     "start_time": "2018-09-22T16:46:21.216616Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "print(' mrcnn_class', mrcnn_class.shape)\n",
    "# print( mrcnn_class[0,0,:])\n",
    "# \n",
    "max_mrcnn_class    = np.max(mrcnn_class, axis = (0,2))\n",
    "argmax_mrcnn_class = np.argmax(mrcnn_class, axis = 2)\n",
    "\n",
    "# print()\n",
    "print('\\n mrcnn_class Max Values   : ', max_mrcnn_class.shape)\n",
    "print(max_mrcnn_class)\n",
    "\n",
    "# print()\n",
    "print(' mrcnn_class Argmax Values: ', argmax_mrcnn_class.shape)\n",
    "print(argmax_mrcnn_class[0])\n",
    "\n",
    "print(' target_class_ds    Values: ', target_class_ids.shape)\n",
    "print(target_class_ids[0])\n",
    "\n",
    "# for i in range(100):\n",
    "#     print('Predicted: ', argmax_mrcnn_class[0,i],  '  Actual ', target_class_ids[0,i])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Display  `target_class_ids()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T09:00:14.575438Z",
     "start_time": "2018-09-26T09:00:14.534931Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(' target_class_ids')\n",
    "print(target_class_ids.shape)\n",
    "print(target_class_ids[0,:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  apply `deltas` from predicted delta `mrcnn_bbox`  to  `output_rois` to obtain refined rois "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:52:01.206727Z",
     "start_time": "2018-09-21T12:52:01.068748Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img_idx = 0 \n",
    "\n",
    "print('output_rois',output_rois.shape, 'deltas ', deltas.shape)\n",
    "cls = 1\n",
    "for i in range(input_gt_class_ids.shape[1]):\n",
    "    if input_gt_class_ids[0,i] == cls:\n",
    "        print(input_gt_class_ids[0,i], '   ', input_gt_bboxes[0,i])\n",
    "\n",
    "        \n",
    "print()        \n",
    "for i in range(output_rois.shape[1]):\n",
    "    if classes[0,i] ==cls:\n",
    "        print(' i ', i, 'class: ',classes[0,i])\n",
    "#         print('   orig           : ', output_rois[0,i])\n",
    "        d1 = deltas[0,i] * mrcnn_config.BBOX_STD_DEV\n",
    "#         print('   delta          : ', deltas[0,i],'   delta * std dev: ', d1)\n",
    "        d2 = utils.apply_box_delta(output_rois[0,i],d1)\n",
    "#         print('   refined        : ', d2)\n",
    "#         print()\n",
    "        print('   orig           : ',output_rois[0,i] * [1024,1024,1024,1024])\n",
    "        print('   refined        : ', d2 * [1024,1024,1024,1024]) \n",
    "        print('   roi_gt_bboxes  : ', roi_gt_boxes[0,i]* [1024,1024,1024,1024]) \n",
    "        print()\n",
    "        print('   pred delta     : ', deltas[0,i] )\n",
    "        print('   tgt delta      : ', target_bbox_deltas[0,i] )\n",
    "        \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Display roi_gt_boxes , and class_ids vs. output_bbox and prediceted class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T16:34:41.699530Z",
     "start_time": "2018-09-22T16:34:41.650195Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(ref_out_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T16:35:45.777944Z",
     "start_time": "2018-09-22T16:35:45.598528Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ref_out_roi1 = ref_out_roi * [1024,1024,1024,1024]\n",
    "print(ref_out_roi1)\n",
    "window = np.array([0,0,1024,1024], dtype =float)\n",
    "print(window.shape)\n",
    "ref_out_roi2  = utils.clip_to_window_np( window, ref_out_roi1)\n",
    "print(ref_out_roi2.shape)\n",
    "for i in range(200):\n",
    "    print(ref_out_roi1[i],' --- ', ref_out_roi2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Display pred_refined_tensor and gt_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T10:00:33.070168Z",
     "start_time": "2018-10-16T10:00:33.031739Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for cls in [1]:\n",
    "    for box in range(20):\n",
    "        print(pred_tensor[0,cls,box])\n",
    "        print(gt_tensor[0,cls,box])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Display roi_gt_boxes along with corresponding refined/clipped output_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:41:23.457232Z",
     "start_time": "2018-10-08T13:41:22.950711Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "print(roi_gt_boxes[0].shape, target_class_ids[0].shape , np.expand_dims(target_class_ids[0],axis=-1).shape)\n",
    "classes, deltas = utils.get_predicted_mrcnn_deltas(mrcnn_class, mrcnn_bbox, verbose=True)\n",
    "deltas *= mrcnn_config.BBOX_STD_DEV\n",
    "print('classes.shape: ',classes.shape, ' deltas.shape: ',deltas.shape)\n",
    "\n",
    "ref_out_roi = utils.apply_box_deltas_np(output_rois[img_id],deltas[img_id])\n",
    "#     ##   Clip boxes to image window    \n",
    "# print(ref_out_roi.shape)\n",
    "window = np.array([0,0,1024,1024], dtype =float)\n",
    "clipped_out_roi  = utils.clip_to_window_np( window, ref_out_roi*[1024,1024,1024,1024])\n",
    "\n",
    "for i in range(200):\n",
    "#     ref_out_roi = utils.apply_box_delta_np(output_rois[0],d1[0])\n",
    "#     if classes[img_id,i] == 1 or target_class_ids[img_id,i] == 1 :\n",
    "\n",
    "    print('idx: ',200-i,' GT Cls: ', target_class_ids[img_id,i]  , ' -', roi_gt_boxes[img_id,i]*[1024,1024,1024,1024], \n",
    "                    ' PR Cls: ', classes[img_id,i],' - ', ref_out_roi[i]*[1024.0,1024.0,1024.0,1024.0] ,\n",
    "                     'ClpdCls: ', clipped_out_roi[i]   ) #) *[1024,1024,1024,1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### display gt_heatmap_scores and pred_heatmap_scores outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T10:22:55.077601Z",
     "start_time": "2018-10-16T10:22:54.959295Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=200, suppress=True)\n",
    "# print(' gt_tensor')\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[img,:,:10])\n",
    "img_id = 1\n",
    "print(' GT Heatmap Scores')\n",
    "\n",
    "print('gt_heatmap_scores: ', gt_heatmap_scores.dtype,  gt_heatmap_scores.shape)\n",
    "print('pred_heatmap_scores: ', pred_heatmap_scores.dtype,  pred_heatmap_scores.shape)\n",
    "\n",
    "# print(gt_heatmap_scores[img,1])\n",
    "# for img_id in range(mrcnn_config.BATCH_SIZE):\n",
    "\n",
    "for img_id in [0]:    # print(pred_refined_heatmap_scores[img_id,:4])\n",
    "    pr_class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    gt_class_ids = np.unique(gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist() \n",
    "    union_class_ids = np.union1d(pr_class_ids, gt_class_ids)\n",
    "    print('-'*56)\n",
    "    print('Image : {}  GT ClassIds: {}   PR ClassIds: {} '.format(img_id, gt_class_ids, pr_class_ids))\n",
    "    print('Image : {}  Union ClassIds: {}'.format(img_id, union_class_ids))\n",
    "    print('-'*56)\n",
    "    for cls in union_class_ids:  \n",
    "        print()\n",
    "        for i in range(25):\n",
    "#             print(' GT: img_id:',img_id, ' cls: ',cls, ' -',gt_tensor[img_id, cls,i]) #, gt_heatmap_scores[img_id, cls,i,7] )\n",
    "#             print(' PR: img_id:',img_id, ' cls: ',cls, ' -',pred_tensor[img_id,cls,i]) #,pred_refined_heatmap_scores[img_id,cls,i,7])\n",
    "\n",
    "            print(' GT: img/cls:',img_id, '/',cls, ' -',gt_heatmap_scores[img_id, cls,i]) #, gt_heatmap_scores[img_id, cls,i,7] )\n",
    "            print(' PR: img/cls:',img_id, '/',cls, ' -',pred_heatmap_scores[img_id,cls,i]) #,pred_refined_heatmap_scores[img_id,cls,i,7])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Display `Pred_Tensor`, `Pred_heatmap`, `mrcnn_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-19T13:55:40.491731Z",
     "start_time": "2018-09-19T13:55:40.409332Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=4, threshold=None, linewidth=150, suppress=True)\n",
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img = 0\n",
    "\n",
    "# max_score = np.max(mrcnn_class, axis = -1)\n",
    "# max_class = np.argmax(mrcnn_class, axis = -1)\n",
    "# # print(' output_rois[',img,'] \\n', output_rois[1]*[128,128,128,128])\n",
    "# print('max class shape:',max_class.shape, 'max score shape: ',max_score.shape)\n",
    "# print('max class[',img,']\\n',max_class[img])\n",
    "# print('max score[',img,']\\n',max_score[img])\n",
    "# print('mrcnn class.shape ',mrcnn_class.shape)\n",
    "# print('mrcnn_class[',img,',:]\\n',mrcnn_class[img,:])\n",
    "# print(output_rois[1])\n",
    "\n",
    "print('input_gt_class_ids')\n",
    "print(input_gt_class_ids[0])\n",
    "\n",
    "# print(' rpn_bbox')\n",
    "# print(rpn_bbox.shape)\n",
    "# print(rpn_bbox[0,:100,:])\n",
    "\n",
    "# print(' rpn_roi_proposals')\n",
    "# print(rpn_roi_proposals.shape)\n",
    "# print(rpn_roi_proposals[0,:100,:])\n",
    "\n",
    "print(' output_rois')\n",
    "print(output_rois.shape)\n",
    "# print(output_rois[0,:40,:])\n",
    "print(output_rois [0,:40,:]* [1024, 1024, 1024, 1024])\n",
    "\n",
    "print(' target_class_ids')\n",
    "print(target_class_ids.shape)\n",
    "print(target_class_ids[0,:40])\n",
    "# print(output_rois [0,:40,:]* [1024, 1024, 1024, 1024])\n",
    "\n",
    "# print(' Pred_tensor')\n",
    "# print(pred_tensor.shape)\n",
    "# print(pred_tensor[img,:,:10])\n",
    "\n",
    "# print(' gt_tensor')\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[img,:,:10])\n",
    "\n",
    "# print(' mrcnn_class')\n",
    "# print( mrcnn_class.shape)\n",
    "# print( mrcnn_class[0,:,:])\n",
    "\n",
    "# print(' mrcnn_bbox')\n",
    "# print( mrcnn_bbox.shape)\n",
    "# print( mrcnn_bbox)\n",
    "\n",
    "# print(' roi_gt_boxes')\n",
    "# print(roi_gt_boxes.shape)\n",
    "# print(roi_gt_boxes[img,:,:])\n",
    "\n",
    "# print(' Pred Heatmap Scores')\n",
    "# print(pred_heatmap_scores.dtype, pred_heatmap_scores.shape)\n",
    "# print(pred_heatmap_scores[img,1])\n",
    "\n",
    "# print(' FCN Scores')\n",
    "# print(fcn_scores.dtype)\n",
    "# for cls in range(4):\n",
    "#     print(pred_heatmap_scores[img,cls,:10])\n",
    "#     print(fcn_scores[img,cls,:10,2:])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "####  Display `output_rois` for visual check - passed on to  `build_pred_tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:48:00.011050Z",
     "start_time": "2018-10-08T13:47:59.957418Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('output_rois shape is ', output_rois.shape)\n",
    "img = 0\n",
    "for img in [0]:\n",
    "    print('Image ', img , ' ------------')\n",
    "    print(output_rois[img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "####  Display  - `pred_refined_tensor` which is passed on to  `build_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T15:34:53.538773Z",
     "start_time": "2018-10-08T15:34:53.480026Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "img_id = 0\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('model_pred_tensor shape is ', model_pred_tensor.shape)\n",
    "print(input_image_meta[0,:10])\n",
    "pr_class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "print('Image : {}  PR ClassIds: {} '.format(img_id, pr_class_ids))\n",
    "for k in pr_class_ids:\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(model_pred_tensor[img,k,:30])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Compare  `pred_heatmap_scores` vs. `pred_refined_heatmap_scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:52:40.296416Z",
     "start_time": "2018-09-21T12:52:40.217876Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "print('pred_refined_heatmap_scores',pred_refined_heatmap_scores.shape)\n",
    "cls = 1\n",
    "for i in range(input_gt_class_ids.shape[1]):\n",
    "    if input_gt_class_ids[0,i] == cls:\n",
    "        print(input_gt_class_ids[0,i], '   ', input_gt_bboxes[0,i])\n",
    "print()        \n",
    "for i in range(pred_heatmap_scores.shape[2]):\n",
    "#     print(' ref_ten   : ', pred_refined_tensor[0,1,i])\n",
    "    print(' hm_scr    : ', pred_heatmap_scores[0,1,i])\n",
    "    print(' ref_hm_scr: ', pred_refined_heatmap_scores[0,1,i])\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  Setup tensors to be passed to `build_predictions ()`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T13:52:33.994332Z",
     "start_time": "2018-09-26T13:52:33.946512Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mrcnn_bbox  = tf.identity(mrcnn_bbox)\n",
    "mrcnn_class = tf.identity(mrcnn_class)\n",
    "norm_input_rois = tf.identity(output_rois)\n",
    "config      = mrcnn_config\n",
    "sess = KB.get_session()\n",
    "print(' Keras session :', sess)\n",
    "import mrcnn.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  `build_predictions()`\n",
    "\n",
    "`pred_tensor[:,:,:,1:7]`  == `[116.9736  21.8213  36.2715  45.6026   0.    0.9139   ]`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T13:52:44.564731Z",
     "start_time": "2018-09-26T13:52:43.827682Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "# def build_refined_predictions(norm_input_rois, mrcnn_class, mrcnn_bbox, config):\n",
    "    '''\n",
    "    Split output_rois by class id, and add class_id and class_score \n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    \n",
    "    pred_tensor:        [ Batchsz, Num_Classes, Num_Rois, 7: (y1, x1, y2, x2, class_id, class_score, normalized class score)]\n",
    "                        \n",
    "                        y1,x1, y2,x2 are in image dimension format\n",
    "    '''\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES\n",
    "    h, w            = config.IMAGE_SHAPE[:2]\n",
    "    # num_rois        = config.TRAIN_ROIS_PER_IMAGE\n",
    "    num_cols        = 6\n",
    "    num_rois        = KB.int_shape(norm_input_rois)[1]\n",
    "    scale           = tf.constant([h,w,h,w], dtype = tf.float32)\n",
    "    # dup_scale       = tf.reshape(tf.tile(scale, [num_rois]),[num_rois,-1])\n",
    "    dup_scale       = scale * tf.ones([batch_size, num_rois, 1], dtype = 'float32')\n",
    "\n",
    "    det_per_class   = config.TRAIN_ROIS_PER_IMAGE ## config.DETECTION_PER_CLASS\n",
    "    \n",
    "    print()\n",
    "    print('  > build_predictions()')\n",
    "    print('    num_rois               : ', num_rois )\n",
    "    print('    norm_input_rois.shape  : ', type(norm_input_rois), KB.int_shape(norm_input_rois))\n",
    "    print('    scale.shape            : ', type(scale), KB.int_shape(scale), scale.get_shape())\n",
    "    print('    dup_scale.shape        : ', type(dup_scale), KB.int_shape(dup_scale), dup_scale.get_shape())\n",
    "    print()\n",
    "    print('    mrcnn_class shape      : ', KB.int_shape(mrcnn_class))\n",
    "    print('    mrcnn_bbox.shape       : ', KB.int_shape(mrcnn_bbox), mrcnn_bbox.shape )\n",
    "    print('    config image shape     : ', config.IMAGE_SHAPE, 'h:',h,'w:',w)\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    # Build a meshgrid for image id and bbox to use in gathering of bbox delta information \n",
    "    #---------------------------------------------------------------------------\n",
    "    batch_grid, bbox_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32),\n",
    "                                         tf.range(num_rois, dtype=tf.int32), indexing = 'ij' )\n",
    "\n",
    "    #------------------------------------------------------------------------------------\n",
    "    # use the argmaxof each row to determine the dominating (predicted) class\n",
    "    #------------------------------------------------------------------------------------\n",
    "    pred_classes     = tf.argmax( mrcnn_class,axis=-1,output_type = tf.int32)\n",
    "    pred_classes_exp = tf.to_float(tf.expand_dims(pred_classes ,axis=-1))    \n",
    "    #     print('    pred_classes : ', pred_classes.shape)\n",
    "    #     print(pred_classes.eval())\n",
    "    #     print('    pred_scores  : ', pred_scores.shape ,'\\n', pred_scores.eval())\n",
    "    #     print('    pred_classes_exp : ', pred_classes_exp.shape)\n",
    "    \n",
    "    gather_ind   = tf.stack([batch_grid , bbox_grid, pred_classes],axis = -1)\n",
    "    pred_scores  = tf.gather_nd(mrcnn_class, gather_ind)\n",
    "    pred_deltas  = tf.gather_nd(mrcnn_bbox , gather_ind)\n",
    "\n",
    "    #------------------------------------------------------------------------------------\n",
    "    # 22-05-2018 - stopped using the following code as it was clipping too many bouding \n",
    "    # boxes to 0 or 128 causing zero area generation\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    ## apply delta refinements to the  rois,  based on deltas provided by the mrcnn head \n",
    "    ##------------------------------------------------------------------------------------\n",
    "    pred_deltas  = tf.multiply(pred_deltas, config.BBOX_STD_DEV, name = 'pred_deltas')\n",
    "    input_rois   = tf.multiply(norm_input_rois , dup_scale )\n",
    "\n",
    "    ## compute \"refined rois\"  utils.apply_box_deltas_tf(input_rois, pred_deltas)\n",
    "    refined_rois   = utils.apply_box_deltas_tf(input_rois, pred_deltas)\n",
    "\n",
    "    ##   Clip boxes to image window    \n",
    "    window = tf.constant([[0,0,h,w]], dtype = tf.float32)\n",
    "    clipped_rois  = utils.clip_to_window_tf( window, refined_rois)\n",
    "    \n",
    "    print('    input_rois.shape       : ', type(input_rois), KB.int_shape(input_rois), input_rois.get_shape())\n",
    "    print('    refined_rois.shape     : ', type(refined_rois), KB.int_shape(refined_rois), refined_rois.get_shape())\n",
    "    print('    refined rois clipped   : ', clipped_rois.shape)\n",
    "    # print('    mrcnn_class : ', mrcnn_class.shape, mrcnn_class)\n",
    "    # print('    gather_ind  : ', gather_ind.shape, gather_ind)\n",
    "    # print('    pred_scores : ', pred_scores.shape )\n",
    "    # print('    pred_deltas : ', pred_deltas.shape )   \n",
    "    # print('    input_rois : ', input_rois.shape, input_rois)\n",
    "    # print('    refined rois: ', refined_rois.shape, refined_rois)\n",
    "        \n",
    "\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    ##  Build Pred_Scatter: tensor of bounding boxes by Image / Class\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    ## sequence id is used to preserve the order of rois as passed to this routine\n",
    "    ##  This may be important in the post matching process but for now it's not being used.\n",
    "    ## 22-09-18 : We need to use this sequence as the sort process based on score will cause\n",
    "    ##            mismatch between the bboxes from output_rois and roi_gt_bboxes\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    sequence = tf.ones_like(pred_classes, dtype = tf.int32) * (bbox_grid[...,::-1] + 1) \n",
    "    sequence = tf.to_float(tf.expand_dims(sequence, axis = -1))   \n",
    "    print('    shape of sequence      : ', sequence.shape)\n",
    "    pred_array  = tf.concat([ clipped_rois, pred_classes_exp , tf.expand_dims(pred_scores, axis = -1), sequence], axis=-1, name = 'pred_array')\n",
    "     \n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # pred_array  = tf.concat([refined_rois, pred_classes_exp , tf.expand_dims(pred_scores, axis = -1)], axis=-1)\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    scatter_ind = tf.stack([batch_grid , pred_classes, bbox_grid],axis = -1)\n",
    "    pred_scatt  = tf.scatter_nd(scatter_ind, pred_array, [batch_size, num_classes, num_rois, pred_array.shape[-1]])\n",
    "    print('    pred_array             : ', pred_array.shape)  \n",
    "    print('    scatter_ind            : ', type(scatter_ind), 'shape', scatter_ind.shape)\n",
    "    print('    pred_scatter           : ', pred_scatt.get_shape())\n",
    "    \n",
    "\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ##  Apply a per class score normalization\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    normalizer   = tf.reduce_max(pred_scatt[...,5], axis = -1, keepdims=True)\n",
    "    normalizer   = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    norm_score   = tf.expand_dims(pred_scatt[...,5]/normalizer, axis = -1)\n",
    "    pred_scatt   = tf.concat([pred_scatt, norm_score],axis = -1)   \n",
    "    print('    - Add normalized score --\\n')\n",
    "    print('    normalizer             : ', normalizer.shape)  \n",
    "    print('    norm_score             : ', norm_score.shape)\n",
    "    print('    pred_scatter           : ', pred_scatt.get_shape())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    ## sort pred_scatter in each class dimension based on bbox scores (last column)\n",
    "    ##------------------------------------------------------------------------------------\n",
    "    _, sort_inds = tf.nn.top_k(pred_scatt[...,6], k=pred_scatt.shape[2])\n",
    "    \n",
    "    # build indexes to gather rows from pred_scatter based on sort order    \n",
    "    class_grid, batch_grid, roi_grid = tf.meshgrid(tf.range(num_classes),tf.range(batch_size), tf.range(num_rois))\n",
    "    roi_grid_exp = tf.to_float(tf.expand_dims(roi_grid, axis = -1))\n",
    "    gather_inds  = tf.stack([batch_grid , class_grid, sort_inds],axis = -1)\n",
    "    \n",
    "    pred_array   = tf.gather_nd(pred_scatt, scatter_ind )\n",
    "    pred_tensor  = tf.gather_nd(pred_scatt, gather_inds[...,:det_per_class,:], name = 'pred_tensor')    \n",
    "\n",
    "    # append an index to the end of each row --- commented out 30-04-2018\n",
    "    # pred_tensor  = tf.concat([pred_tensor, roi_grid_exp], axis = -1)\n",
    "\n",
    "    print('    sort_inds              : ', type(sort_inds)   , ' shape ', sort_inds.shape)\n",
    "    print('    class_grid             : ', type(class_grid)  , ' shape ', class_grid.get_shape())\n",
    "    print('    batch_grid             : ', type(batch_grid)  , ' shape ', batch_grid.get_shape())\n",
    "    print('    roi_grid shape         : ', type(roi_grid)    , ' shape ', roi_grid.get_shape()) \n",
    "    print('    roi_grid_exp           : ', type(roi_grid_exp), ' shape ', roi_grid_exp.get_shape())\n",
    "    print('    gather_inds            : ', type(gather_inds) , ' shape ', gather_inds.get_shape())\n",
    "    print('    pred_array             : ', pred_array.shape, pred_array.get_shape())\n",
    "    print('    pred_tensor            : ', pred_tensor.get_shape())\n",
    "\n",
    "#     return  pred_tensor    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T10:44:44.849028Z",
     "start_time": "2018-09-24T10:44:44.805566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Reshape pred_scatt??  No, doesn't work well as the reshape will convert into [batch_sz, #classes x # bboxes, 8]\n",
    "# btch_sz, cls_sz, bbox_sz, col_sz = pred_scatt.shape\n",
    "# print(btch_sz, cls_sz, bbox_sz, col_sz )\n",
    "# reshape = tf.reshape(pred_scatt, [btch_sz, -1, col_sz])\n",
    "# print(reshape.shape)\n",
    "\n",
    "### This works well, converts pred_scatter back to pred_array (with added normzalized score column)\n",
    "# \n",
    "# reshape = tf.gather_nd(pred_scatt, scatter_ind )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Display `pred_tensor`  from model code and code above, `pred_heatmap_scores`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T13:53:33.492334Z",
     "start_time": "2018-09-26T13:53:33.004813Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_tensor            : ', pred_tensor.get_shape() )\n",
    "print('pred tensor from model : ', model_pred_tensor.shape)\n",
    "with sess.as_default():\n",
    "    r_pred_tensor = pred_tensor.eval()\n",
    "    \n",
    "    \n",
    "for img in range(2):\n",
    "    class_ids = np.unique(r_pred_tensor[img,:,:,4]).astype(int).tolist()    \n",
    "    print('Classids: ', class_ids)\n",
    "    for i in class_ids:\n",
    "        print('Image ', img , '/ Class ',i,' ------------')\n",
    "        for j in range(25):\n",
    "            print(r_pred_tensor[img,i,j])\n",
    "            print(model_pred_tensor[img,i,j])\n",
    "            print(model_pred_heatmap_scores[img,i,j])\n",
    "#             print(pred_heatmap_scores[img,i,j])\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T10:03:58.910808Z",
     "start_time": "2018-09-25T10:03:58.726130Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "with sess.as_default():\n",
    "    print(scatter_ind.shape)\n",
    "    print(pred_scatt.shape)\n",
    "    print(pred_array.shape)\n",
    "#     r_clipped_rois = clipped_rois.eval()\n",
    "    r_pred_array = pred_array.eval()\n",
    "for i in range(200):\n",
    "#     print()\n",
    "#     print('input_ro:  ', r0[0,i]) \n",
    "#     print('original (clipped) :  ', r_clipped_rois[0,i])\n",
    "    print('pred_array         :  ', r_pred_array[0,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T10:05:06.237621Z",
     "start_time": "2018-09-25T10:05:06.190986Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "\n",
    "# with sess.as_default():\n",
    "#     print(pred_scores.eval())\n",
    "#     print(pred_classes.eval())\n",
    "#     print(scatter_ind.eval()[0])\n",
    "#     print(norm_score.eval()[0,9])\n",
    "#     print(pred_array.eval()[0,:200])\n",
    "#     print(scatter_ind.shape)\n",
    "#     print(pred_scatt.shape)\n",
    "#     print(pred_array.shape)\n",
    "#     r_clipped_rois = clipped_rois.eval()\n",
    "#     r_pred_array   = pred_array.eval()\n",
    "#     print(pred_scatt.eval()[0,1,0:200])\n",
    "#     print(normalizer.eval()[0,9])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Some tests on the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Test that refined_rois is correctly working in `clip_to_window_tf` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T13:42:38.351532Z",
     "start_time": "2018-05-18T13:42:37.820120Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    test_np = refined_rois.eval()\n",
    "    test_tf = refined_rois_clipped.eval()\n",
    "    window_np = np.array([0,0,128,128])\n",
    " \n",
    "    print(window_np.shape)\n",
    "    for i in range(5):\n",
    "#         print('Before', i)\n",
    "#         print(test_np[i])\n",
    "        test_np[i] = clip_to_window(window_np, test_np[i])\n",
    "#         print('After', i)\n",
    "#         print(test_np[i])\n",
    "#         print('   tensor flow')\n",
    "#         print(test_tf[i])\n",
    "        \n",
    "    for i in range(5):\n",
    "      all_equal = np.all(test_np == refined_rois_clipped.eval())\n",
    "      print('i: ', i, '--- EQUAL : ', all_equal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Test that pred_classes and pred_deltas have been properly selected when using tf.gather_nd ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T13:32:01.297444Z",
     "start_time": "2018-05-18T13:32:00.765661Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    tmp0 = pred_classes.eval()\n",
    "    tmp1 = mrcnn_bbox.eval()\n",
    "    tmp2 = pred_deltas.eval()\n",
    "    tmp4 = mrcnn_class.eval()\n",
    "    tmp3 = pred_scores2.eval()\n",
    "    tmp5 = pred_scores.eval()\n",
    "    \n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(32):\n",
    "        print('i: ', i, ' j :', j,'--- class: ',tmp0[i,j],'---------------')\n",
    "    #     print(tmp0[i,j])\n",
    "        print(tmp1[i,j])\n",
    "        print(' ===> ', tmp2[i,j])\n",
    "        print(' mrcnn_score: ', tmp4[i,j,tmp0[i,j]], ' pred_score:', tmp5[i,j,0], 'pred_score2: ', tmp3[i,j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false
   },
   "source": [
    "####  Verify refined_rois generated by TF and NP are equal when using `apply_box_deltas_tf( )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T10:48:35.696940Z",
     "start_time": "2018-05-18T10:48:34.824880Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import apply_box_deltas, apply_box_deltas_tf\n",
    "with sess.as_default():\n",
    "    refined_rois_tf = apply_box_deltas_3d(output_rois, pred_deltas).eval()\n",
    "    print(' refined rois_tf: ', refined_rois_tf.shape, refined_rois_tf.dtype)\n",
    "    tmp = []\n",
    "    bxs = output_rois.eval()\n",
    "    dlt = pred_deltas.eval()\n",
    "    for i in range(5):\n",
    "        tmp.append(apply_box_deltas(bxs[i], dlt[i]))\n",
    "    refined_rois_np = np.asarray(tmp)\n",
    "    print(' refined rois_np: ', refined_rois_np.shape,refined_rois_np.dtype)\n",
    "    print(' refined rois_np == refined rois_tf ?? :', np.all(refined_rois_tf[0,1] == refined_rois_np[0,1]))\n",
    "\n",
    "#     for i in range(5):\n",
    "#         for j in range(32):\n",
    "#             all_eq = np.all(refined_rois_tf[0,1] == refined_rois_np[0,1])\n",
    "#             if ~all_eq:\n",
    "#                 print(' Not equal : ',i,'/',j)\n",
    "#                 print(refined_rois_tf[i,j])\n",
    "#                 print(refined_rois_np[i,j])\n",
    "#             else:\n",
    "#                 print(' equal : ',i,'/',j)\n",
    "print(refined_rois_tf[0])\n",
    "print(refined_rois_np[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Prepare values to pass to build_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:50:29.488452Z",
     "start_time": "2018-10-08T13:50:29.445281Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "# def build_heatmap(in_tensor, config, names = None):\n",
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "print(model_pred_tensor.shape)\n",
    "in_tensor = tf.identity(model_pred_tensor)\n",
    "# in_tensor   = pred_tensor\n",
    "# in_array    = pred_array \n",
    "sess = KB.get_session()\n",
    "config = mrcnn_model.config\n",
    "names = ['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  `build_heatmap()` - part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:49:28.181644Z",
     "start_time": "2018-10-08T14:48:56.921962Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():    \n",
    "# def build_heatmap(in_tensor, config, names = None):    \n",
    "    num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "    img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "    heatmap_scale   = config.HEATMAP_SCALE_FACTOR\n",
    "    rois_per_image  = (in_tensor.shape)[2]  \n",
    "    grid_h, grid_w  = config.IMAGE_SHAPE[:2] // heatmap_scale\n",
    "    \n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "    # strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "    print('\\n ')\n",
    "    print('  > NEW build_heatmap() for ', names )\n",
    "    print('    in_tensor shape      : ', in_tensor.shape)       \n",
    "    print('    num bboxes per class : ', rois_per_image )\n",
    "    print('    heatmap scale        : ', heatmap_scale, 'Dimensions:  w:', grid_w,' h:', grid_h)\n",
    "\n",
    "    #-----------------------------------------------------------------------------    \n",
    "    ## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "    #-----------------------------------------------------------------------------\n",
    "    # pt2_ind shape is [?, 3]. \n",
    "    #   pt2_ind[0] corresponds to image_index \n",
    "    #   pt2_ind[1] corresponds to class_index \n",
    "    #   pt2_ind[2] corresponds to roi row_index \n",
    "    # pt2_dense shape is [?, 6]\n",
    "    #    pt2_dense[0] is image index\n",
    "    #    pt2_dense[1:4]  roi cooridnaytes \n",
    "    #    pt2_dense[5]    is class id \n",
    "    #-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,0:4]), axis=-1)\n",
    "    pt2_ind = tf.where(pt2_sum > 0)\n",
    "    pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "    print('    pt2_sum shape ',pt2_sum.shape)\n",
    "    print('    pt2_ind shape :', pt2_ind.shape)\n",
    "    print('    pt2_dense shape ',pt2_dense.get_shape())\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates  \n",
    "    #-----------------------------------------------------------------------------\n",
    "    X = tf.range(grid_w , dtype=tf.int32)\n",
    "    Y = tf.range(grid_h , dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "\n",
    "    # duplicate (repeat) X and Y into a  batch_size x rois_per_image tensor\n",
    "    print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "    ones = tf.ones([tf.shape(pt2_dense)[0] , 1, 1], dtype = tf.int32)\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    print('    Ones:    ', ones.shape)                \n",
    "    print('    ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    print('    ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    pos_grid = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    print('    before transpse ', pos_grid.get_shape())\n",
    "    pos_grid = tf.transpose(pos_grid,[1,2,0,3])\n",
    "    print('    after transpose ', pos_grid.get_shape())    \n",
    "    \n",
    "    pt2_dense_scaled = pt2_dense[:,:4]/heatmap_scale\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "    ##-----------------------------------------------------------------------------\n",
    "    width  = pt2_dense_scaled[:,3] - pt2_dense_scaled[:,1]      # x2 - x1\n",
    "    height = pt2_dense_scaled[:,2] - pt2_dense_scaled[:,0]\n",
    "    cx     = pt2_dense_scaled[:,1] + ( width  / 2.0)\n",
    "    cy     = pt2_dense_scaled[:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)\n",
    "\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ##  Compute Normal Distribution for bounding boxes\n",
    "    ##-----------------------------------------------------------------------------    \n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag(loc = means,  scale_diag = covar)\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    print('    Prob_grid shape before tanspose: ',prob_grid.get_shape())\n",
    "    prob_grid = tf.transpose(prob_grid,[2,0,1])\n",
    "    print('    Prob_grid shape after tanspose : ',prob_grid.get_shape())    \n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## (1) apply normalization per bbox heatmap instance\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    print('\\n    normalization ------------------------------------------------------')   \n",
    "    normalizer = tf.reduce_max(prob_grid, axis=[-2,-1], keepdims = True)\n",
    "    normalizer = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    print('    normalizer     : ', normalizer.shape) \n",
    "    prob_grid_norm = prob_grid / normalizer\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## (2) multiply normalized heatmap by normalized score in in_tensor/ (pt2_dense column 7)\n",
    "    ##     broadcasting : https://stackoverflow.com/questions/49705831/automatic-broadcasting-in-tensorflow\n",
    "    ##---------------------------------------------------------------------------------------------    \n",
    "#  Using the double tf.transpose, we dont need this any more    \n",
    "#     scr = tf.expand_dims(tf.expand_dims(pt2_dense[:,7],axis = -1), axis =-1)\n",
    "\n",
    "    prob_grid_norm_scaled = tf.transpose(tf.transpose(prob_grid_norm) * pt2_dense[:,7])\n",
    "    print('    prob_grid_norm_scaled : ', prob_grid_norm_scaled.shape)\n",
    "#     maxes2 = tf.reduce_max(prob_grid_norm_scaled, axis=[-2,-1], keepdims = True)\n",
    "#     print('    shape of maxes2       : ', maxes2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:38:38.183662Z",
     "start_time": "2018-10-08T14:38:13.395724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    # print(prob_grid_norm.shape)\n",
    "    # r_normalizer = normalizer.eval()    \n",
    "#     r_prob_grid = prob_grid.eval()\n",
    "#     r_prob_grid_norm = prob_grid_norm.eval()\n",
    "#     r_prob_grid_norm_scaled = prob_grid_norm_scaled.eval()\n",
    "    r_maxes2 = maxes2.eval()\n",
    "    r_score  = pt2_dense[:,7].eval()\n",
    "#     r_pt2_dense = pt2_dense.eval()\n",
    "#     r_cx, r_cy  = cx.eval(), cy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:39:12.390360Z",
     "start_time": "2018-10-08T14:39:12.338513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(r_normalizer.shape)\n",
    "# print(r_prob_grid.shape, r_prob_grid_norm.shape)\n",
    "# print(r_maxes0.shape)\n",
    "# print(r_maxes1.shape)\n",
    "print(r_maxes2.shape)\n",
    "print(r_score.shape)\n",
    "# print(r_pt2_dense[:50])\n",
    "for i in range(20):\n",
    "    print('   ', r_score[i], '   ', r_maxes2[i],'  ') # , r_pt2_dense[i],r_cx[i], r_cy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T15:32:15.735805Z",
     "start_time": "2018-09-26T15:32:15.682892Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for y in [111,112,113]:\n",
    "    print(r_prob_grid[0,y,95:115])\n",
    "    print(r_prob_grid_norm[0,y,95:115])\n",
    "    print(r_prob_grid_norm_scaled[0,y,95:115])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T15:49:07.091492Z",
     "start_time": "2018-09-26T15:49:05.482516Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_2d_gaussian, plot_3d_gaussian\n",
    "box = 23\n",
    "plot_3d_gaussian(r_prob_grid[box], zlim = 0.1)\n",
    "plot_3d_gaussian(r_prob_grid_norm[box])\n",
    "plot_3d_gaussian(r_prob_grid_norm_scaled[box])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###   `build_heatmap()` - part 2 - Calculate heatmap sum using old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:50:17.448359Z",
     "start_time": "2018-10-08T14:50:17.355565Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    ## IMPORTANT: kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "    ## which cause singular sigma cov matrices\n",
    "    ##--------------------------------------------------------------------------------\n",
    "    #     prob_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    ## (3) scatter out the probability distributions based on class \n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    print('\\n    Scatter out the probability distributions based on class --------------') \n",
    "    gauss_scatt   = tf.scatter_nd(pt2_ind, prob_grid_norm_scaled, [batch_size, num_classes, rois_per_image, grid_w, grid_h], name = 'gauss_scatter')\n",
    "    print('    pt2_ind shape   : ', pt2_ind.shape)  \n",
    "    print('    prob_grid shape : ', prob_grid.shape)  \n",
    "    print('    gauss_scatt     : ', gauss_scatt.shape)   # batch_sz , num_classes, num_rois, image_h, image_w\n",
    "    \n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    ## (4) SUM : Reduce and sum up gauss_scattered by class  \n",
    "    ##-------------------------------------------------------------------------------------\n",
    "    print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "    gauss_heatmap = tf.reduce_sum(gauss_scatt, axis=2, name='pred_heatmap2')\n",
    "    # force small sums to zero - for now (09-11-18) commented out but could reintroduce based on test results\n",
    "    # gauss_heatmap = tf.where(gauss_heatmap < 1e-12, gauss_heatmap, tf.zeros_like(gauss_heatmap), name='Where1')\n",
    "    print('    gaussian_heatmap shape     : ', gauss_heatmap.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_heatmap) )      \n",
    "    \n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## (5) heatmap normalization\n",
    "    ##     normalizer is set to one when the max of class is zero     \n",
    "    ##     this prevents elements of gauss_heatmap_norm computing to nan\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    print('\\n    normalization ------------------------------------------------------')   \n",
    "    normalizer = tf.reduce_max(gauss_heatmap, axis=[-2,-1], keepdims = True)\n",
    "    print('    normalizer shape       : ', normalizer.shape)    \n",
    "    normalizer = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    gauss_heatmap_norm = gauss_heatmap / normalizer\n",
    "    print('    gauss norm            : ', gauss_heatmap_norm.shape   ,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap_norm) )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Alternative method: use `scatter_nd_add` to build guassian sum\n",
    "requires definition of tf.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:51:09.679531Z",
     "start_time": "2018-10-08T13:51:09.587607Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "#   kvar = KB.variable(value = KB.zeros([batch_size, num_classes, grid_w, grid_h], dtype = 'float32'))\n",
    "#   kvar = tf.scatter_nd_add(kvar, pt2_ind[:,:2],prob_grid)\n",
    "\n",
    "#   kvar_norm  = KB.variable(value = KB.zeros([batch_size, num_classes, grid_w, grid_h], dtype = 'float32'))\n",
    "#   kvar_norm = tf.scatter_nd_add(kvar_norm, pt2_ind[:,:2],prob_grid)\n",
    "\n",
    "    kvar_norm_scaled = KB.variable(value = KB.zeros([batch_size, num_classes, grid_w, grid_h], dtype = 'float32'))\n",
    "    kvar_norm_scaled = KB.zeros([batch_size, num_classes, grid_w, grid_h])\n",
    "    kvar_norm_scaled = tf.scatter_nd_add(kvar_norm_scaled, pt2_ind[:,:2],prob_grid_norm_scaled)\n",
    "\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    ## heatmap normalization\n",
    "    ## normalizer is set to one when the max of class is zero     \n",
    "    ## this prevents elements of gauss_heatmap_norm computing to nan\n",
    "    ##---------------------------------------------------------------------------------------------\n",
    "    print('\\n    normalization ------------------------------------------------------')   \n",
    "    normalizer = tf.reduce_max(kvar_norm_scaled, axis=[-2,-1], keepdims = True)\n",
    "    normalizer = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    gaussian_heatmap_norm = kvar_norm_scaled / normalizer\n",
    "    # gauss_heatmap_norm    = gauss_heatmap / tf.reduce_max(gauss_heatmap, axis=[-2,-1], keepdims = True)\n",
    "    # gauss_heatmap_norm    = tf.where(tf.is_nan(gauss_heatmap_norm),  tf.zeros_like(gauss_heatmap_norm), gauss_heatmap_norm, name = 'Where2')\n",
    "    print('    gauss norm            : ', gaussian_heatmap_norm.shape  )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:31:20.741468Z",
     "start_time": "2018-09-26T16:29:40.444137Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "#     r_ghm  = gauss_heatmap.eval()\n",
    "    r_kvar = KB.eval(kvar)\n",
    "    r_kvar_norm = KB.eval(kvar_norm)\n",
    "    r_kvar_norm_scaled = KB.eval(kvar_norm_scaled)\n",
    "    r_kvar_final = kvar_final.eval()\n",
    "#     r_kvar = kvar.eval()\n",
    "#     r_kvar_norm = kvar_norm.eval()\n",
    "#     r_kvar_norm_scaled = kvar_norm_scaled.eval()\n",
    "#     r_kvar_final = kvar_final.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:31:20.835850Z",
     "start_time": "2018-09-26T16:31:20.791378Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(r_kvar.shape, r_kvar_norm.shape, r_kvar_norm_scaled.shape, r_kvar_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:31:20.789145Z",
     "start_time": "2018-09-26T16:31:20.744504Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=4, threshold=30000, linewidth=260, suppress=True)\n",
    "# print(r_kvar.shape, r_ghm.shape)\n",
    "# print(kvar, gauss_heatmap)\n",
    "# for  i in [9]:  #range(81):\n",
    "#     for j in range(256):\n",
    "#         print(' Col: ', j, ': ',np.all(r_kvar[0,i,j] == r_ghm[0,i,j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:32:02.165855Z",
     "start_time": "2018-09-26T16:31:54.694866Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_2d_gaussian, plot_3d_gaussian\n",
    "cls = 1\n",
    "plot_3d_gaussian(r_ghm[0,cls])\n",
    "plot_3d_gaussian(r_kvar[0,cls])\n",
    "plot_3d_gaussian(r_kvar_norm[0,cls])\n",
    "plot_3d_gaussian(r_kvar_final[0,cls])\n",
    "\n",
    "# for i in range(81):\n",
    "#     print(np.max(r_kvar[0,i]), np.max(r_ghm[0,i]), np.sum(r_kvar[0,i]),np.sum(r_ghm[0,i]))\n",
    "# plot_3d_gaussian(r_prob_grid_norm_scaled[box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T09:14:52.264821Z",
     "start_time": "2018-09-26T09:14:52.218973Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(linewidth=150, precision=6)\n",
    "# # print('scatter shape is ', pred_scatt.get_shape())\n",
    "# print('pt2_dense shape is ', pt2_dense.get_shape() )\n",
    "# with sess.as_default():\n",
    "#     r_pt2_ind   = pt2_ind.eval()\n",
    "#     r_pt2_dense = pt2_dense.eval()\n",
    "#     X1,Y1 = tf.meshgrid(tf.range(batch_size, dtype=tf.int32), tf.range(num_detections, dtype=tf.int32), indexing = 'ij')\n",
    "#     r_X1 = X1.eval()\n",
    "#     r_Y1 = Y1.eval()\n",
    "# print(r_X1.shape , Y1.shape)\n",
    "# print(r_X1)\n",
    "# print(r_Y1)\n",
    "# print(r_pt2_ind.shape)\n",
    "# where_to_go = np.stack([r_pt2_ind[:,0],r_pt2_dense[:,4], r_pt2_dense[:,6]],axis =-1)\n",
    "# print(where_to_go.shape)\n",
    "# print(where_to_go)\n",
    "\n",
    "# class_ids = np.unique(r_pt2_dense[:,4]).astype(int).tolist()    \n",
    "# print('Classids: ', class_ids)\n",
    "\n",
    "# for box in range(r_pt2_ind.shape[0]):\n",
    "#     print(r_pt2_ind[box],'      ', r_pt2_dense[box,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T13:17:02.166622Z",
     "start_time": "2018-09-25T13:17:02.123433Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "#     gauss_sum = tf.zeros([batch_size, num_classes, rois_per_image, img_w//scale, img_h//scale])\n",
    "#     print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )      \n",
    "\n",
    "#     counter = 0\n",
    "#     limit   = batch_size * rois_per_image\n",
    "#     c = lambda i, j, k,l: tf.less_equal(i, pt2_ind.get_shape()[0])\n",
    "#     b = lambda i, j, k,l: tf.add(j[k[i]], l[i])\n",
    "#     loop_vars = [counter, gauss_sum, pt2_ind, prob_grid]\n",
    "#     tf.while_loop(c, b, loop_vars)\n",
    "\n",
    "\n",
    "#     print('pt2_dense shape',pt2_dense.shape)\n",
    "#     for i in range(pt2_dense.shape[0]):\n",
    "#         print('i', i, 'pt2_ind[i]',pt2_ind[i].shape)\n",
    "#         gauss_sum[pt2_ind[i,:]] += prob_grid[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:05:49.554110Z",
     "start_time": "2018-09-26T16:05:14.827455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "#     init_sum.initializer()\n",
    "    r_ghm_norm  = gauss_heatmap_norm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:06:14.623280Z",
     "start_time": "2018-09-26T16:06:13.539432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_2d_gaussian, plot_3d_gaussian\n",
    "box = 23\n",
    "plot_3d_gaussian(r_ghm_norm[0,1])\n",
    "plot_3d_gaussian(r_ghm[0,1])\n",
    "# for i in range(81):\n",
    "#     print(np.max(r_kvar[0,i]), np.max(r_ghm[0,i]), np.sum(r_kvar[0,i]),np.sum(r_ghm[0,i]))\n",
    "# plot_3d_gaussian(r_prob_grid_norm_scaled[box])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  `build_heatmap()` - part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:50:35.860403Z",
     "start_time": "2018-10-08T14:50:35.535087Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ##  Generate scores using prob_grid and pt2_dense - NEW METHOD\n",
    "    ##  added 09-21-2018\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    scores_from_sum2 = tf.map_fn(build_hm_score, [prob_grid, pt2_dense_scaled, pt2_dense[:,7]], dtype = tf.float32, swap_memory = True)\n",
    "    scores_scattered = tf.scatter_nd(pt2_ind, scores_from_sum2, [batch_size, num_classes, rois_per_image, 3], name = 'scores_scattered')\n",
    "    gauss_scores = tf.concat([in_tensor, scores_scattered], axis = -1,name = names[0]+'_scores')\n",
    "    print('    scores_scattered shape : ', scores_scattered.shape) \n",
    "    print('    gauss_scores           : ', gauss_scores.shape, ' Name:   ', gauss_scores.name)\n",
    "    print('    gauss_scores  (FINAL)  : ', gauss_scores.shape, ' Keras tensor ', KB.is_keras_tensor(gauss_scores) )      \n",
    "    \n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ##   Normalization is already perfored on the scores at a per_class leve, so we dont use this \n",
    "    ##  code below anympre\n",
    "    ##\n",
    "    ##  This is a regular normalization that moves everything between [0, 1]. \n",
    "    ##  This causes negative values to move to -inf, which is a problem in FCN scoring. \n",
    "    ##  To address this a normalization between [-1 and +1] was introduced in FCN.\n",
    "    ##  Not sure how this will work with training tho.\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "    #     normalizer   = tf.reduce_max(scores_scatt[...,-1], axis = -1, keepdims=True)\n",
    "    #     print('norm',normalizer.shape)\n",
    "    #     normalizer   = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    #     norm_score2   = tf.expand_dims(scores_scatt[...,-1]/normalizer, axis = -1)\n",
    "    #     print('norm_SCORE2',norm_score2.shape)\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    #  Generate scores using GAUSS_SUM -- OLD METHOD\n",
    "    #  removed 09-21-2018\n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    #   Generate scores : \n",
    "    #   -----------------\n",
    "    #  NOTE: Score is generated on NORMALIZED gaussian distributions (GAUSS_NORM)\n",
    "    #        If want to do this on NON-NORMALIZED, we need to apply it on GAUSS_SUM\n",
    "    #        Testing demonstated that the NORMALIZED score generated from using GAUSS_SUM \n",
    "    #        and GAUSS_NORM are the same. \n",
    "    #        For now we will use GAUSS_SUM score and GAUSS_NORM heatmap. The reason being that \n",
    "    #        the raw score generated in GAUSS_SUM is much smaller. \n",
    "    #        We may need to change this base on the training results from FCN \n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #   duplicate GAUSS_NORM <num_roi> times to pass along with bboxes to map_fn function\n",
    "    # \n",
    "    #   Here we have a choice to calculate scores using the GAUSS_SUM (unnormalized) or GAUSS_NORM (normalized)\n",
    "    #   after looking at the scores and ratios for each option, I decided to go with the normalized \n",
    "    #   as the numbers are larger\n",
    "    #\n",
    "    #   Examples>\n",
    "    #   Using GAUSS_SUM\n",
    "    # [   3.660313    3.513489   54.475536   52.747402    1.   0.999997    4.998889 2450.          0.00204     0.444867]\n",
    "    # [   7.135149    1.310972   50.020126   44.779854    1.   0.999991    4.981591 1892.          0.002633    0.574077]\n",
    "    # [  13.401865    0.         62.258957   46.636948    1.   0.999971    4.957398 2303.          0.002153    0.469335]\n",
    "    # [   0.          0.         66.42349    56.123024    1.   0.999908    4.999996 3696.          0.001353    0.294958]\n",
    "    # [   0.          0.         40.78952    60.404335    1.   0.999833    4.586552 2460.          0.001864    0.406513]    \n",
    "    #                                                       \n",
    "    #   Using GAUSS_NORM:                             class   r-cnn scr   \n",
    "    # [   3.660313    3.513489   54.475536   52.747402    1.   0.999997 1832.9218   2450.          0.748131    0.479411]\n",
    "    # [   7.135149    1.310972   50.020126   44.779854    1.   0.999991 1659.3965   1892.          0.877059    0.56203 ]\n",
    "    # [  13.401865    0.         62.258957   46.636948    1.   0.999971 1540.4974   2303.          0.668909    0.428645]\n",
    "    # [   0.          0.         66.42349    56.123024    1.   0.999908 1925.3267   3696.          0.520922    0.333813]\n",
    "    # [   0.          0.         40.78952    60.404335    1.   0.999833 1531.321    2460.          0.622488    0.398898]\n",
    "    # \n",
    "    #  to change the source, change the following line gauss_heatmap_norm <--> gauss_heatmap\n",
    "    #---------------------------------------------------------------------------------------------------------------------------\n",
    "    # flatten guassian scattered and input_tensor, and pass on to build_bbox_score routine \n",
    "    # in_shape = tf.shape(in_tensor)\n",
    "    # print('    shape of in_tensor is : ', KB.int_shape(in_tensor))\n",
    "    # in_tensor_flattened  = tf.reshape(in_tensor, [-1, in_shape[-1]])  <-- not a good reshape style!! \n",
    "    # replaced with following line:\n",
    "    # in_tensor_flattened  = tf.reshape(in_tensor, [-1, in_tensor.shape[-1]])\n",
    "    #\n",
    "    #  bboxes = tf.to_int32(tf.round(in_tensor_flattened[...,0:4]))\n",
    "    #\n",
    "    # print('    in_tensor             : ', in_tensor.shape)\n",
    "    # print('    in_tensor_flattened   : ', in_tensor_flattened.shape)\n",
    "    # print('    Rois per class        : ', rois_per_image)\n",
    "    #\n",
    "    #     print('\\n    Scores from gauss_heatmap ----------------------------------------------')\n",
    "    #     temp = tf.expand_dims(gauss_heatmap, axis =2)\n",
    "    #     print('    temp expanded          : ', temp.shape)\n",
    "    #     temp = tf.tile(temp, [1,1, rois_per_image ,1,1])\n",
    "    #     print('    temp tiled shape       : ', temp.shape)\n",
    "    # \n",
    "    #     temp = KB.reshape(temp, (-1, temp.shape[-2], temp.shape[-1]))\n",
    "    #     \n",
    "    #     print('    temp flattened         : ', temp.shape)\n",
    "    #     print('    in_tensor_flattened    : ', in_tensor_flattened.shape)\n",
    "    # \n",
    "    #     scores_from_sum = tf.map_fn(build_hm_score, [temp, in_tensor_flattened], dtype=tf.float32)\n",
    "    #     scores_shape    = [in_tensor.shape[0], in_tensor.shape[1], in_tensor.shape[2], -1]\n",
    "    #     scores_from_sum = tf.reshape(scores_from_sum, scores_shape)    \n",
    "    #     print('    reshaped scores        : ', scores_from_sum.shape)\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    #  tf.reduce_max(scores_from_sum[...,-1], axis = -1, keepdims=True) result is [num_imgs, num_class, 1]\n",
    "    #\n",
    "    #  This is a regular normalization that moves everything between [0, 1]. \n",
    "    #  This causes negative values to move to -inf, which is a problem in FCN scoring. \n",
    "    #  To address this a normalization between [-1 and +1] was introduced in FCN.\n",
    "    #  Not sure how this will work with training tho.\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    #     normalizer   = tf.reduce_max(scores_from_sum[...,-1], axis = -1, keepdims=True)\n",
    "    #     normalizer   = tf.where(normalizer < 1.0e-15,  tf.ones_like(normalizer), normalizer)\n",
    "    #     norm_score   = tf.expand_dims(scores_from_sum[...,-1]/normalizer, axis = -1)\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # Append `in_tensor` and `scores_from_sum` to form `bbox_scores`\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    #     gauss_scores = tf.concat([in_tensor, scores_from_sum, norm_score], axis = -1,name = names[0]+'_scores')\n",
    "    #     print('    scores_from_sum final  : ', scores_from_sum.shape)    \n",
    "    #     print('    norm_score             : ', norm_score.shape)\n",
    "    #     print('    gauss_scores           : ', gauss_scores.shape,  '   name:   ', gauss_scores.name)\n",
    "    #     print('    gauss_scores  (FINAL)  : ', gauss_scores.shape, ' Keras tensor ', KB.is_keras_tensor(gauss_scores) )    \n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:51:30.100497Z",
     "start_time": "2018-10-08T14:51:30.050615Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "    ##--------------------------------------------------------------------------------------------\n",
    "    ## //create heatmap Append `in_tensor` and `scores_from_sum` to form `bbox_scores`\n",
    "    ##--------------------------------------------------------------------------------------------\n",
    "#     gauss_heatmap      = tf.transpose(gauss_heatmap,[0,2,3,1], name = names[0])\n",
    "###    gauss_heatmap_norm = tf.transpose(gauss_heatmap_norm,[0,2,3,1], name = names[0]+'_norm')\n",
    "\n",
    "### Use heatmap computed from KVAR\n",
    "    gauss_heatmap_norm = tf.transpose(gaussian_heatmap_norm,[0,2,3,1], name = names[0]+'_norm')\n",
    "    \n",
    "    # print('    gauss_heatmap       shape : ', gauss_heatmap.shape     ,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap) )  \n",
    "    # print('    gauss_heatmap_norm  shape : ', gauss_heatmap_norm.shape,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap_norm) )  \n",
    "#     print('    gauss_heatmap       shape : ', gauss_heatmap.shape     ,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap) )  \n",
    "    print('    gauss_heatmap_norm  shape : ', gauss_heatmap_norm.shape,' Keras tensor ', KB.is_keras_tensor(gauss_heatmap_norm) )  \n",
    "    print('    complete')\n",
    "\n",
    "#     return   gauss_heatmap_norm, gauss_scores  # , gauss_heatmap   gauss_heatmap_L2norm    # [gauss_heatmap, gauss_scatt, means, covar]    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:44:31.437678Z",
     "start_time": "2018-10-08T14:44:31.393338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "#     print(pred_array.shape)\n",
    "#     pt2_sum2 = tf.reduce_sum(tf.abs(pred_array[:,:,0:4]), axis=-1)\n",
    "#     r_dense = pt2_dense.eval()\n",
    "#     r_sum = pt2_sum.eval()\n",
    "#     r_ind = pt2_ind.eval()\n",
    "#     r_pred_scores = gauss_scores.eval()\n",
    "# print(r_dense.shape)\n",
    "# print(r_sum.shape)\n",
    "# print(r_ind.shape)\n",
    "# print(r_ind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  `build_hm_score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T13:51:32.685181Z",
     "start_time": "2018-10-08T13:51:32.605522Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------------------------------------------------          \n",
    "##\n",
    "##----------------------------------------------------------------------------------------------------------------------          \n",
    "    \n",
    "def build_hm_score(input_list):\n",
    "    '''\n",
    "    Inputs:\n",
    "    -----------\n",
    "        heatmap_tensor :    [ image height, image width ]\n",
    "        input_row      :    [y1, x1, y2, x2] in absolute (non-normalized) scale\n",
    "        input_norm_score:   Normalzied score from pred_tensor \n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "        gaussian_sum :      sum of gaussian heatmap vlaues over the area covered by the bounding box\n",
    "        bbox_area    :      bounding box area (in pixels)\n",
    "        weighted_sum :      gaussian_sum * bbox_score\n",
    "    '''\n",
    "    heatmap_tensor, input_bbox, input_norm_score = input_list\n",
    "    \n",
    "    with tf.variable_scope('mask_routine'):\n",
    "        y_extent     = tf.range(input_bbox[0], input_bbox[2])\n",
    "        x_extent     = tf.range(input_bbox[1], input_bbox[3])\n",
    "        Y,X          = tf.meshgrid(y_extent, x_extent)\n",
    "        bbox_mask    = tf.stack([Y,X],axis=2)        \n",
    "        mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "        mask_indices = tf.to_int32(mask_indices)\n",
    "        mask_size    = tf.shape(mask_indices)[0]\n",
    "        mask_updates = tf.ones([mask_size], dtype = tf.float32)    \n",
    "        mask         = tf.scatter_nd(mask_indices, mask_updates, tf.shape(heatmap_tensor))\n",
    "        # mask_sum    =  tf.reduce_sum(mask)\n",
    "        mask_applied = tf.multiply(heatmap_tensor, mask, name = 'mask_applied')\n",
    "        bbox_area    = tf.to_float((input_bbox[2]-input_bbox[0]) * (input_bbox[3]-input_bbox[1]))\n",
    "        gaussian_sum = tf.reduce_sum(mask_applied)\n",
    "\n",
    "#         Multiply gaussian_sum by score to obtain weighted sum    \n",
    "#         weighted_sum = gaussian_sum * input_row[5]\n",
    "\n",
    "#       Replaced lines above with following lines 21-09-2018\n",
    "        # Multiply gaussian_sum by normalized score to obtain weighted_norm_sum \n",
    "        weighted_norm_sum = gaussian_sum * input_norm_score    # input_list[7]\n",
    "\n",
    "    return tf.stack([gaussian_sum, bbox_area, weighted_norm_sum], axis = -1)\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Evaluate results from `build_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:53:08.736373Z",
     "start_time": "2018-10-08T14:51:37.298067Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "with sess.as_default():\n",
    "#     sess.run( tf.global_variables_initializer())\n",
    "#     gauss_scatt         = gauss_scatt.eval()\n",
    "#     pred_heatmap        = gauss_sum.eval()\n",
    "    r_normalizer        = normalizer.eval()\n",
    "    pred_heatmap_norm   = gauss_heatmap_norm.eval()\n",
    "    pred_heatmap_scores = gauss_scores.eval()\n",
    "#     prob_grid           = prob_grid.eval()\n",
    "#     r_scores_from_sum2 = scores_from_sum2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:54:15.949083Z",
     "start_time": "2018-10-08T14:54:15.899465Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "img = 0\n",
    "# print(gauss_sum.shape)\n",
    "# print(gauss_scatt.shape)\n",
    "# print(pred_heatmap.shape)\n",
    "print(r_normalizer.shape)\n",
    "print(pred_heatmap_norm.shape)\n",
    "print(model_pred_heatmap_norm.shape)\n",
    "# print(r_scores_from_sum2.shape)\n",
    "print(pred_heatmap_scores.shape)\n",
    "print(model_pred_heatmap_scores.shape)\n",
    "# print(pred_heatmap_scores[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T15:22:09.189978Z",
     "start_time": "2018-10-08T15:22:09.037994Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=250, suppress=True)    \n",
    "# np.set_printoptions(precision=4, threshold=4000, linewidth=210, suppress=True)\n",
    "for img in [0]:\n",
    "    class_ids = np.unique(pred_heatmap_scores[img,:,:,4]).astype(int).tolist()    \n",
    "    print('\\n Class ids for img', i, ':',class_ids, '\\n')\n",
    "    for i in class_ids:\n",
    "        print('Image ', img , '/ Class ',i,' ------------ ')        \n",
    "        for j in range(25):\n",
    "            print(' gt    score : ', model_gt_heatmap_scores[img,i,j]) \n",
    "            print(' pred  score : ', pred_heatmap_scores[img,i,j])\n",
    "            print(' model score2: ', model_pred_heatmap_scores[img,i,j])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### compare results of `pred_heatmap_scores` from code above and program file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T15:08:26.001000Z",
     "start_time": "2018-10-08T15:08:25.706504Z"
    },
    "hidden": true,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    " \n",
    "print('pred_heatmap_scores shape is       ', pred_heatmap_scores.shape )\n",
    "print('pred_heatmap_scores from model is :', model_pred_heatmap_scores.shape)\n",
    "# with sess.as_default():\n",
    "#     r_pred_tensor = pred_tensor.eval()\n",
    "for img in [0]:\n",
    "    class_ids = np.unique(pred_heatmap_scores[img,:,:,4]).astype(int).tolist()    \n",
    "    print('Classids: ', class_ids)\n",
    "    for i in class_ids:\n",
    "        print('Image ', img , '/ Class ',i,' ------------ normalizer:', r_normalizer[img,i])\n",
    "        for j in range(200):\n",
    "            print(pred_heatmap_scores[img,i,j])\n",
    "            print(model_pred_heatmap_scores[img,i,j])\n",
    "            if (pred_heatmap_scores[img,i,j,-1] == model_pred_heatmap_scores[img,i,j,-1] == 0):\n",
    "                break\n",
    "#         print(pred_refined_tensor[img,i,j])\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Run TF graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with sess1.as_default():\n",
    "# FeedList = [positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_class_ids, roi_gt_boxes, roi_gt_box_assignment ]\n",
    "# FeedList = [ rois, roi_gt_class_ids,  roi_gt_deltas, roi_gt_boxes]\n",
    "Fetches  = [ pred_heatmap, pred_heatmap_norm, pred_heatmap_scores]\n",
    "tt = sess.run(Fetches)\n",
    "print(type(tt), len(tt))\n",
    "for i in tt:\n",
    "    print(type(i), i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  Plot heatmaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Plot 2D heatmap of  one `pred_heatmap` distribution generated in `build_heatmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:52:41.062772Z",
     "start_time": "2018-10-15T19:52:41.012103Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_one_bbox_heatmap, plot_3d_heatmap, plot_3d_heatmap_all_classes, plot_2d_heatmap, plot_2d_heatmap_with_bboxes\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "print('Image id: ',image_id)\n",
    "img_id = 0\n",
    "class_names = dataset_train.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  2D plot of `pred_heatmap_norm` returned from model : `model_pred_heatmap_norm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:17:10.937230Z",
     "start_time": "2018-10-15T19:17:10.901319Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ## range(mrcnn_config.BATCH_SIZE):\n",
    "    # print(pred_refined_heatmap_scores[img_id,:4])\n",
    "    print(pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    \n",
    "#     plot_2d_heatmap_with_bboxes(model_pred_heatmap_norm, model_pred_heatmap_scores, \n",
    "#                                 img_id, [0], width=6, height=6, class_names = class_names, scale = 4)\n",
    "#     plot_2d_heatmap_with_bboxes( pred_heatmap_norm,  pred_heatmap_scores, \n",
    "#                                 img_id, [0], width=6, height=6, class_names = class_names, scale = 4)    \n",
    "    \n",
    "#     plot_2d_heatmap(pred_heatmap_norm, img_id, class_ids, width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  2D plot of `pred_heatmap_norm` returned from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:52:46.738329Z",
     "start_time": "2018-10-15T19:52:46.285921Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [1]:     ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_2d_heatmap_with_bboxes( pred_heatmap_norm,  pred_heatmap_scores, \n",
    "                                img_id, class_ids, width=6, height=6, class_names = class_names, scale = 4)      \n",
    "#     plot_2d_heatmap(model_pred_heatmap_norm, img_id, class_ids, width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  2D plot of `gt_heatmap_norm` returned from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:52:54.964969Z",
     "start_time": "2018-10-15T19:52:54.531072Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [1]:     ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(gt_heatmap_norm.shape)\n",
    "    class_ids = np.unique(gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_2d_heatmap_with_bboxes(gt_heatmap_norm, gt_heatmap_scores, \n",
    "                                img_id, class_ids, width=6, height=6, class_names = class_names, scale = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D plot of `model_pred_heatmap_norm` returned form model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:20:52.897723Z",
     "start_time": "2018-10-15T19:20:52.803582Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ##range(mrcnn_config.BATCH_SIZE):\n",
    "    print(model_pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(model_pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(model_pred_heatmap_norm, img_id, [37], width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D plot of  `pred_heatmap_norm` returned form code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:53:38.910183Z",
     "start_time": "2018-10-15T19:53:37.370021Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [0]: ## range(mrcnn_config.BATCH_SIZE):\n",
    "    print(pred_heatmap_norm.shape)\n",
    "    class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(pred_heatmap_norm, img_id, class_ids, width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  3D plot of  `gt_heatmap_norm` returned form code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:53:48.031070Z",
     "start_time": "2018-10-15T19:53:43.844950Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in [1]: ## range(mrcnn_config.BATCH_SIZE):\n",
    "    print(gt_heatmap_norm.shape)\n",
    "    class_ids = np.unique(gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    plot_3d_heatmap(gt_heatmap_norm, img_id, class_ids, width=6, height=6, class_names = class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Verfiy max and min of gaussian heatmaps are 1.0 and 0.0, respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T19:44:33.238584Z",
     "start_time": "2018-10-15T19:44:33.136281Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, threshold=None, linewidth=200, suppress=True)\n",
    "print(pred_heatmap_norm.shape)\n",
    "hm_max = np.max(pred_heatmap_norm, axis = (1,2))\n",
    "hm_min = np.min(pred_heatmap_norm, axis = (1,2))\n",
    "print(hm_max.shape)\n",
    "for img_id in range(mrcnn_config.BATCH_SIZE):\n",
    "    # print(pred_refined_heatmap_scores[img_id,:4])\n",
    "    class_ids = np.unique(pred_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('\\n Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    print('-'*38)\n",
    "    for cls in class_ids: \n",
    "        print(' class: {}   max: {}  min: {}'.format(cls, hm_max[img_id,cls], hm_min[img_id,cls]))\n",
    "#         print(pred_heatmap_scores[img_id, cls])\n",
    "\n",
    "print(gt_heatmap_norm.shape)\n",
    "hm_max = np.max(gt_heatmap_norm, axis = (1,2))\n",
    "hm_min = np.min(gt_heatmap_norm, axis = (1,2))\n",
    "print(hm_max.shape)\n",
    "for img_id in range(mrcnn_config.BATCH_SIZE):\n",
    "    # print(pred_refined_heatmap_scores[img_id,:4])\n",
    "    class_ids = np.unique(gt_heatmap_scores[img_id,:,:,4]).astype(int).tolist()\n",
    "    print('\\n Image : {}  ClassIds: {}'.format(img_id, class_ids))\n",
    "    print('-'*38)\n",
    "    for cls in class_ids: \n",
    "        print(' class: {}   max: {}  min: {}'.format(cls, hm_max[img_id,cls], hm_min[img_id,cls]))\n",
    "#         print(pred_heatmap_scores[img_id, cls])\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Display `pred_scatter` heatmaps for all bounding boxes of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:12.230708Z",
     "start_time": "2018-05-20T14:13:10.485070Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "print('Image id: ',image_id , '    Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "img = 1\n",
    "print(pred_heatmap_scores[img,0,0])\n",
    "plot_bbox_heatmaps(gauss_scatt[img], pred_tensor[img], width = 15, height=25, num_bboxes=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Display `gauss_heatmap` heatmap (not normalized, normlized, L2 normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-19T12:54:21.168641Z",
     "start_time": "2018-09-19T12:54:21.110294Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib notebook\n",
    "print('Image id: ',image_id , '    Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "img = 0\n",
    "print(pred_heatmap_scores[img,0,0])\n",
    "# plot_one_heatmap(pred_heatmap[img], pred_heatmap_scores[img], width=19, num_bboxes = 10, title='Non-normalized')\n",
    "plot_gaussian(pred_heatmap_norm[img,:,:,1],0, \n",
    "plot_one_heatmap(pred_heatmap_norm[img], pred_heatmap_scores[img], width=19, num_bboxes = 10, title='normalized')\n",
    "# plot_one_heatmap(pred_heatmap_L2norm[img], pred_heatmap_scores[img], width=19, num_bboxes = 10, title='L2-normalized')\n",
    "# plot_heatmaps(pred_heatmap, pred_heatmap_scores, width = 15, num_bboxes=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Display `gauss_heatmap` 3D heatmap (not normalized, normlized, L2 normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:43:53.940653Z",
     "start_time": "2018-05-20T14:43:52.360486Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_3d_heatmap\n",
    "%matplotlib notebook\n",
    "print('Image id: ',image_id , '    Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "img = 1\n",
    "print(pred_heatmap_scores[img,cls,:10])\n",
    "\n",
    "ttl = 'Non-normalized - image: {}'.format(img)\n",
    "plot_3d_heatmap(pred_heatmap[img], title = ttl, width = 20)\n",
    "plot_one_heatmap(pred_heatmap[img], pred_heatmap_scores[img], width=15, title=ttl)\n",
    "\n",
    "ttl = 'Normalized - image: {}'.format(img)\n",
    "plot_3d_heatmap(pred_heatmap[img], title = ttl, width = 20)\n",
    "plot_one_heatmap(pred_heatmap[img], pred_heatmap_scores[img], width=15, title=ttl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Find maximum of gaussian distributions for the pred_heatmap\n",
    "Potentially use this as our heatmap scores \n",
    "Found out that using MAX values from the class heatmap (currently generated from the pred_tensor that itself is generated form output_rois and mrcnn_class) is not a viable option, because mutlple max values tend to congreagate around the peak of the gaussian distribution. \n",
    "This is also the case for gt_heatmaps.\n",
    "This will probably also be the case for the FCN output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### pred_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:23:37.739059Z",
     "start_time": "2018-05-11T13:23:37.484900Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "\n",
    "print(pred_hm.shape)\n",
    "cls_hm = pred_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print(pred_hm_norm.shape)\n",
    "cls_hm_norm = pred_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:09:06.929477Z",
     "start_time": "2018-05-11T13:09:06.655253Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### gt_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:12.185707Z",
     "start_time": "2018-05-11T13:24:11.932533Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "print(pred_hm.shape)\n",
    "cls_hm = gt_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print('---- norm -----')\n",
    "print(gt_hm_norm.shape)\n",
    "cls_hm_norm = gt_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:14.243495Z",
     "start_time": "2018-05-11T13:24:13.965220Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:48:39.739236Z",
     "start_time": "2018-05-11T11:48:39.479040Z"
    },
    "hidden": true,
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "max_a = np.max(cls_pred_heatmap)\n",
    "print(max_a.shape)\n",
    "\n",
    "print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "print()\n",
    "\n",
    "print(' covar ', covar_sqrd)\n",
    "print(prob_b[35:50, 45:54])\n",
    "max_b = np.max(prob_b)\n",
    "print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "##  `development build_heatmap_tf ()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "### Generate Multivariate Normal Distribution from Pred_Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Prepare values to pass to build_gaussian_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "####  Display for visual check - `pred_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "####  Display for visual check - `gt_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "\n",
    "### Plot heatmap produced by network `fcn_bilinear` and compare with `pred_gaussian`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:56:18.789494Z",
     "start_time": "2018-05-19T20:56:18.196391Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_gaussian, plot_gaussian_2d\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "img = 2\n",
    "cls = 2\n",
    "image_id = input_image_meta[img,0]\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "Zout1 = pred_heatmap     # gt_gaussiam \n",
    "Zout2 = pred_heatmap_norm  # fcn_bilinear\n",
    "Zout3 = pred_heatmap_L2norm  # fcn_bilinear\n",
    "\n",
    "print(Zout1.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "print(pred_tensor[img,cls,:10])\n",
    "print(pred_tensor.shape)\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "\n",
    "width = 9\n",
    "# for j in [cls] : #range(num_classes):\n",
    "print(pred_heatmap_scores[img,cls,:10])\n",
    "ttl = 'Pred_hm      - image :  {} class: {} '.format(img,j)\n",
    "plot_gaussian_2d(Zout1[img,:,:,j], title = ttl, width = width)\n",
    "\n",
    "ttl = 'pred_norm - image :  {} class: {} '.format(img,j)     \n",
    "plot_gaussian_2d(Zout2[img,:,:,j], title = ttl, width = width)  \n",
    "\n",
    "ttl = 'pred_norm_L2 - image :  {} class: {} '.format(img,j)     \n",
    "plot_gaussian_2d(Zout3[img,:,:,j], title = ttl, width = width)  \n",
    "\n",
    "\n",
    "from mrcnn.visualize import display_gt_bboxes, display_roi_proposals\n",
    "model_info = [model, config, dataset_train, train_generator]\n",
    "display_roi_proposals(model_info, input_image_meta, pred_tensor, [cls], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:03:17.009403Z",
     "start_time": "2018-05-19T13:03:16.778767Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "width = 12\n",
    "plot_gaussian2([pred_heatmap_norm, fcn_heatmap_norm], image_idx = 0, title = ttl, width = width)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Test `means`, `covar`, `gauss_grid`, and `gauss_sum ` between development version and final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:10.133108Z",
     "start_time": "2018-05-02T11:10:09.386212Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(means.get_shape(), means.get_shape())\n",
    "tst1 = means.eval()\n",
    "tst2 = means2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:14.482950Z",
     "start_time": "2018-05-02T11:10:14.205020Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = st.eval()\n",
    "tst2 = st2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:18.158709Z",
     "start_time": "2018-05-02T11:10:17.474806Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_grid.eval()\n",
    "tst2 = gauss_grid2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,0,:10])\n",
    "print()\n",
    "print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:23.859635Z",
     "start_time": "2018-05-02T11:10:23.164182Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_sum.eval()\n",
    "tst2 = gauss_sum2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "# print(tst1[0,0,:10])\n",
    "# print()\n",
    "# print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T19:52:46.002369Z",
     "start_time": "2018-05-19T19:52:45.737646Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "from scipy.stats import  multivariate_normal\n",
    "# Build mesh-grid to hold pixel coordinates ----------------------------------\n",
    "XX = np.arange(0, img_w, 1)\n",
    "YY = np.arange(0, img_h, 1)\n",
    "XX, YY = np.meshgrid(XX, YY)\n",
    "print('XX shape', XX.shape)\n",
    "pos  = np.empty(XX.shape + (2,))   # concatinate shape of x to make ( x.rows, x.cols, 2)\n",
    "pos[:,:,0] = XX;\n",
    "pos[:,:,1] = YY;\n",
    "print('XX')\n",
    "print(XX)\n",
    "print('YY')\n",
    "print(YY)\n",
    "print(pos[0,:,:])\n",
    "print(pos[0])\n",
    "print(grid[0].eval())\n",
    "print(' pos type    ', type(pos), type(grid))\n",
    "print(' grid shape ', pos.shape, grid.shape)\n",
    "print(np.all(pos == grid.eval()))\n",
    "mean = np.array([1,2])\n",
    "covar = np.array([[1,0],[0,1]])\n",
    "print(' mean  ', mean)\n",
    "print(' covar ', covar)\n",
    "mvna   = multivariate_normal(mean, covar)\n",
    "prob_a = mvna.pdf(pos)\n",
    "\n",
    "# mvnb = multivariate_normal(mean, covar_sqrd)\n",
    "# prob_b = mvnb.pdf(pos)\n",
    "\n",
    "# print(prob_a[35:50, 45:54])\n",
    "# max_a = np.max(prob_a)\n",
    "# print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "# print()\n",
    "\n",
    "# print(' covar ', covar_sqrd)\n",
    "# print(prob_b[35:50, 45:54])\n",
    "# max_b = np.max(prob_b)\n",
    "# print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "# print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:08:23.894913Z",
     "start_time": "2018-05-19T20:08:22.044145Z"
    },
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates  \n",
    "    #-----------------------------------------------------------------------------\n",
    "    X = tf.range(80, dtype=tf.int32)\n",
    "    Y = tf.range(80, dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "\n",
    "    # duplicate (repeat) X and Y into a  batch_size x rois_per_image tensor\n",
    "    print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "    ones = tf.ones([1, 1, 1], dtype = tf.int32)\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    print('    Ones:    ', ones.shape)                \n",
    "    print('    ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    print('    ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    print('    before transpse ', tf.shape(bef_pos).eval())\n",
    "    pos_grid = tf.transpose(bef_pos,[1,2,0,3])\n",
    "    print('    after transpose ', tf.shape(pos_grid).eval())    \n",
    "    pt2_den = tf.constant([[10,10,30,70]], dtype = tf.float32)\n",
    "    print(type(pt2_den))\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "    #-----------------------------------------------------------------------------\n",
    "    width  = pt2_den[:,3] - pt2_den[:,1]      # x2 - x1\n",
    "    height = pt2_den[:,2] - pt2_den[:,0]\n",
    "    print(width.eval(), type(width))\n",
    "    print(height.eval(), type(height))\n",
    "    cx     = pt2_den[:,1] + tf.div( width  , 2.0)\n",
    "    cy     = pt2_den[:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)\n",
    "    print(means.eval())\n",
    "    print(covar.eval())\n",
    "\n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    print('     Prob_grid shape before tanspose: ',prob_grid.get_shape())\n",
    "    prob_grid = tf.transpose(prob_grid,[2,0,1])\n",
    "    print('     Prob_grid shape after tanspose: ',prob_grid.get_shape())    \n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot Image with bounding boxes from `output_rois`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:53:03.431815Z",
     "start_time": "2018-09-21T12:53:03.337488Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "image_id = input_image_meta[img_idx,0]\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "log(\"image\", image)\n",
    "log(\"mask\", mask)\n",
    "log(\"class_ids\", class_ids)\n",
    "log(\"bbox\", bbox)\n",
    "\n",
    "# class_names = [str(dataset_train.class_names[class_id]) for class_id in class_ids]\n",
    "class_names = dataset_train.class_names\n",
    "# visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print('Classes     : ', class_ids)\n",
    "print(\"image_id    : \", image_id, ' Reference: ', dataset_train.image_reference(image_id))\n",
    "print(' class_ids    : ', class_ids.shape[0])\n",
    "print(' bbox         : ', bbox.shape[0])\n",
    "print(' output_rois: : ', output_rois.shape)\n",
    "print(' Image id     : ', image_id , '  Image meta', img_meta[img_idx,:10])\n",
    "print(' Classes      : ', [class_names[i] for i in class_ids])\n",
    "print(' Image window : ', img_meta[0, 4:8])\n",
    "print(' Image shape  : ', image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display `output_roi` without  delta refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:55:18.047596Z",
     "start_time": "2018-09-21T12:55:17.482833Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unormalized_rois = output_rois[img_idx] * [1024,1024,1024,1024]\n",
    "unrefined_rois   = utils.boxes_to_image_domain(unormalized_rois, img_meta[0] )\n",
    "visualize.draw_rois(image, unrefined_rois, target_class_ids[0], class_names, limit=5) #, random = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display `output_rois` with after clipping to image boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T13:08:25.467820Z",
     "start_time": "2018-09-21T13:08:24.905458Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clipped_rois = utils.clip_to_window_np(img_meta[0, 4:8], unormalized_rois)\n",
    "clipped_rois = utils.boxes_to_image_domain(clipped_rois, img_meta[0] )\n",
    "visualize.draw_rois(image, clipped_rois , target_class_ids[0], class_names, bbox_ids = [0,1,2]) # or , limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Displayt `output_rois` after applying `target_bbox_deltas`\n",
    "\n",
    "NOTE: MUST BE MULTIPLIED BY BBOX_STD_DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T13:08:57.332574Z",
     "start_time": "2018-09-21T13:08:56.776213Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(' Target_bbox_deltas: ',target_bbox_deltas.shape)\n",
    "## 1- Apply Bounding Box Standard Deviation and apply to output_rois\n",
    "apply_deltas = target_bbox_deltas[img_idx] * mrcnn_config.BBOX_STD_DEV\n",
    "refined_rois = utils.apply_box_deltas_np(output_rois[img_idx], apply_deltas)\n",
    "print(' Refined ROIs shape: ',refined_rois.shape)\n",
    "# print(refined_rois[:20])\n",
    "\n",
    "## 3- Clip to image windoow boundaries:\n",
    "refined_rois = refined_rois * [1024,1024,1024,1024]\n",
    "refined_rois = utils.clip_to_window_np(img_meta[0, 4:8], refined_rois)\n",
    "\n",
    "## 4- Transfer to image coordniates :\n",
    "refined_rois = utils.boxes_to_image_domain(refined_rois, img_meta[0] )\n",
    "## 5- Visualize\n",
    "visualize.draw_rois(image, refined_rois, target_class_ids[0], class_names,bbox_ids = [0,1,2], limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Apply predicted `mrcnn_bbox` delta refinements to `output_rois` and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T13:10:07.212107Z",
     "start_time": "2018-09-21T13:10:06.133701Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create un\n",
    "unormalized_rois = output_rois[img_idx] * [1024,1024,1024,1024]\n",
    "clipped_rois = utils.clip_to_window_np(img_meta[0, 4:8], unormalized_rois)\n",
    "unrefined_rois   = utils.boxes_to_image_domain(clipped_rois, img_meta[0] )\n",
    "\n",
    "## 1- Extract predicted deltas from mrcnn_bbox\n",
    "classes, deltas = get_predicted_mrcnn_deltas(mrcnn_class, mrcnn_bbox, verbose = False)\n",
    "# print(classes.shape, deltas.shape)\n",
    "# print(classes[0,:20])\n",
    "# print(deltas[0,:20])\n",
    "\n",
    "\n",
    "## 2- Apply Bounding Box Standard Deviation and apply to output_rois\n",
    "apply_deltas = deltas[0] * mrcnn_config.BBOX_STD_DEV\n",
    "refined_rois = utils.apply_box_deltas_np(output_rois[img_idx], apply_deltas)\n",
    "print(' Refined ROIs shape: ',refined_rois.shape)\n",
    "# print(refined_rois[:20])\n",
    "\n",
    "## 3- Clip to image windoow boundaries:\n",
    "refined_rois = refined_rois * [1024,1024,1024,1024]\n",
    "refined_rois = utils.clip_to_window_np(img_meta[0, 4:8], refined_rois)\n",
    "\n",
    "## 4- Transfer to image coordniates :\n",
    "refined_rois = utils.boxes_to_image_domain(refined_rois, img_meta[0] )\n",
    "\n",
    "# Visualize\n",
    "visualize.draw_rois(image, unrefined_rois, target_class_ids[0], class_names,  limit=5)\n",
    "visualize.draw_rois(image, refined_rois, target_class_ids[0], class_names,  limit=5)\n",
    "# visualize.draw_rois_with_refinements(image, unrefined_rois, refined_rois, target_class_ids[0], class_names, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Display `image_gt_bboxes` provided by data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T13:00:26.348261Z",
     "start_time": "2018-09-21T13:00:25.813073Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display image and instances\n",
    "# visualize.display_instances_with_mask(image, bbox, mask, class_ids, dataset_train.class_names)   \n",
    "\n",
    "# print(input_gt_bboxes[0,:20])\n",
    "gt_bboxes = utils.boxes_to_image_domain(input_gt_bboxes[0], img_meta[0] )\n",
    "visualize.draw_rois(image, gt_bboxes[:20], input_gt_class_ids[0,:20], class_names, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## misc code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### sparse to dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    tf_dense = tf.sparse_to_dense(pt2_ind), in_tensor.shape[:-1], 1,0)\n",
    "    r_tf_dense = tf_dense.eval()\n",
    "print(r_tf_dense.shape)    \n",
    "print(r_tf_dense[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "####  Display for visual check - `pred_heatmap_norm` is the final result from  `build_heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T17:29:35.708474Z",
     "start_time": "2018-05-21T17:29:35.418691Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pred_heatmap_norm.shape)\n",
    "temp = pred_heatmap_norm\n",
    "np.set_printoptions(linewidth=150, threshold=10000, suppress=False)\n",
    "print('  Temp shape :',  temp.shape)\n",
    "temp_sum = np.sum(temp,axis=(1,2))\n",
    "print('temp_sum is ', temp_sum.shape)\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        print('img ',i,' class ', j, ' sum:',temp_sum[i,j],  ' max: ',np.max(temp[i,:,:,j]),' mean: ', np.mean(temp[i,:,:,j]),' min: ', np.min(temp[i,:,:,j]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T18:56:20.286127Z",
     "start_time": "2018-05-21T18:56:19.956192Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6, suppress=True)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_heatmap_scores shape is ', pred_heatmap_scores.shape)\n",
    "for img in [0,1,2]:\n",
    "    for k in range(4):\n",
    "        print('Image ', img , '/ Class ',k,' ------------')\n",
    "        print(np.min(pred_heatmap_scores[img,k,:,8]))\n",
    "        print(pred_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T17:25:18.661505Z",
     "start_time": "2018-05-20T17:25:18.406810Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "print('gt_heatmap_scores shape is ', gt_heatmap_scores.shape)\n",
    "img = 1\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(gt_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T17:12:28.879203Z",
     "start_time": "2018-05-21T17:12:28.616104Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "    temp = fcn_heatmap\n",
    "    np.set_printoptions(linewidth=150, threshold=10000)\n",
    "    print('  output shapes :',  temp.get_shape())\n",
    "    temp_sum = tf.reduce_sum(temp, [2,3])\n",
    "    temp_min = tf.reduce_min(temp, [2,3])\n",
    "    temp_max = tf.reduce_max(temp, [2,3])\n",
    "    temp_avg = tf.reduce_mean(temp, [2,3])\n",
    "    print('temp_sum is ', temp_sum.shape)\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "                print('img/cls ',i,'/', j,'  sum:',temp_sum[i,j], 'min',temp_min[i,j] ,'max',temp_max[i,j] ,'avg',temp_avg[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "#### `byclas_to_byimage()` reshape tensor / numpy array from per_class to per image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T18:35:36.921742Z",
     "start_time": "2018-09-25T18:35:36.852068Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def byclass_to_byimage_np(in_array, seqid_column):    \n",
    "    ''' \n",
    "    convert a by class tensor shaped  [batch_size, num_classes, num_bboxes, columns ] to \n",
    "            a by image tensor shaped  [batch_size, num_bboxes, columns]\n",
    "    '''\n",
    "    #     np_sum = np.sum(np.abs(model_gt_heatmap_scores[:,:,:,0:4]), axis=-1)\n",
    "    #     print(np_sum.shape)\n",
    "    #     a,b,c = np.where(np_sum > 0)\n",
    "    a,b,c = np.where(in_array[...,seqid_column]>0)\n",
    "\n",
    "    output = np.zeros((in_array.shape[0],in_array.shape[-2],in_array.shape[-1]))\n",
    "#     print(' output shape is ',output.shape)\n",
    "#     print(a.shape, b.shape,c.shape)\n",
    "    \n",
    "    for img, cls , box in zip(a, b,c):\n",
    "#         print( img,cls, box, 200 - in_array[img, cls, box,6].astype(int))\n",
    "        output[img, 200 - in_array[img, cls, box,6].astype(int)] = in_array[img, cls, box]\n",
    "\n",
    "    return output\n",
    "\n",
    "def byclass_to_byimage_tf(in_array, seqid_column):    \n",
    "    ''' \n",
    "    convert a by class tensor shaped  [batch_size, num_classes, num_bboxes, columns ] to \n",
    "            a by image tensor shaped  [batch_size, num_bboxes, columns]\n",
    "    '''\n",
    "    aa = tf.reshape(in_array, [in_array.shape[0], -1, in_array.shape[-1]])\n",
    "    _ , sort_inds = tf.nn.top_k(tf.abs(aa[:,:,seqid_column]), k= in_array.shape[2])\n",
    "    batch_grid, bbox_grid = tf.meshgrid(tf.range(in_array.shape[0]), tf.range(in_array.shape[2]),indexing='ij')\n",
    "    gather_inds = tf.stack([batch_grid, sort_inds],axis = -1)\n",
    "    output = tf.gather_nd(aa, gather_inds )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Try `byclass_to_byimage()` on `gt_heatmap_scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T18:20:28.345294Z",
     "start_time": "2018-09-25T18:20:27.629896Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print(gt_heatmap_scores.shape)\n",
    "# outp = byclass_to_byimage_tf(gt_heatmap_scores,6)\n",
    "# with sess.as_default():\n",
    "#      r_outp = outp.eval()\n",
    "# print(r_outp.shape)\n",
    "# print(r_outp[0])\n",
    "# print(r_outp[1])\n",
    "\n",
    "\n",
    "# print(tf_model_pred_heatmap_scores.shape, tf_model_pred_heatmap_scores)\n",
    "# outp = byclass_to_byimage_tf(tf_model_pred_heatmap_scores,6)\n",
    "# with sess.as_default():\n",
    "#      r_outp = outp.eval()\n",
    "# print(r_outp.shape)\n",
    "# print(r_outp[0])\n",
    "# print(r_outp[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Try `byclass_to_byimage()` on `pred_heatmap_scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T18:35:43.684389Z",
     "start_time": "2018-09-25T18:35:42.799114Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "\n",
    "tf_model_pred_heatmap_scores = tf.constant(model_pred_heatmap_scores) \n",
    "\n",
    "print('pred_heatmap_scores shape is       ', pred_heatmap_scores.shape )\n",
    "print('pred_heatmap_scores from model is :', tf_model_pred_heatmap_scores.shape,tf_model_pred_heatmap_scores)\n",
    "r_out2 = byclass_to_byimage_np(pred_heatmap_scores,6)\n",
    "\n",
    "with sess.as_default():\n",
    "    r_out1 = byclass_to_byimage_tf(tf_model_pred_heatmap_scores,6).eval()\n",
    "\n",
    "for img in range(2):\n",
    "    class_ids = np.unique(pred_heatmap_scores[img,:,:,4]).astype(int).tolist()    \n",
    "    print('Classids: ', class_ids)\n",
    "    print('Image ', img ,' ------------')\n",
    "    for j in range(200):\n",
    "        print('tf: ',r_out1[img,j])\n",
    "        print('np: ',r_out2[img,j])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### ground work for writing `byclass_to_by_image()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T17:12:56.458588Z",
     "start_time": "2018-09-25T17:12:55.776329Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(pred_heatmap_scores.shape)\n",
    "# gt_heatmap_scores = tf.identity(model_gt_heatmap_scores)\n",
    "# aa = tf.reshape(gt_heatmap_scores, [gt_heatmap_scores.shape[0], -1, gt_heatmap_scores.shape[-1]])\n",
    "# _ , sort_inds = tf.nn.top_k(tf.abs(aa[:,:,6]), k=gt_heatmap_scores.shape[2])\n",
    "# print(sort_inds.shape)\n",
    "# batch_grid, bbox_grid = tf.meshgrid(tf.range(batch_size), tf.range(gt_heatmap_scores.shape[2]),indexing='ij')\n",
    "# gather_inds = tf.stack([batch_grid, sort_inds],axis = -1)\n",
    "# print(aa.shape)\n",
    "# print(bb.shape)\n",
    "# cc = tf.gather_nd(aa, gather_inds )\n",
    "# print('cc : ',cc.shape)\n",
    "# with sess.as_default():\n",
    "# #     r_pred_heatmap_scores = gauss_scores.eval()\n",
    "#     r_aa = aa.eval()\n",
    "#     r_sort_inds = sort_inds.eval()\n",
    "#     r_gather_inds = gather_inds.eval()\n",
    "# #     r_bb = bb.eval()\n",
    "#     r_cc = cc.eval()\n",
    "# #     r_dd = dd.eval()\n",
    "# # print(r_pred_heatmap_scores[0,1])\n",
    "# print('cc: ',r_cc.shape)\n",
    "# print('bb: ',r_bb.shape)\n",
    "# print('aa: ',r_aa.shape)\n",
    "# # print(r_sort_inds)\n",
    "# print(r_gather_inds)\n",
    "# # print(r_bb)\n",
    "# print(r_cc[0])\n",
    "print(r_cc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Convert `pred_heatmap_scores` using `byclass_to_byimage_np`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T16:03:29.189366Z",
     "start_time": "2018-09-25T16:03:29.110660Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print(model_pred_heatmap_scores.shape)\n",
    "print(model_pred_heatmap_scores[0,0,0])\n",
    "outp = byclass_to_byimage_np(model_pred_heatmap_scores,6)\n",
    "print(outp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Convert `gt_heatmap_scores` using `byclass_to_byimage_np`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T15:51:19.844675Z",
     "start_time": "2018-09-25T15:51:19.746388Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "\n",
    "# print('pred_heatmap_scores shape is       ', gt_heatmap_scores.shape )\n",
    "print('pred_heatmap_scores from model is :', model_gt_heatmap_scores.shape)\n",
    "print(model_gt_heatmap_scores[0,1])\n",
    "\n",
    "# with sess.as_default():\n",
    "#     r_pred_tensor = pred_tensor.eval()\n",
    "# for img in range(2):\n",
    "#     class_ids = np.unique(model_gt_heatmap_scores[img,:,:,4]).astype(int).tolist()    \n",
    "#     print('Classids: ', class_ids)\n",
    "#     for i in class_ids:\n",
    "#         print('Image ', img , '/ Class ',i,' ------------')\n",
    "#         for j in range(200):\n",
    "#             print(gt_heatmap_scores[img,i,j])\n",
    "#             print(model_gt_heatmap_scores[img,i,j])\n",
    "# #         print(pred_refined_tensor[img,i,j])\n",
    "#         print()\n",
    " \n",
    "outp = byclass_to_byimage_np(model_gt_heatmap_scores,6)\n",
    "print(outp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "####  Display for visual check - `pred_heatmap_scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T16:49:31.958039Z",
     "start_time": "2018-05-19T16:49:31.945996Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_heatmap_scores shape is ', pred_heatmap_scores.shape)\n",
    "img = 0\n",
    "for k in range(4):\n",
    "    print('Image ', img , '/ Class ',k,' ------------')\n",
    "    print(pred_heatmap_scores[img,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "####  Display for visual check - `pred_heatmap_norm`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T20:33:24.888916Z",
     "start_time": "2018-05-17T20:33:24.652795Z"
    },
    "hidden": true,
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(pred_heatmap_norm.shape)\n",
    "temp = pred_heatmap_norm\n",
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "print('  Temp shape :',  temp.shape)\n",
    "temp_sum = np.sum(temp,axis=(1,2))\n",
    "print('temp_sum is ', temp_sum.shape)\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "            print('img ',i,' class ', j, ' sum:',temp_sum[i,j])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TFG]",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
